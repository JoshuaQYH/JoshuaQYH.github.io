[{"title":"数据结构 | 二叉树","date":"2019-03-29T08:56:20.000Z","path":"2019/03/29/数据结构-二叉树/","text":"非递归实现遍历 前序遍历非递归实现 使用栈来完成。 访问左节点，压入右节点。 左节点为空，弹出右节点。 中序遍历非递归实现 使用栈来完成 遇到一个节点，将其推入栈，遍历其左子树 遍历完左子树，弹出栈顶节点并访问 同时遍历其右节点，重复上述动作。 非递归后续遍历二叉树 从根节点开始，判断栈空还是非空 沿左路下降。。。 最难的。。总之就是左右子树访问完毕，才访问根节点 O(n) ​ 二叉树的搜索 宽度搜索 队列来存储 类似层序遍历。 访问当前节点，将左右节点压入队列 弹出当前节点 存储结构使用二叉链表的信息。当前节点，存储左右节点的指针。（还有的保存了parent指针） 寻找一个指针的父节点。 1234567891011121314151617181920Node* FindParent(Node* root, Node* current)&#123; Node* tmp; if(root == NULL) return NULL; // root 是否为 current的父节点 if(root-&gt;left == current || root-&gt;right == current)&#123; return root; &#125; if(tmp = FindParent(root-&gt;left, current) != NULL)&#123; return tmp; &#125; if(tmp = FindParent(root-&gt;right, current) != NULL) return tmp; return NULL;&#125;Node* Tree(Node* current)&#123; stack&lt;Node*&gt; s; Node* tmp = root; s.push(NULL);&#125; 完全二叉树，用数组层序存储。 编号为 i 的节点的左节点为 2 i + 1 二叉搜索树快速搜索，时间复杂度为 O(log n ) 其中的构建二叉搜索树比较简单。这里重点记一下，BST删除节点的操作。 我们使用递归的来删除节点，需要分三种情况： 节点的左节点为空，直接将右节点复制到删除节点的位置。（不用考虑右节点是否为空） 如果左节点非空，右节点为空，那就将左节点复制到删除节点的位置。 如果左右节点都不为空，那就找出左子树中的最右节点，将右子树的根节点拼接到该最右节点的右边。 这个方法其实会导致挂接后，整个树的高度过长，影响搜索的效率 我们可以换另外一种思路，就是找到右子树的最小节点，保存其值，赋值给删除节点，然后删除右子树的最小节点。 12345678910111213141516171819202122232425262728293031void removehelp(Node* &amp;root, int val)&#123; if(root == NULL) cout &lt;&lt; val &lt;&lt; \" is not in the tree \\n\" &lt;&lt; endl; else if(val &lt; root-&gt;val)&#123; removehelp(root-&gt;left, val); &#125; else if(val &gt; root-&gt;val)&#123; removehelp(root-&gt;right, val); &#125; else&#123; Node* tmp = root; if(root-&gt;left == NULL) root = root-&gt;right; else if (root-&gt;right == NULL) root = = root-&gt;left; else&#123; tmp = deletemin(root-&gt;right); // 找到右子树中最小的那个数 min，并删除 root-&gt;setValue(tmp-&gt;value); // 将 min中的数赋值给删除的节点的值 &#125; delete tmp; tmp = NULL; &#125;&#125;Node* deletemin(Node * &amp;root)&#123; if(root-&gt;left != NULL)&#123; return deletemin(root-&gt;left); &#125; else&#123; // 找到右子树中最小的，删除，然后将该节点复制到原先被删除节点的位置 node *tmp = root; root = root-&gt;right; return tmp; &#125;&#125; 如何放置BST退化成线性结构？ 允许重复关键码吗？","tags":[{"name":"C++","slug":"C","permalink":"https://joshuaqyh.github.io/tags/C/"},{"name":"数据结构","slug":"数据结构","permalink":"https://joshuaqyh.github.io/tags/数据结构/"}]},{"title":"Leetcode | Practice 7","date":"2019-03-29T07:40:47.000Z","path":"2019/03/29/Leetcode-Practice-7/","text":"如题。 题目的要求就是输入一个编码的串S，包含数字和字母，从头开始读取，如果读取到字母，就直接放入结果的解码串，如果读取到数字，就把解码串已有的内容复制几遍。 最后给定一个数K，返回该位置的字符。 想来是比较简单的，因为可以直接申请一个string，读到字母就往里头append，读到数字就复制几遍，然后最后按索引输出结果字符就行了。先试试。 果然有坑！ 1234567891011121314151617181920class Solution &#123;public: string decodeAtIndex(string S, int K) &#123; string contain = \"\"; for (int i = 0; i &lt; S.length(); i++)&#123; if(S[i] &gt; '1' &amp;&amp; S[i] &lt;= '9')&#123; for(int j = 1; j &lt; S[i] - '0'; j++)&#123; contain += contain; &#125; &#125; else&#123; contain.append(1, S[i]); &#125; &#125; stringstream ss; ss &lt;&lt; contain[K - 1]; string res = ss.str(); return res; &#125;&#125;; 1234Input: S = &quot;a2345678999999999999999&quot;, K = 1Output: &quot;a&quot;Explanation: The decoded string is &quot;a&quot; repeated 8301530446056247680 times. The 1st letter is &quot;a&quot;. 内存会不够的！！ 得另外确定一个思路，可以考虑一下在复制过程中，直接输出K处的结果。 emmm 不需要复制字符串，不然内存占用太大了。。 可以先确定解码后的字符串长度。 然后再反向遍历初始字符串，然后对解码后的字符串长度进行缩短。知道缩短至长度为K时，输出字符。 太妙了！（不是我写的，逃。。 123456789101112131415161718192021222324252627class Solution &#123;public: string decodeAtIndex(string S, int K) &#123; long size = 0; int N = S.size(); // Find size = length of decoded string for (int i = 0; i &lt; N; ++i) &#123; if (isdigit(S[i])) size *= S[i] - '0'; else size++; &#125; for (int i = N-1; i &gt;=0; --i) &#123; K %= size; if (K == 0 &amp;&amp; isalpha(S[i])) return (string) \"\" + S[i]; if (isdigit(S[i])) size /= S[i] - '0'; else size--; &#125; return S; &#125;&#125;;","tags":[{"name":"C++","slug":"C","permalink":"https://joshuaqyh.github.io/tags/C/"},{"name":"Leetcode","slug":"Leetcode","permalink":"https://joshuaqyh.github.io/tags/Leetcode/"}]},{"title":"软件工程 | 正确性要素 on SDLC","date":"2019-03-27T13:47:37.000Z","path":"2019/03/27/软件工程-正确性要素-on-SDLC/","text":"题目要求选择一个测试要素，以你做过的一个软件作品为例，分别讨论该要素在软件生命周期的需求，设计，编程，测试，安装和维护各阶段的测试目标和内容。 回答以我上学期做过的区块链DAPP课程项目 MyTrello (基于以太坊的去中心化日程管理 Web 应用)为例（主要涉及了两大核心的功能：团队人员管理和任务驱动协作）， 我选择 正确性测试要素进行讨论。该要素在软件生命周期的各个阶段的测试目标和内容总结如下。 需求阶段事件：定义产品的功能规格说明。 目标： 保证需求分析的正确性以及充分性。具体来讲其目标是保证需求正确反应用户的需要，需求被定义和文档化。 内容： 检查需求分析所定义的功能是否反映用户需求。即认真审视以团队为单元，以任务流为驱动，以以太坊智能合约技术为基础的去中心化 web app 的正确性。 测试需求是否已经被明确定义，以及输出合理规范的需求文档。 即是否产出作为一个团队日程管理所具备的核心功能的需求规格说明书。 检测产品需求功能是否满足课程要求。 设计阶段事件：设计符合需求。 目标： 对设计阶段产出的文档和架构说明进行评审；当需求分析发生改变时，测试要对修改的部分进行检查，确保设计与需求保持一致。 内容： 评估技术选型和架构是否有满足需求。分析选用 solidity 语言编写智能合约是否可靠，使用 solc 编译合约是否合理，使用web.js 来部署调用合约是否妥当，使用react作为前端框架是否足够高效等等。 评审设计阶段产出的文档，在功能设计上是否符合需求规格。即对比需求文档，从本项目中的团队管理和任务流驱动的两个核心功能出发，检查设计的接口是否符合需求，评审设计文档中是否存在着对需求遗漏缺失，理解认知错误的地方，有则修正设计文档。 编程阶段事件：程序符合设计。 目标： 检测编码是否与设计一致，是否正确地实现系统功能需求，编码是否正确地按照既有的标准进行。 内容： 测试编码是否与设计文档定义一致，包括模块化，接口定义，界面设计。即检查智能合约中的接口功能是否与设计文档保持一致，编译、部署、调用合约是否按照设计文档中的规范进行。若未一致，则结合设计文档对现有代码进行修正。 测试程序的能否正确运行。使用黑盒、白盒测试对本日程管理应用的每个单元模块进行测试。 测试阶段事件： 功能测试。 目标：进行第三方的正式确认测试，检验所开发的系统是否按照用户提出的要求运行。 内容： 在一个新的应用系统来进行测试，运行部分或全部系统，确认用户需求被满足。按照用户规定的需求来测试应用功能，检查应用是否能正常连接以太坊公有测试网络，是否能正常完成团队管理和任务管理这两大功能，确认产品功能是否正确满足了用户的需求。若未能正确满足，则重新检查修改，以匹配需求。 安装阶段事件：正确的程序和数据防入产品。 目标： 保证被测试系统不存在问题，注重对程序安装的正确性和完整性进行核对。 内容： 对程序安装的正确性进行核对。按照系统安装说明手册的步骤进行，确定好测试环境（win10 nodejs metamask ），借助npm 包管理器安装好软件相应的包和环境依赖。使用命令运行项目，在浏览器查看项目的安装情况。若失败，则要寻求相应的解决方案。 维护阶段事件：修改需求 目标：根据软件实际运行情况以及用户的反馈对软件功能或需求进行适当的修正。 内容： 经过多次的使用，对项目一些细节有了新的需求。比如在本日程管理项目中增加事件通知，任务历史记录功能，赋予更加简洁灵活的任务交互操作，修改冗余的功能。","tags":[{"name":"软件工程","slug":"软件工程","permalink":"https://joshuaqyh.github.io/tags/软件工程/"},{"name":"软件测试","slug":"软件测试","permalink":"https://joshuaqyh.github.io/tags/软件测试/"}]},{"title":"软件测试 | 敏捷宣言四-风险评估","date":"2019-03-27T12:38:27.000Z","path":"2019/03/27/软件测试-敏捷宣言四-风险评估/","text":"题目在敏捷宣言遵循的12条原则中，挑选一条你最感兴趣的原则进行风险评估。 风险评估在12条原则中，我选择进行阐释的原则是第4条，即： 在整个项目过程中，业务人员和开发人员每天在一起工作。 以下是个人评估过程，所阐述的原则简称原则4。 关于风险。敏捷开发中主要存在着四个维度的风险：分别是人员风险、技术风险，产品风险和过程风险。它们相互联系和同一，决定了软件开发的效率。而其中与原则4相关联的风险就是人员风险。 首先必须明确人员风险是什么。人员风险主要有：团队成员沟通不畅，对业务不理解，不熟悉，缺乏高效协作；人员变动频繁，缺乏激励，工作氛围低下；成员道德素质、能力素质低下；成员之间存在潜在的矛盾和冲突；缺乏客户介入等。这些风险对团队都具有一定的破坏性，可以通过调整工作模式，工作顺序来进行一定程度上的规避和预防。 原则4对人员风险的具有一定的规避作用。在原则4中，它强调的是业务人员和开发人员必须紧密结合，保持高效顺畅的沟通。在项目的整个流程中，开发和业务人员每天一起工作，保证业务和开发工作进度的有效控制和跟踪。由于业务人员和开发人员空间和交流成本的降低，可通过频繁沟通，短会议，及时反馈的方式来解决沟通不畅，缺乏协作的问题。业务人员可以在第一时间识别新的业务需求并快速传达给开发人员，通知制定相应的架构编码任务并实施，而开发人员也可以在第一时间提交业务反馈和业务代码变更的需求，业务人员也可以快速响应开发人员的请求，迅速实现业务的动态灵活调整。 在高效的协作和响应的敏捷开发工作模式下，团队成员沟通不畅的问题得到有效解决，业务人员能够快速摸清产品的真实需求并制定相应的业务策略，而开发人员能更好的识别业务需求，实现敏捷开发，一定程度避免开发进度过慢甚至失败的局面。","tags":[{"name":"软件工程","slug":"软件工程","permalink":"https://joshuaqyh.github.io/tags/软件工程/"}]},{"title":"数据结构 | 字符串string 学习","date":"2019-03-26T14:16:17.000Z","path":"2019/03/26/数据结构-字符串string-学习/","text":"本文内容来自中国大学MOOC上北京大学的数据结构与算法的公开课。 主要从字符串string相关编码方面进行笔记的梳理，涉及： 字符串常见操作实现 字符串的运算算法实现 字符串的快速模式匹配 （KMP） 字符串的存储和常见操作实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091// 求字符串的长度int strlen(char d [])&#123; int i = 0; while(d[i] != '\\0')&#123; i++; &#125; return i;&#125;// 字符串的拷贝操作char *strcpy(char *d, char *s)&#123; int i = 0; while(s[i] != '\\0')&#123; i++; d[i] = s[i]; &#125; d[i] = '\\0'; return d;&#125;// 字符串的比较int strcmp(const char *s1, const char *s2)&#123; int i = 0; for(i = 0; s1[i] == s2[i]; i++)&#123; if(s1[i] == s2[i] &amp;&amp; s1[i] == '\\0') return 0; &#125; return (s1[i] - s2[i]) / abs(s1[i] - s2[i]);&#125;class String&#123;private: char* str; int size;public: String(char *str)&#123; size = strlen(str); str = new char[size + 1]; assert(str != NULL); strcpy(this-&gt;str, str); &#125; ~String()&#123; delete [] str; str = NULL; &#125; int size()&#123; return size; &#125; char* c_str()&#123; return str; &#125; String operator=(String &amp;s)&#123; if(str != s.size())&#123; delete []str; str = new char[s.size() + 1]; assert(str != NULL); size = s.size(); &#125; strcpy(str, s.c_str());\\ return *this; &#125; String substring(int start, int num)&#123; assert(start &gt;= 0 &amp;&amp; start + num - 1&lt; size); char * newstr = new char[num + 1]; int i = 0; while(i != num)&#123; newstr[i] = str[start + i]; i++; &#125; newstr[i] = '\\0'; return String(newstr); &#125; void reverse()&#123; int start = 0; int end = size - 1; while(start != end)&#123; int tmp = str[start] - str[end]; if(tmp &gt; 0)&#123; str[start] = str[start] - tmp; str[end] = str[end] + tmp; &#125; else if(tmp &lt; 0)&#123; str[end] = str[end] - tmp; str[start] = str[start] + tmp; &#125; end--; start++; &#125; &#125;&#125; 字符串的模式匹配朴素模式匹配法（穷举法）字符串匹配就是给定一个字符串，想要判断一下在该字符串中是否存在有一个子串，有则返回第一个匹配字符的下标，否则返回-1 12345678910int fidPat_3(string T, string P, int startIndex)&#123; for(int g = startIndex; g &lt;= T.length() - P.length(); g++)&#123; for(int j = 0; (j &lt; P.length() &amp;&amp; P[j] == T[g + j]); j++)&#123; if(j == P.length()-1)&#123; return g; &#125; &#125; &#125; return -1;&#125; 该算法最坏情况下的复杂度是 O(m × n), m 为长串的长度，n为短串的长度。 快速模式KMP算法 KMP算法就是在朴素匹配算法的基础之上，对每次滑动的位数 n 进行了提前的计算，减少了不要的冗余计算。 而这个滑动的位数计算的思想就是先建立一个关于模式串P中每一个字符的特征向量表。 其中next数组就是所谓的特征向量表。当 j ！= 0 时，向量元素值的含义就是在模式串本身的从0到 j - 1的子串中，首尾的的连续等长子串相等时的最大长度值k。 这样当模式串的第 j + 1个元素匹配错误的时候，我们就可以直接确定下一步滑动的位数为 j - k 位。 理由是模式串首部的前k个字符和模式串的 【j - k ： j 】的子串相匹配，下一次匹配时，可以用首部的串代替尾部的子串，然后减少比较次数。 123456789101112131415161718192021int KMPMatching(string T, string P, int *N, int start)&#123; // N 为特征向量 int j = 0; // 模式串P的比较位置 int i = start; // 目标串的比较位置 int plen = P.length(); int tlen = T.length(); if(tlen - start &lt; plen) return -1; while(j &lt; plen &amp;&amp; i &lt; tlen)&#123; if(j == -1 || T[i] == P[j])&#123; i++; // 如果两个比较位置相同，那么位置都递增 j++; &#125; else&#123; // 模式串在位置 j 发生了不匹配 j = N[j]; // 模式串的比较位置需要更新为特征向量的值 &#125; &#125; if(j &gt;= plen)&#123; //匹配成功，返回匹配子串的起始位置 return (i - plen); &#125; return -1;&#125; 123456789101112131415161718192021int* fineNext(string P)&#123; int j, k; int m = P.length(); assert(m &gt; 0); int *next = new int[n]; assert(next != NULL); next[0] = -1; j = 0; k = -1; while(j &lt; m - 1)&#123; while(k &gt; 0 &amp;&amp; P[k] != P[j])&#123; k = next[k]; &#125; j++; k++; next[j] = k; // 进行优化 if (P[k] == P[j])&#123; next[j] = next[k]; &#125; else next[j] = k; &#125; return next;&#125;","tags":[{"name":"C++","slug":"C","permalink":"https://joshuaqyh.github.io/tags/C/"},{"name":"数据结构","slug":"数据结构","permalink":"https://joshuaqyh.github.io/tags/数据结构/"}]},{"title":"Leetcode | Practice 6","date":"2019-03-26T13:21:05.000Z","path":"2019/03/26/Leetcode-Practice-6/","text":"这题目看起来是真的有点迷，中级题目。 给一个从1到N的数组，对该数组进行重构，使之符合以下两条规则： 第i个数能够被i整除 i能够被第i个整除 我们需要返回能够符合以上两条规则之一或者同时满足的数组的个数。0 &lt; N &lt;= 15 怎么说好呢，一个数组升序都是满足的。 emmmm 完全没有思路啊，，我看来得去看看MOOC上浙大的数据结构和北大的算法课。。 貌似可以用回溯，，回溯在大一时简直就是噩梦，都没有听懂。。。。 看了大佬的回溯算法，简直有点迷，递归回溯算法。。我先贴个码吧，我先去刷了慕课了。。 应该是用了递归深度搜索方法，仔细看看真的好妙 啊。 我还是多看看课程吧，算法渣。。 123456789101112131415161718192021222324class Solution&#123;public: int coutArrangement(int N)&#123; int ans = 0; visited = vector&lt;int&gt;(N + 1, 0); dfs(N, &amp;ans, 1); // 第 1 个数开始搜索 return ans; &#125; private: vector&lt;int&gt; visited; void dfs(int n, int *ans, int pos)&#123; if(pos &gt; n)&#123; (*ans)++; // 找到了一个符合的数组 &#125; int i = 0; for(int i = 1; i &lt;= n; i++)&#123; if(!visited[i] &amp;&amp; (i % pos == 0 || pos % i == 0))&#123; visited[i] = 1; // 在深度搜索的时候，该位置无法被访问 dfs(n, ans, pos + 1); visited[i] = 0; // 深层的深度搜索结束了，该位置恢复访问。。 &#125; &#125; &#125;&#125;","tags":[{"name":"C++","slug":"C","permalink":"https://joshuaqyh.github.io/tags/C/"},{"name":"Leetcode","slug":"Leetcode","permalink":"https://joshuaqyh.github.io/tags/Leetcode/"}]},{"title":"Leetcode | Practice 5","date":"2019-03-26T12:36:05.000Z","path":"2019/03/26/Leetcode-Practice-5/","text":"选一道easy的题来解解闷。。。 找出数组中的两个数之和等于target。。 思路： 两重遍历。不过由于数组是升序的，在第一层遍历开始前，先判断一下当前元素和结尾元素之和能否大于等于目标值，如果不行则continue 给定收尾索引，判断对应位置之和和target的关系。如果相等，则返回，如果大于target，则尾索引变小，如果小于target，则头索引变大。 思路一实现： 时间复杂度 O(n^2) 12345678910111213141516171819202122232425class Solution &#123;public: vector&lt;int&gt; twoSum(vector&lt;int&gt;&amp; numbers, int target) &#123; vector&lt;int&gt; result; //int smallest = numbers[0]; int biggest = numbers[numbers.size() - 1]; for(int i = 0; i &lt; numbers.size() - 1; i++)&#123; if(biggest + numbers[i] &lt; target)&#123; continue; &#125; for(int j = i + 1; j &lt; numbers.size(); j++)&#123; if(numbers[i] + numbers[j] == target)&#123; result.push_back(i + 1); result.push_back(j + 1); break; &#125; &#125; if(result.size() == 2)&#123; break; &#125; &#125; return result; &#125;&#125;; 1234567891011121314151617181920212223class Solution &#123;public: vector&lt;int&gt; twoSum(vector&lt;int&gt;&amp; numbers, int target) &#123; vector&lt;int&gt; result; int i = 0; int j = numbers.size() - 1; while(i &lt; j)&#123; int sum = numbers[i] + numbers[j]; if(sum == target)&#123; result.push_back(i + 1); result.push_back(j + 1); break; &#125; else if(sum &lt; target)&#123; i++; &#125; else&#123; j --; &#125; &#125; return result; &#125;&#125;;","tags":[{"name":"C++","slug":"C","permalink":"https://joshuaqyh.github.io/tags/C/"},{"name":"Leetcode","slug":"Leetcode","permalink":"https://joshuaqyh.github.io/tags/Leetcode/"}]},{"title":"Leetcode | Practice 4","date":"2019-03-26T02:16:19.000Z","path":"2019/03/26/Leetcode-Practice-4/","text":"Find K Pairs with Smallest Sums给定两个升序整数数组nums1 nums2以及一个整数k。 定义一个数对，一个元素来自nums1 一个来自nums2。 目的是返回k个数对，这些数对的内部元素之和升序存放。 例子如下： 1234Input: nums1 = [1,7,11], nums2 = [2,4,6], k = 3Output: [[1,2],[1,4],[1,6]] Explanation: The first 3 pairs are returned from the sequence: [1,2],[1,4],[1,6],[7,2],[7,4],[11,2],[7,6],[11,4],[11,6] 解题思路： 初级思路：求出每一个对，然后再找出前K大的对，返回。 缺点：时空复杂度都太高。求出每一个对时间复杂度为 $O(m^2)$，找出前K大的对时间复杂度为$O(mlogm)$ 。 中级思路：使用map容器进行选择。以数对之和为键, 数对数组为值（可能有，map会自动排序，然后输出前k个对。。这种做法结果证明时空占用都挺大的。。 看看大佬们的分享。使用优先队列来搞，比较快的样子。 …. 最简单的做法， 使用map键的自动排序特性。这个内部实现肯定比直接使用现有高效的排序方式来的慢。。。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748#include&lt;map&gt;#include&lt;vector&gt;#include&lt;iostream&gt;using namespace std;class Solution &#123;public: vector&lt;pair&lt;int, int&gt;&gt; kSmallestPairs(vector&lt;int&gt;&amp; nums1, vector&lt;int&gt;&amp; nums2, int k) &#123; map&lt;int, vector&lt;pair&lt;int, int&gt;&gt;&gt; _map; for (auto iter1 = nums1.begin(); iter1 != nums1.end(); iter1++) &#123; for (auto iter2 = nums2.begin(); iter2 != nums2.end(); iter2++) &#123; int sum = *iter1 + *iter2; _map[sum].push_back(make_pair(*iter1, *iter2)); &#125; &#125; int num = 0; vector&lt;pair&lt;int, int&gt;&gt; res; for (auto it = _map.begin(); it != _map.end(); it++) &#123; for (auto vec = it-&gt;second.begin(); vec != it-&gt;second.end(); vec++) &#123; res.push_back(*vec); num++; if (num == k) return res; &#125; if (num == k) return res; &#125; return res; &#125;&#125;;int main() &#123; Solution s; int arr1[3] = &#123; 1, 7, 13 &#125;; int arr2[3] = &#123; 2, 4, 8 &#125;; vector&lt;int&gt; nums1; vector&lt;int&gt; nums2; for (int i = 0; i &lt; 3; i++) &#123; nums1.push_back(arr1[i]); nums2.push_back(arr2[i]); &#125; vector&lt;pair&lt;int, int&gt;&gt; res = s.kSmallestPairs(nums1, nums2, 3); for (int i = 0; i &lt; res.size(); i++) &#123; cout &lt;&lt; res[i].first &lt;&lt; \" \" &lt;&lt; res[i].second &lt;&lt; endl; &#125; system(\"pause\");&#125; 12345678910111213141516171819202122232425262728293031323334class Solution &#123;public: vector&lt;pair&lt;int, int&gt;&gt; kSmallestPairs(vector&lt;int&gt;&amp; nums1, vector&lt;int&gt;&amp; nums2, int k) &#123; if (nums1.empty() || nums2.empty() || k == 0) &#123; return &#123;&#125;; &#125; vector&lt;pair&lt;int, int&gt;&gt; result; result.reserve(k); // 定义排序方式 auto cmp = [&amp;nums1, &amp;nums2](const pair&lt;int, int&gt;&amp; p1, const pair&lt;int, int&gt;&amp; p2) &#123; return nums1[p1.first] + nums2[p1.second] &gt; nums1[p2.first] + nums2[p2.second]; &#125;; // 第一个元素是pair对，第二个元素是pair数组，保证某些和相同的对在同一位置 priority_queue&lt;pair&lt;int, int&gt;, vector&lt;pair&lt;int, int&gt;&gt;, decltype(cmp)&gt; q(cmp); // ？？？先放数组一的第一个元素进优先队列 for (int i = 0; i &lt; nums1.size(); ++i) &#123; q.push(make_pair(i, 0)); &#125; // 利用优先队列来筛选目标 while (k-- &gt; 0 &amp;&amp; !q.empty()) &#123; // 返回队首，由于优先特性，返回的是最小的对 auto minPair = q.top(); q.pop(); if (minPair.second + 1 &lt; nums2.size()) &#123; q.push(make_pair(minPair.first, minPair.second + 1)); &#125; // 数组尾部替换为新筛选得到的最小对 result.emplace_back(nums1[minPair.first], nums2[minPair.second]); &#125; return result; &#125;&#125;;","tags":[{"name":"C++","slug":"C","permalink":"https://joshuaqyh.github.io/tags/C/"},{"name":"Leetcode","slug":"Leetcode","permalink":"https://joshuaqyh.github.io/tags/Leetcode/"}]},{"title":"深度学习 | StarGAN - paper summary","date":"2019-03-25T16:31:38.000Z","path":"2019/03/26/深度学习-StarGAN-paper-summary/","text":"StarGAN: Unified Generative Adversarial Networks for Multi-Domain Image-to-Image TranslationSummaryAlthough many GAN models show amazing performance in image-to-image translation tasks in recent studies, there are lots of limitations in scalability, robustness,efficiency and so on. Aimed at developing a more effective GAN model in image translation task, StarGAN is introduced to solve the problem that existing models are incapable of the implementation of multi-domain image translation among different datasets by using a single network. The StarGAN framework can learn mappings among multiple domains using a single generator and discriminator and behaves more effective than current similar models in the training phase. However, the other models cannot jointly train domains from various datasets, and if they want to learn all mappings within k domains, k(k-1) generators have to be trained, which is inefficient and ineffective. The StarGAN model structure consists of two modules, including a generator and a discriminator. The working principle of StarGAN is to train a generator G that learns mappings among different domains and a discriminator D that distinguish between real and fake images and classify real images to its corresponding real domain. Basically, StarGAN adopts two generators (G1, G2) for generating near-true fake images to fool the discriminator, causing the discriminator to be unable to distinguish the authenticity of the images and classify the pictures as the target domain. The input of G1is an image and the target domain label, and then its output is a fake image. Furthermore, G2 tries to take in as input both fake image from the output of G1 and original domain under the depth-wise concatenation and reconstructs an image as the output that will be treated as the input image of G1.Therefore, a near-true fake image is generated after many generating cycles and inputs the discriminator for judgment. Toachieve the goal to train a single generator G that learns mappings among multiple domains, G is trained to translate an input image x into an output image yconditioned on the randomly generated target domain label c, G (x, c) → y.Meanwhile, an auxiliary classifier is introduced to permit a singlediscriminator to control multiple domains. The discriminator will produceprobability distributions over both sources and domain labels. That is D: x→{Dsrc(x), Dcls(x)}.Dsrc(x) means the probability distributionover sources given by D. The authorsdefine an adversarial loss to measure how easily the generated image iscorrectly distinguished: Basedon the generated and adversarial characteristics, the generator will try tominimize the above objective, while the discriminator will try to maximize it.The loss function of the aforementioned auxiliary classifier can divide intotwo situations to discuss which is to classify real images and fake images tothe target domain c, defined as: Toguarantee that translated images preserve the content of its input images whilechanging only the domain-related part of the inputs, a cycle consistency lossapplies to the generator, represented as: Insummary, the loss function of the full objective to optimize D and G is designed as follows: Thehyperparameter λcls, λrec is used to control therelative importance of domain classification and reconstruction loss. Both D and G will try to minimize the above full objective during the trainingprocessing. Animportant advantage and novel aspect of StarGAN is that it can utilize severaldatasets with different types of labels while all existing models only can betrained with a single dataset. To alleviate the problem that label informationis partially known to each dataset, the authors introduce a method named maskvector m to ignore unspecified labelsand focus on the explicitly known label provided by a particular dataset. Themask vector m is represented by ann-dimensional one-hot vector, where n stands for the number of datasets.Therefore, a unified version of the label is made as a vector c(~): Where ci represents the label of ith dataset. So it solves theproblem of the inconsistent labels on multiple datasets and inability to sharethe label and transfer the feature. When training StarGAN with multipledatasets, the domain label c(~) is applied and the model isto be trained in a multi-task learning setting, where the discriminator triesto minimize only the classification error associated to the known label. Beforestarting to implement the model, we should understand the internal constructionof the generator and discriminator. The generator network structure of StarGANis modified and adapted from CycleGAN, composing of two convolutional layerswith the stride size of two for downsampling, six residual blocks, and twotransposed convolutional layers with the stride size of two for upsampling.Moreover, it applies the instance normalization method for the generator butnot for the discriminator. Adapted from PatchGANs, the discriminator isdesigned to classify whether the local image patches are real or fake. The twodatasets CelebA and RaFD are used to train and test StarGAN, and try to makethe comparison between StarGAN and some baseline models like DIAT, cycleGAN,and IcGAN, finding the advantage and strength of StarGAN. The qualitativeresults on CelebA show a higher visual quality and preserve the facial identityfeature of an input. Moreover, quantitative result reflects that StarGANobtained the majority of votes for best transferring attributes in all cases.As for the result on RaFD, StarGAN is capable of generating the mostnatural-looking expressions and preserve the personal identity and facialfeatures of the input. Furthermore, the model gets the lowest classificationerror, meaning producing the most realistic facial expression. Also, theparameters required of the model is less than other models, enhancing thescalability of the model. When training model jointly on CelebA and RaFD, ithas confirmed that StarGAN can properly learn features in a dataset andtransfer them to another dataset by using a proper mask vector, achievingexcellent results on image-to-image cross-domain translation. Due tothe limited number of test datasets used in the experiment, it is almost notpossible to verify whether the StarGAN model is universal or not. Anotherunfortunate fact is that some properties outside the target domain arefrequently modified. For instance, face attributes would be easily modifiedwhen executing the synthetic facial expression task. For further development ofthis model, we assume that the model will develop towards more accurate andfine-grained target domain generation, and meanwhile ensure the stability of non-targetdomain attributes. However, it also is worthy of recognition that this modelhas achieved relatively excellent improvement and progress on the efficiencyand quality of the image-to-image translation. In particular, the beginning oftraining models with multiple different datasets with various labels created.It is valuable work to enable more researchers to explore and develop excellentimage translation applications across multiple domains. Appendix[1] StarGAN: Unified Generative Adversarial Networks forMulti-Domain Image-to-Image Translation Yunjey Choi 1,2, Minje Choi 1,2, MunyoungKim 2,3, Jung-Woo Ha 2, Sung Kim 2,4, and JaegulChoo 1,2 1 Korea University, 2 Clova AI Research (NAVER Corp.), 3 The College of NewJersey, 4 HKUST IEEEConference on Computer Vision and Pattern Recognition (CVPR), 2018 (Oral) [2] The code of this paper is open in Github. [3] Z. Liu, P. Luo, X. Wang,and X. Tang. Deep learning face attributes in the wild. In Proceedings of the IEEE International Conference on Computer Vision(ICCV), 2015. [4] O. Langner, R. Dotsch, G.Bijlstra, D. H. Wigboldus, S. T. Hawk, and A. Van Knippenberg. Presentation andvalidation of the radboud faces database. Cognitionand Emotion, 24(8):1377–1388, 2010. [5] Facial Attribute Transferon CelebA [6] Facial ExpressionSynthesis on RaFD","tags":[{"name":"深度学习","slug":"深度学习","permalink":"https://joshuaqyh.github.io/tags/深度学习/"},{"name":"Paper","slug":"Paper","permalink":"https://joshuaqyh.github.io/tags/Paper/"}]},{"title":"机器学习 | 支持向量机学习笔记","date":"2019-03-25T08:54:42.000Z","path":"2019/03/25/机器学习-支持向量机学习笔记/","text":"SVM原理假设有两类样本，类别分别为 - 1， 1。空间中存在一个超平面能够划分这两类样本。 求解SVM 梳理一下过程就是： 我们记初始的目标优化函数为 f(w)。 求 min f(w)。 但是这个 min f(w) 真的不太好求，所以我们引入拉格朗日乘子 a，构造了一个拉格朗日函数 L(w, b, a)。 根据KKT条件可得，当 f(w) = max L(w, b, a); 所以有 min f(w) = min max L(w, b, a) 但因为是凸规划问题，不太好求 max L，所以我们把问题转化为 min f(w) = min max L(w, b, a) &gt;= max min L(w, b, a)。 所以我们对 w b 求偏导，令其等于0，然后代入L(w, b, a) 得到 min L(w, b, a)： 记上述式子为 g (a) = min L(w, b, a)。 于是问题转化为 min f(x) = max g(a)。 所以我们求解 max g(a)，得到 a，然后代入超平面方程得到关于 a， b的模型方程。 至于 a 我们使用 SMO算法来求解。 而位移项，我们可以通过支持向量的平均值来计算。 核函数引入核函数的作用就是将一些低维空间的数据映射到高维空间，使之在高维空间中得以找到一个超平面进行划分，解决一些样本在低维空间的线性不可分的问题 软间隔软间隔的意思就是允许一些样本不满足到超平面的距离大于等于1的约束。 引入了软间隔，我们需要重新修改优化的目标函数。 当然我们需要保证我们最大间隔的约束性质，同时允许一些样本不受约束。建模如公式6.29. 同样的求解思路是引入拉格朗日乘子，不过这次是引入了两个乘子。 上述比较显得较为潦草，碍于个人时间有限，有些地方表达可能不太严谨，但已经大致的描述了SVM的相关概念和原理。 更为详细的博文请戳这里。支持向量机通俗导论（理解SVM的三层境界）","tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://joshuaqyh.github.io/tags/机器学习/"}]},{"title":"软件工程 | 系分作业二","date":"2019-03-24T12:17:58.000Z","path":"2019/03/24/软件工程-系分作业二/","text":"16340186 邱奕浩 电子政务方向 一、 简答题 用简短的语言给出对分析，设计的理解。 分析强调的是对问题和需求和调查研究，而不是解决方案。其含义较为广泛，如市场分析，需求分析，面向对象分析等等。 设计强调的是满足需求上的解决方案，但不涉及其实现，设计通常不会涉及较为底层细节的描述，更多是描述宏观的事物和策略。 简单来说分析就是做正确的事，设计就是正确地去做事。（来自教材《UML和模式应用》P5）、 ​ 用一句话描述面向对象分析与设计的优势。 OOA／D的优势在于能够满足复杂软件功能的分析，设计与实现，同时又有有利于团队成员理解项目和产品的迭代更新。 ​ 简述 UML（统一建模语言）的作用。考试考哪些图？ UML是描述，构造和文档化系统制品的可视化语言，是图形化表示法的事实标准，主要用来绘制和展示 与软件（尤其是OO软件）相关的图形和文字，能够形象直观的表达面向对象软件设计中各个部分的逻辑和关联，帮助软件开发人员更好的理解项目设计。 考试考的图有：用例图、静态图、行为图、实现图 从软件本质的角度，解释软件范围（需求）控制的可行性。 软件的本质特性是复杂性，不可视性，不一致性，可变性。软件范围多数情况下对于客户和开发人员都是相对模糊的，软件的需求设计并不是一开始就能完全确定下来，在后续的开发、测试、运维阶段都会发生一定的变化，并进行不断地迭代更新，不断满足用户日新月异的需求点。 而根据著名的 ２／８ 法则，产品初期发展只需要 ２０％ 的有效核心需求就足以打开市场的大门，后续再进一步扩大软件范围，不断地跟进满足需求，不断完善用户服务和体验，依旧可以创造有价值的软件产品。 ​ 二、项目管理实践 看板使用练习（提交看板执行结果贴图，建议使用 Git project） 使用截图工具（ png 格式输出），展现你团队的任务 Kanban 每个人的任务是明确的。必须一周后可以看到具体结果 每个人的任务是1-2项 至少包含一个团队活动任务 ​ UML 绘图工具练习（提交贴图，必须使用 UMLet） 请在 参考书2 或 教材 中选择一个类图（给出参考书页码图号）","tags":[{"name":"软件工程","slug":"软件工程","permalink":"https://joshuaqyh.github.io/tags/软件工程/"}]},{"title":"Leetcode | Practice 3","date":"2019-03-17T17:46:35.000Z","path":"2019/03/18/leetcode-practice-3/","text":"本次题目来自链接 题目大意是： 给出一个数组，相当于一堆卡牌，每个元素相当于一张牌，每次从卡牌中抽出一张牌，离开牌堆后，下一张牌需要放在牌底。在这种规则下，我们需要确定牌的顺序，来保证这些牌的抽走顺序是升序的。 代码虽然不难，但是思路必须抓得清，我们很容易被把牌塞回牌底这一动作迷惑，其实我们可以把它看作是跳过这一张牌，将其留在原来的位置，然后抽取下一张牌。我们需要做的就是给升序后的数组的每一个元素确定其相应的索引位置。 整体思路是这样子的： 我们定义一个同样大小的数组result，初始化为0，用于存放结果； 将待处理的数组进行升序处理得到deck（deck中的元素都是大于0的）； 设置一个全局的放置标志 put = true 和一个全局索引数 i = 0 遍历deck中的每一个元素，找出这一个元素在新数组中的位置： 我们确保索引数是循环移动的 当找到一个位置 i的值为0 &amp; put = true的时候，就完成元素的放置 当 i 完成放置之后，下一个元素在下一个位置 i + 1就不能放置，所以 put = false，当索引 i = i+ 1时，就会跳过该位置，在这一回中 put = true，保证下一回合能够放置。 下一个元素必须在 i + 2个放置，在 i + 1的时候，需要令 put = true，完成放置，即重复2~3。 emmmm 还是有点乱，看代码吧。 1234567891011121314151617181920vector&lt;int&gt; deckRevealedIncreasing(vector&lt;int&gt; &amp; deck)&#123; vector&lt;int&gt; result(deck.size(), 0); sort(deck.begin(), deck.end()); bool put = true; int i = 0; for auto val : deck: for (;;i++)&#123; if(i == deck.size()) i = 0; if(result[i] == 0)&#123; if(put == true)&#123; result[i] = val; put = false; break; &#125; put = true; &#125; &#125; return result;&#125;","tags":[{"name":"C++","slug":"C","permalink":"https://joshuaqyh.github.io/tags/C/"},{"name":"algorithm","slug":"algorithm","permalink":"https://joshuaqyh.github.io/tags/algorithm/"},{"name":"Leetcode","slug":"Leetcode","permalink":"https://joshuaqyh.github.io/tags/Leetcode/"}]},{"title":"深度学习-训练中存在的问题和策略","date":"2019-03-14T08:23:24.000Z","path":"2019/03/14/深度学习-训练中存在的问题/","text":"梯度爆炸和消失在求解梯度时，通过链式法则可以使用多个中间梯度来表示初始梯度，在多层网络中，如果多个中间梯度都大于1，那么最后计算得到的梯度将远大于一，故存在梯度爆炸； 如果许多中间梯度都大于1，那么最后计算的到梯度将近乎0，故存在梯度消失。 由于梯度爆炸的存在，训练过程相当不稳定。我们需要保证，激活函数的导数或权重的绝对值小于等于1。 解决梯度爆炸的策略有： 初始化权重值的绝对值小于1 在训练前对权重进行标准化 对输入进行归一化 梯度消失将会使训练相当慢，我们必须使激活函数倒数*权重的绝对值不要太小，解决的策略有： 选择ReLU激活函数 权重初始化，$w - N(0, \\sigma^2)$ 权重在训练前重新标准化 简单来说，在开始训练之前，网络权重初始化的策略是，从由输出维数n和m决定的正态分布或者均匀分布中采样，会加快网络的训练过程。 当激活函数是tanh时（Weight initialization: Xavier’s method） 当激活函数是ReLU时（Kaiming He 大神） 55255515524 Mini-batch 的问题问题：每一批的数据分布不一致。 解决方法：批量归一化BN。将每一组数据都归一化为标准正态分布。（均值为0，方差为1） BN 通常放在激活函数ReLU之前。 在合理的学习率范围内，学习率越大，BN越有效。上述的$\\gamma $$,\\beta$ 作为模型的参数，一并学习。 过拟合的问题过拟合是普遍存在的，我们有以下几种策略来解决： 借助验证集来确定提前终止迭代的次数 ​ 正则化：$L_P$Norm dropout 数据增广（增强） 集成模型 ​","tags":[{"name":"深度学习","slug":"深度学习","permalink":"https://joshuaqyh.github.io/tags/深度学习/"}]},{"title":"Leetcode | Practice 2","date":"2019-03-14T08:01:08.000Z","path":"2019/03/14/Leetcode-Practice-2/","text":"Author: qyh Date: 2019-03-14 Description: Buid BT Stree from preorder tree URL:https://leetcode.com/problems/construct-binary-search-tree-from-preorder-traversal/ 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576#include &lt;iostream&gt;#include &lt;string&gt;#include &lt;vector&gt;#include &lt;queue&gt;using namespace std;/*Definition for a binary tree node.*/struct TreeNode &#123; int val; TreeNode *left; TreeNode *right; TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125;&#125;; class Solution &#123;public: /*********************** 求解思路： 其实很简单，就是简单的二叉搜索树的插入，然后输出根节点就行了，没有那么复杂。。。 ***********************/ TreeNode* bstFromPreorder(vector&lt;int&gt;&amp; preorder) &#123; if (preorder.empty()) return NULL; TreeNode* root = new TreeNode(preorder[0]); for (int i = 1; i &lt; preorder.size(); i++)&#123; insert(root, preorder[i]); &#125; return root; &#125; TreeNode* insert(TreeNode* &amp;root, int val) &#123; if (root == NULL) root = new TreeNode(val); else if (root-&gt;val &gt; val) &#123; root-&gt;left = insert(root-&gt;left, val); &#125; else &#123; root-&gt;right = insert(root-&gt;right, val); &#125; return root; &#125;&#125;;void levelOrder(TreeNode* root) &#123; if (root == NULL) return; queue&lt;TreeNode*&gt; Q; Q.push(root); while (!Q.empty()) &#123; TreeNode* tmp = Q.front(); cout &lt;&lt; tmp-&gt;val &lt;&lt; endl; Q.pop(); if (tmp-&gt;left != NULL) &#123; Q.push(tmp-&gt;left); &#125; if (tmp-&gt;right != NULL) &#123; Q.push(tmp-&gt;right); &#125; &#125;&#125;int main() &#123; vector&lt;int&gt; test; int val[6] = &#123;8, 5, 1, 7, 10, 12&#125;; for (int i = 0; i &lt; 6; i++) &#123; test.push_back(val[i]); &#125; Solution sol; TreeNode* root = sol.bstFromPreorder(test); levelOrder(root); system(\"pause\");&#125;","tags":[{"name":"C++","slug":"C","permalink":"https://joshuaqyh.github.io/tags/C/"},{"name":"algorithm","slug":"algorithm","permalink":"https://joshuaqyh.github.io/tags/algorithm/"},{"name":"Leetcode","slug":"Leetcode","permalink":"https://joshuaqyh.github.io/tags/Leetcode/"}]},{"title":"软件质量标准","date":"2019-03-08T06:29:42.000Z","path":"2019/03/08/软件工程-软件质量标准/","text":"软件质量问题定义软件质量问题是软件工程开发的关键问题，也是软件工程生产的核心问题。 软件质量问题是导致软件项目进度延误，预算超支或项目失败，项目终止等软件危机的根本原因。 意义提高软件质量可以降低项目开发的总成本： 降低维护成本并延长软件的生命期，降低软件失效导致的成本损失。 我们需要通过减少并及早检测纠正实际的软件开发过程和软件开发结果于预期不符的情况，降低错误成本。 软件质量概念现代质量管理中，质量代表着用户的满意程度。 ANSI/IEEE std729-1983： 软件质量是与软件产品满足规定和隐含的需求能力有关的特征和特性的全体。 ISO/IEC 9001-1999：软件质量是产品满足需求的能力。 软件质量的不同观点 先验论观点：质量是产品一种可以认识但不可定义的性质 用户观点：质量是产品满足使用目的的衡量指标 制造者观点：质量是产品性能和规格符合要求的符合度 产品观点：质量是联结产品固有性能的纽带 价值观点：质量依赖于顾客愿意付给产品报酬的数量 软件质量范畴 （3A） 可说明性: 用户可以给予产品的描述和定义来使用产品 有效性：产品对大多数用户是有效的 易用性/可用性：产品容易使用，并且具备有用的功能 高质量软件标准体系产品质量 过程质量控制 软件产品质量标准 功能性：软件所实现的功能达到它的设计规范和满足用户需求的程度 可用性：对于一个软件，用户学习，操作，准备输入和理解输出所付出的努力程度 可靠性：在规定的时间和条件下，软件所能达到保持其正常功能操作，性能水平的程度 性能：在指定的条件下，用软件实现某种功能所需的计算机资源的有效程度。 能力/容量：系统的接受力，容纳或吸收的能力，或某项功能的最大量或最大限度 可测量性：系统某些特性可以通过一些量化的数据指标描述当前状态或理想状态 可维护性：对于一个运行阶段的软件，当环境改变或软件发生错误时，进行相应修改所需要付出的努力程度 兼容性：不同版本之间的软件功能存在普适兼容 可扩展性：在软件功能进行迭代时，优良的可扩展性可减少无谓的工作劳动，减少对已有系统的改动，从而提高效率。 软件的质量特性的定义 软件质量层次模型","tags":[{"name":"软件工程","slug":"软件工程","permalink":"https://joshuaqyh.github.io/tags/软件工程/"}]},{"title":"深度学习模型中的优化策略","date":"2019-03-07T16:15:32.000Z","path":"2019/03/08/深度学习-模型优化策略/","text":"在深度学习中，我们通常需要优化我们所定义的损失函数，优化的方法思想就是通过梯度下降的方式不断逼近一个局部最优解，更新模型参数然后来保证损失函数预测误差最小。在本文主要综述了几种常见的优化策略，包括梯度下降的策略以及学习率变化的策略。这些策略有一些基本的概念需要重点掌握，这些策略有简单有复杂， 但是依照“没有免费午餐“的定理，在具体情景中，要具体运用比较，没有绝对的最优策略，只有相对的最优策略。 虽然在实践中我们可以直接调用深度学习框架的API来完成优化，但是要更加深入地理解其原理和过程才是一个优秀的深度学习工程师啊，面试肯定会涉及一些原理概念解释滴。下面就开始总结啦！ 批量梯度下降法 Batch gradient descent批量梯度下降法（也叫确定性梯度算法）指的是在一个大批量的数据样本中同时处理所有样本，在更新参数的时候，会同时利用所有样本的梯度变化。公式表达如下： $$\\theta_{t+1} = \\theta_{t} - \\eta \\bigtriangledown L(\\theta_t) = \\theta_t - \\frac{\\eta}{N} \\sum_{n=1}^{N}\\bigtriangledown l(y_n, f(x_n; \\theta_t))$$ 从公式上可以看到模型参数$\\theta$开始更新的时候，是当计算得到所有样本$x_n$输出预测结果$f(x_n; \\theta_t)$后得到损失函数梯度值时，进行模型参数的更新。 可以看到这整个过程的缺点就是训练慢，处理棘手，而且内存消耗大，但是可以保证找到一个最小的损失函数值。 伪代码如下： 123for iter in range(nb_epoches): params_grad = eval_grad(loss_func, dataset, params) params = params - learning_rate * params_grad 随机梯度下降法 Stochastic gradient descent随机梯度下降法简称SGD，与批量梯度下降法相比，随机梯度下降法是在每训练一个样本的时候就进行的函数模型的更新，在每次的训练迭代中，会先随机打乱训练集，然后每抽取一个样本进行训练时，就进行更新。 公式表达如下： $\\theta_{t+1} = \\theta_t - \\eta \\bigtriangledown L(\\theta_t) = \\theta_t - \\eta \\bigtriangledown l(y_n , f(x_n; \\theta_t))$ 显而易见，在处理大数据样本的时候，模型更新速度很快，但是存在收敛震荡的情况，可能会跳出局部最优解，但是也很接近局部最优解。从计算设备的角度来考虑，随机梯度下降无法做到很好的并行计算，没有很好地利用多核架构，每一次更新都得依赖前一个样本的计算。 伪代码如下： 12345for iter in range(epoches): np.random.shuffle(dataset) for example in dataset: param_grad = eval_grad(loss_func, example, params) params = params - learning_rate * params_grad 小批量梯度下降 Mini-batch gradient descent小批量梯度下降法，其实就是介于批量下降法和随机梯度下降法之间的优化方法，关键在于每次更新模型参数时，训练样本的大小。我们知道大批量的运算将会使我们的计算设备和内存不堪重负，而随机梯度下降法的中的单样本更新则无法充分使用我们的多核计算架构。我们想要达到的目的就是：既能有效的保证计算设备的良好充分使用，又能保证较短的训练时间和较好的性能 。而小批量梯度下降法就是我们比较常用的一种优化方法。 小批量的大小通常使用以下几个因素决定的： 更大的批量将计算得到更为精确的梯度估计，但是回报却是小于线性的。 极小批量将无法充分利用多核架构，这促使我们给批量设定一个最小阈值。 如果批量处理中所有样本可以并行地处理，那么内存消耗和批量大小将会呈正比，所有批量有一个上限。 小批量随机梯度下降法用数学公式表达如下： $$\\theta_{t+1} = \\theta_{t} - \\eta\\bigtriangledown L(\\theta_t) = \\theta_t - \\frac{\\eta}{S} \\sum_{(x_n, y_n) ∈S} \\bigtriangledown l(y_n, f(x_n; \\theta_t))$$ S 代表批量的大小，通常为10~300之间。 整个过程如下： 12345for i in range(nb_epochs): np.random.shuffle(dataset) for batch in get_batches(dataset, batch_size = 64): params_grad = eval_grad(loss_func, batch, params) params = params - learning_rate * params_grad 对于小批量梯度下降法来说，用小批量可以比较好的近似真实梯度，但是对学习率的自适应调整有了一定的要求。 动量 Momentum虽然SGD仍然是非常接收欢迎的优化方法，但是其学习过程有时是相当的漫长，动量方法就是为了加速学习，特别是在处理高曲率，小但一致的梯度，或者带噪声的梯度。动量算法简单来说就是在原来SGD的基础上，利用了之前所有梯度指数级衰减的移动平均，并且沿该方向继续移动。 在描述该方法的时候，引入了变量 v 来充当速度的角色，它代表参数在参数空间移动的方向和速率。数学描述如下： $v_{t+1} = \\gamma v_t + \\eta\\bigtriangledown L(\\theta_t)$ $\\theta_{t+1} = \\theta_t - v_{t+1}$ 该迭代式可以看出： $v_{t+1} = \\eta { \\bigtriangledown L(\\theta_t) + \\eta L(\\theta_{t-1}) + \\eta^2 \\bigtriangledown L(\\theta_{t-2}）+ … }$ 这种方法有效的利用了前面所有的梯度信息，可以有效的减少SGD，mini-batch的震荡，但是这种算法有时会导致跳出最优解，而且随着计算次数的增加，有些梯度信息已经几乎可以忽略不记了。 自适应梯度下降法 Adagrad自适应可以理解为学习率的自适应变化，在基础的下降法种的学习率$\\eta$ 是一个常数，在自适应法中，学习率需要除以之前所有导数的平方和的平方根。 表达式如下： $g_{t+1, i} = g_{t, i} + (\\frac{\\partial L(\\theta_t)}{\\partial \\theta_i})^2$ $\\theta_{t+1, i} = \\theta_{t, i} - \\frac{\\eta}{\\sqrt{g_{t+1, i}} + \\epsilon} \\frac{\\partial L(\\theta_t)}{\\partial \\theta_i}$ 该方法实现了学习率的自动调整，当迭代次数增加的时候，学习率将会变得极小。 RMSprop (root mean square propagation)为了解决Adagrad学习率单调递减的原因，我们对于每一个时刻的导数计算，引入了$\\gamma $来避免学习率极低的情况，是简单利用线性加权的方式来描述这一方法的： $g_{t+1, i} = \\gamma g_{t, i} + (1 - \\gamma)(\\frac{\\partial L(\\theta_t)}{\\partial \\theta_i}) ^2$ $\\theta_{t+1, i} = \\theta_{t, i} - \\frac{\\eta}{\\sqrt{g_{t+1, i} + \\epsilon}} \\frac{\\partial L(\\theta_t)}{\\partial \\theta_i}$ 一般$gamma$可以取0.9。 Adam (Adaptive moment estimation)Adam 简单来说就是在RMSProp的基础之上，添加了momentum和bias的方法，过程如下： 从上文可以看到，Adam其实是对学习率和要更新的梯度值进行了修改，学习率近似于RMSProp的方法，而梯度的修改则是参照了Momentum方法，当前的梯度信息需要依赖以往所有梯度信息的线性加权求和，权重随着迭代次数增加而减少。","tags":[{"name":"深度学习","slug":"深度学习","permalink":"https://joshuaqyh.github.io/tags/深度学习/"}]},{"title":"机器学习 | PageRank 算法和简单应用","date":"2019-03-05T08:20:08.000Z","path":"2019/03/05/机器学习-PageRank-算法和简单应用/","text":"PageRank 算法原理PageRank 算法是一种简单有效且流行的网页排序算法，它通过一个网页的所有入链数目来计算该网页的重要性（PageRank 值，简称 PR），其思想类似于一篇论文被引用的次数越大，该论文的影响力越大。 以下给出一个简单的例子，一个个网页就是互联网中的一个个节点，这些网页之间相互引用，构成一个有向图。 这里有着和算法相关的两个概念。 出链：网页链接出去的链接，相当于离散数学的图论中的出度概念； 入链：链接进来的链接，相当于入度。 简单来说，一个网页的影响力（PR值） = 该网页所有入链集合的加权影响力之和，用公式表示为： $$RP(u) = \\sum_{v ∈ B_u} \\frac{PR(v)}{L(v)}$$ 其中，u 为待评估的节点网页，$B_u$ 为所有入链到节点u的网页集合，$PR_(v)$ 为入链到u的网页影响力值，而 $L(v)$ 则是网页 v 的出链数目。 以上述图像为例子，已知一个网页出链的数目，可以计算一个网页跳转到另外一个网页的概率，由此 A，B，C，D四个网页的转移矩阵 M 假设这四个网页的初始影响力（权重） w 都是一致的，给出如下向量 w0，代表A，B，C，D初始影响力。 经过第一次转移之后，各页面计算结果如下 w1, (矩阵乘法的过程，其实就是PR公式计算了)。 由此不断产生迭代，直到第 n 次迭代之后，wn 的影响力不再发生变化，收敛的最终结果就是各网页的最终PR值。 存在两种特殊情况： １. 等级泄露：一个网站如果没有出链，只有入链，那么吸收了其他页面的影响力，但却不释放，最终会导致其他页面的PR值为０； ２. 等级沉没，如果一个网站只有出链，没有入链，多次迭代，这个网站的影响力PR将会变为０。 为了解决这两个问题，ＰａｇｅＲａｎｋ有了一个优化模型，称为随机浏览模型。 随机浏览模型 在原来模型的基础上，引入了一个阻尼因子ｄ，这个因子代表用户按照跳转链接来上网的概率，通常取一个固定值，而 1 - d 则代表了用户不是通过跳转链接来访问的网页，比如直接输入网址。其中 N代表比较网页的总数。 PageRank 算法实践首先我们需要了解如何使用 PageRank 算法以及如何用python快速构建一个图。 这里直接使用工具包，networkx，里面内置了PageRank 计算函数和建图的函数，代码如下： 123456789101112131415161718192021222324252627282930import networkx as nx# creat directed graphG = nx.DiGraph()# define the edge relationshipedges = [(\"a\", \"b\"), (\"a\", \"c\"), (\"a\", \"d\"), (\"b\", \"a\"), (\"b\", \"d\"), (\"c\", \"a\"), (\"d\", \"b\"), (\"d\", \"b\")]# add edgefor edge in edges: G.add_edge(edge[0], edge[1])# calculate pr value with the pagerankpagerank_list = nx.pagerank(G, alpha = 1)print (pagerank_list)# node operationsG.add_node('c')G.add_nodes_from(['d', 'e'])G.remove_node('d')G.remove_nodes_from(['c', 'd'])print(G.nodes())print(G.number_of_nodes())# edge operationsG.add_edge('x', 'y')print(G.edges())G.remove_edge('x', 'y')print(G.edges())print(G.number_of_edges()) 实战项目来自 Github, 主要是分析 希拉里邮件发送接收的关系网，由此来发现与希拉里关系密切的人。 代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100import pandas as pdimport networkx as nximport numpy as npfrom collections import defaultdictimport matplotlib.pyplot as pltemails = pd.read_csv(\"./data/Emails.csv\")file = pd.read_csv(\"./data/Aliases.csv\")# key: alias value: personIdaliases = &#123;&#125;for index, row in file.iterrows(): aliases[row['Alias']] = row['PersonId'] file = pd.read_csv(\"./data/Persons.csv\")# key: id value: namepersons = &#123;&#125;for index, row in file.iterrows(): persons[row['Id']] = row['Name']# transform the alias name to the samedef unify_name(name): name = str(name).lower() name = name.replace(',','').split(\"@\")[0] if name in aliases.keys(): return persons[aliases[name]] return namedef draw_graph(graph): # graph is a direct graph object # set spring_layout positions = nx.spring_layout(graph) # set the size of the nodes. The PR value is higher, the node is larger. nodesize = [x['pagerank']*20000 for v, x in graph.nodes(data=True)] # set the length of the edges edgesize = [np.sqrt(e[2]['weight']) for e in graph.edges(data = True)] # draw nodes nx.draw_networkx_nodes(graph, positions, node_size = nodesize, alpha = 0.4) # draw edges nx.draw_networkx_edges(graph, positions, edge_size = edgesize, alpha = 0.6) # draw nodes' label nx.draw_networkx_labels(graph, positions, font_size = 10) plt.show() # normalize the from and to value.# the metadataFrom and metadatato is the columns's nameemails.MetadataFrom = emails.MetadataFrom.apply(unify_name)emails.MetadataTo = emails.MetadataTo.apply(unify_name)# set the weight is equal the sending times# &#123; (from, to): num &#125;edges_weights_temp = defaultdict(list) # the key can be a tuplefor row in zip(emails.MetadataFrom, emails.MetadataTo, emails.RawText): temp = (row[0], row[1]) if temp not in edges_weights_temp: edges_weights_temp[temp] = 1 else: edges_weights_temp[temp] += 1 # transfer the format (from, to):value -&gt; from, to, valueedge_weights = [(key[0], key[1], val) for key, val in edges_weights_temp.items()]# create the direct graphgraph = nx.DiGraph()# add weight graph.add_weighted_edges_from(edge_weights)# calculate the pr value of every nodepagerank = nx.pagerank(graph) # return a dict# get the pr of per valuepagerank_list = &#123;node: rank for node, rank in pagerank.items()&#125;# set the pr value as the attribute of the nodenx.set_node_attributes(graph, name = 'pagerank', values=pagerank_list)# draw graphdraw_graph(graph)# simplify the graphpagerank_threshold = 0.02# copy a graphsmall_graph = graph.copy()for n, p_rank in graph.nodes(data = True): if p_rank['pagerank'] &lt; pagerank_threshold: small_graph.remove_node(n)draw_graph(small_graph) 结果如下：","tags":[{"name":"数据分析","slug":"数据分析","permalink":"https://joshuaqyh.github.io/tags/数据分析/"},{"name":"机器学习","slug":"机器学习","permalink":"https://joshuaqyh.github.io/tags/机器学习/"},{"name":"数据挖掘","slug":"数据挖掘","permalink":"https://joshuaqyh.github.io/tags/数据挖掘/"}]},{"title":"软件工程 | 阐释原型方法对软件生命周期各阶段的支持","date":"2019-03-02T19:01:15.000Z","path":"2019/03/03/阐释原型方法对软件生命周期各阶段的支持/","text":"要正确理解原型方法对软件生命周期不同阶段的支持，分别给出： 辅助或代替分析阶段； 辅助设计阶段； 代替分析与设计阶段； 代替分析、设计和实现阶段； 代替全部开发阶段；这五种情形所对应的开发活动执行时间顺序。 以下对这五种情形所对应的开发活动执行时间顺序展开阐述。 1. 辅助或代替分析阶段 从上图可知，在分析和需求说明阶段应用原型方法，其开发活动的执行顺序如下： 定义软件的初步需求 原型方法辅助或代替分析阶段： 快速分析软件初步需求 快速构造软件需求说明书 用户理解软件需求书 用户对软件需求书进行评价反馈 根据反馈，决定是否需要修改需求分析结果，进行新一轮的原型方法还是跳出当前分析阶段，进入下一阶段。 不断循环应用原型方法，直到得出明确的需求说明文档，然后进入下一阶段。 根据需求说明书，开始进行软件的概要设计和详细设计，输出设计说明文档 根据设计说明文档，进行编码实现，输出初步的程序系统 对程序系统进行编码测试，得到软件产品 运行软件产品，并持续维护。 2. 辅助设计阶段 由上图可知，在设计阶段应用原型方法，其对应的开发活动顺序如下： 确定初步的软件需求 对需求进行详细分析，并输出明确的需求说明文档 原型方法辅助设计阶段： 结合需求说明文档，快速分析需求 快速构造软件系统的架构，以及不同的功能实现算法 工程师对现有提出的系统架构进行评价和反馈 结合评价反馈判断是否需要修改系统架构和设计，以及功能实现算法 不断循环应用原型方法，直到得到一个合适的系统架构和性能较好的功能实现算法，输出最终的软件架构设计说明文档，进入下一阶段 编码实现阶段，充分理解软件架构设计文档，并开始实现，并输出符合设计的程序系统 对上一阶段的程序系统进行编码测试，输出良好的，无缺陷的软件产品 运行软件产品，持续维护 3. 代替分析与设计阶段 原型方法代替分析与设计阶段，其开发执行顺序如下： 定义软件初步需求 原型方法代替分析与设计阶段： 快速分析软件需求 快速构造设计说明文档 工程师，架构师对比使用需求和软件设计说明 对需求和设计提出评价和反馈 根据反馈决定是否修改需求文档和软件设计文档，循环应用原型方法 不断循环，直到得到完善的需求说明文档和架构设计说明文档 根据设计文档，开始编码实现功能，并输出初步的符合设计的程序系统 对初步的程序系统进行编码测试，得到符合设计和需求的软件产品 持续运行和维护上线的软件产品 4. 代替分析、设计和实现阶段 从分析到输出程序系统，应用原型方法来代替分析、设计和实现阶段，各开发活动对应的时间实行顺序为： 定义软件初步需求 应用原型方法，代替分析、设计和实现阶段： 快速分析软件需求 快速构造软件设计说明文档 快速编码，构造软件程序系统 用户使用软件程序系统，提出评价和反馈 根据反馈决定是否修改需求，变更软件设计文档，修正软件产品，继续应用原型方法 继续应用原型方法，直到得到明确的需求说明文档，详细的软件设计文档，和功能较为完备的程序系统，然后进入下一阶段 对上一阶段的程序系统进行编码测试，集成测试，验证测试，确保输出功能符合需求设计的可靠软件产品 持续运行和维护软件产品 5. 代替全部开发阶段 原型方法可代替全部的开发阶段，即从分析到输出最终软件产品，其过程顺序如下： 定义软件初步需求 原型方法代替所有开发阶段： 快速分析和明确软件需求 快速构造软件架构设计说明书 根据软件设计文档，快速编码构造程序系统 在编码构造的同时，快速执行相应的编码测试，输出软件产品 用户使用软件产品，提出评价和反馈 根据评价反馈，确定是否继续应用原型方法 继续循环原型方法，直到输出明确的需求说明文档、详细的软件设计文档、可靠的软件产品、完备的测试 持续运行和维护软件。 ​ 以上，完。","tags":[{"name":"软件工程","slug":"软件工程","permalink":"https://joshuaqyh.github.io/tags/软件工程/"},{"name":"软件测试","slug":"软件测试","permalink":"https://joshuaqyh.github.io/tags/软件测试/"}]},{"title":"概念 | 软件的本质与软件工程科学","date":"2019-03-02T04:05:54.000Z","path":"2019/03/02/软件工程-概念-软件的本质与软件工程科学/","text":"以下问题和解答来自 SYSU 16 级系统分析与设计课程 week1 的作业实践。 Student ID ： 16340186 Student Name : 邱奕浩 Q1: 阐述软件工程的定义。 A1： 软件工程一直以来缺乏严格标准的定义，不过很多学者，组织机构都给出了自己的定义，如： NATO (1968): 软件工程是研究和应用如何以系统的，规范化的，可定量的过程化方法去开发和维护软件，以及如何把经过实践验证而证明正确的管理技术和当前最好的技术方法综合起来的一门独立学科。 IEEE (1993)：软件工程是将系统化的，严格约束化的，量化的工程方法应用于软件的开发，运行，维护过程，即用工程化的方法来打造软件。 《计算机科学技术百科全书》：软件工程是应用计算机科学，数学，逻辑学及管理科学等原理，来开发软件的过程。 《信息技术 软件工程术语》: 软件工程是应用计算机科学理论和技术以及工程管理原则和方法，按预算和进度，实现满足用户要求的软件产品的定义、开发、和维护的工程或学科。 从上述各方的定义中，我们可以得出： 软件工程是一门独立的交叉学科，也是一门独特的工程，综合了理论，工程，技术，管理等方面的知识，同时处于理论与实践水平不断发展的过程。 软件工程具有系统化，约束化，规范化，过程化，可量化的特点，具备相应的工程管理原则和方法。 ​ Q2: 解释导致软件危机 ( software crisis ) 的本质原因和表现形式，并述说克服软件危机的方法。 A2： 软件危机的本质原因： 软件的大量需求与软件生产力效率之间的矛盾， 软件系统的复杂性与软件开发方法之间的矛盾。 软件危机的表现形式： 软件开发成本日益增长，开发成本往往超出预算（成本） 软件开发进度难以控制，项目的开发时间往往超出预定的进度时间表（时间） 用户对软件产品不满意的现象经常发生，这是对用户需求的理解不够明确，用户需求多样化的原因（需求） 软件产品的质量不可靠，时常存在 Bug （质量） 软件的可维护性低，数量不断膨胀的软件产品缺乏适当的文档资料 （维护） 软件的开发生产率跟不上硬件的发展，计算能力越大，编程问题越大，软件越复杂。（摩尔定律） 克服软件危机的主要方法： 软件从业者必须正确认识计算机软件的内涵（软件 ≠ 程序）。 充分认识到软件开发并不是来自于某种个体劳动的神秘技巧，而是需要依托组织良好，管理严密，协同配合的工程活动。 采用成熟的软件开发技术和方法，比如结构化程序设计，面向对象的开发)，CMM，UML等等 开发和使用适当的软件工具 从业者的专业素养和知识水平必须不断提升 IBM大型机之父 Brooks 在其著名论文《没有银弹》中断言：“在10年无法找到解决软件危机的灵丹妙药”，在其另外一著作《人月神话》提到：开发软件的困难是天生存在的，我们只能渐进式的改善它。在整体工程环境没有改变之前，对克服软件危机所能做的就是依靠人的素质，培养优秀的软件工程师。 ​ Q3: 解释一下软件的生命周期的概念。 A3：软件像一个个生命体一样，具有孕育、诞生、成长、成熟、衰亡的生存过程，即软件的生命周期。软件的生命周期被划分为若干阶段，每个阶段具有明确的任务，从而使规模，结构和管理复杂软件的开发过程得到适当的控制管理。生命周期主要分为以下6个阶段。 可行性分析与计划阶段 确定软件开发的总体目标，给出功能，性能，可靠性以及接口等方面的要求，并进行可行性分析。 估算软件的开发成本，估计可利用的资源，成本，效益，开发进度，进行投资-收益分析，制定开发计划。 提交可行性分析报告、开发计划等文档。 需求分析阶段 分析用户需求，给出需求的详细定义，确定软件的各项功能，性能需求和设计约束，确定对文档编制的要求。 提交软件需求说明文档，软件规格说明文档，数据要求说明等文档和初步的用户手册。 设计阶段 概要设计：将需求转化成软件的体系结构，结构中每一组成部分必须是意义明确的模块，每一个模块必须和需求相匹配。 详细设计：对模块所完成的任务进行详细具体的描述，提供源程序编写的直接依据。 提交结构设计说明、详细设计说明和测试计划初稿等文档。 实现阶段 完成源程序的编码，编译，调试，得到没有语法错误的程序清单。必须确保程序结构良好，清晰，具有较为良好的可读性，并且与上一设计阶段中的要求相一致。 根据项目重要性和规模，编写开发进度日报，周报，或月报。 完成用户手册，操作手册等面向用户的文档编写工作。 编制初步的测试计划。 测试阶段 全面测试目标软件（包括单元测试，集成测试，系统测试等），并检查审阅已编制好的文档，提交测试分析报告。逐项评价所生产的程序，文档以及开发工作本身，提交项目开发总结报告。 在这个开发过程中，开发集体需要按月编写进度月报。 运行和维护阶段 用户使用软件之后，必须在运行使用中加以持续的维护，根据用户新提出的需求进行软件功能的扩充，删改，更新和升级。 软件维护包括改正性维护（用于发现软件错误），适应性维护（适应运行环境的变化）以及完善性维护（增强功能）。 ​ Q4: SWEBoK 的 15 个知识域（An Overview of the SWEBOK Guide 请中文翻译其名称与简短说明） A4：SWEBoK 的中文名称为软件工程知识体系( Software Engineering Body of Knowledge)，是 IEEE Computer Society 构建软件生产的最佳实践与相关知识的框架，用于指导软件工程人才的培养与学科建设。知识体系分为软件工程实践和基础教育两个部分，共有15个知识域 ( Knowledge Aaras 以下简称 KA ) 。 软件工程实践(The Practice of Software Engineering) 软件需求 (Software Requirements) ：软件需求知识域主要关注软件需求的协商，谈判，分析，明确。，验证等过程。该 KA 是整个 SWEBoK 中最重要的两个领域之一。经业界实践表明，如果软件需求工作没做好，那么整条软件产品线和软件工程项目将变得极其最弱，所谓 ”牵一发而动全身”。 软件设计 (Software Design) ： 软件设计是定义软件结构，组件，接口，和其他系统特性以及产品结果的过程，该 KA 涵盖了软件的设计过程和目标产品。软件设计在软件生命周期中的主要目的是结合上一阶段的软件需求，做出对软件内部结构，接口和行为的具体描述。和软件需求 KA一样，软件设计KA是 SWEBoK 中最重要的领域之一。 软件构建 (Software Construction)： 软件构建实现主要涉及到了详细的代码设计实现，单元测试，集成测试，调试和验证等工作任务。软件构建 KA 包含的相关主题是满足需求和设计约束的软件程序的发展过程，涵盖了软件构造基础，管理软件构建任务，构建方法论，实用的构建思想和软件构造的工具。 软件测试 (Software Testing) ：软件测试是一项评估软件项目质量以及识别软件缺陷并改善的工作，该 KA 包含了软件测试的基础知识，软件测试的技术，用户界面接口测试，相关的测试措施和实际软件的考虑方法。 软件维护 (Software Maintenance) ：软件维护 KA 涉及了升级现有软件功能（完善性维护），调整软件适应运行环境的变化（适应性维护），以及更正软件缺陷（改正性维护）等方面的工作。 软件配置管理 (Software Configuration Management) ： 系统的配置是硬件，固件，软件或他们组合的功能和物理特征。同时配置还可以看作是硬件，固件，软件，或其组合的特定版本的集合。不同的版本有不同的配置，根据特定的构建过程组合在一起，以服务与特定的目的。 软件工程管理 (Software Engineering Management) ：软件工程管理包括计划，协调，衡量，报告和控制一个项目，以确保软件的开发和维护是系统化的，有纪律的以及可量化的。 软件工程过程 (Software Engineering Process) ： 该KA涉及软件生命周期过程的定义，实现，评估，度量，管理和改进。所涵盖的主题包括过程实现和变更，过程定义，过程评估模型和方法，以及过程测量。 软件工程模型和方法 (Software Engineering Models and Methods) ：该 KA 解决了围绕整个软件生命周期各阶段问题的方法，以及在特定生命周期阶段的其他 KA 所包含的问题的方法。 软件质量 (Software Quality)： 软件质量问题是普遍存在于整个软件生命周期的问题，该 KA 关注软件质量的基础，软件质量管理过程，以及实际的考虑。 软件工程专业实践 (Software Engineering Professional Practice)：该 KA 的理念是对于软件工程师而言，必须具备的知识，技能和态度，要以一种专业的，负责的，和合乎道德的方法来进行实践。 软件工程教育的需求 (The Educational Requirements of Software Engineering ) 软件工程经济学 (Software Engineering Economics)： 该 KA 主要关注的是如何在业务环境中做出决策，以便技术决策与组织的业务目标保持一致。 计算基础 (Computing Foundations)：该 KA 涵盖了提供给软件工程实践所需的计算背景的基础主题。包括问题解决技术、抽象、算法和复杂性、编程基础、并行和分布式计算的基础、计算机组织、操作系统和网络通信。 数学基础 (Mathematical Foundations) ： 该 KA 涵盖了用于软件工程实践所需的数学理论基础，包含的主题有集合、关系、函数、基本的明题和谓词逻辑、证明方法、图、树、离散数学、仿真建模等等。 工程基础 (Engineering Foundations)：该KA主要提供了用于软件工程实践所需的工程背景基础，主题涵盖了经验方法和实验技术、统计分析、测量与指标、工程设计、建模与仿真、以及根本原因分析等方面。 Q5： 简单解释 CMMI 的五个级别。 A5： CMMI 中文名称为能力成熟度模型集成，是一种过程性的改进训练和评估计划，用于度量一个企业的软件工程能力。其五个级别简单概括如下： Level 1 - Initial：企业运作处于一种无序，自发生产的模式，过程难以预测，控制性差，反应性弱。 Level 2 - Managed：企业在管理级的水平上处于有序的，项目化的生产模式，具有明确的流程和较好的项目控制程序。 Level 3 - Defined：企业工程水平达到定义级，企业企业管理组织化，流程标准化，体系制度化。 Level 4 - Quantitatively Managed：企业管理水平进一步升级，实现数字化管理和控制。 Level 5 - Optimizing：在优化级别，企业项目管理达到最高水平，能主动改善业务项目流程，不断实现过程优化。 Q6：用自己的语言简述 SWEBok 或 CMMI（ 200 字）。 SWEBok （软件工程知识体系）是 IEEE Computer Society 提出来的一套构建软件生产的最佳实践与相关知识的框架，用于指导软件工程人才的培养和学科建设。该体系从软件工程的实践和教育两个方面切入，就这两个方面划分了15个知识域（KA）。 在实践方面，知识体系归纳了 11 种知识域：围绕软件生命周期提出了 5 个知识域：软件需求 KA、软件设计 KA、软件实现 KA、软件测试 KA、软件运行维护 KA；结合工程管理的原则，提出了 6 个 KA：软件配置管理 KA、软件工程管理 KA、软件工程过程 KA、软件工程建模与方法 KA、软件质量 KA、软件工程专业实践 KA。 在教育方面，则是提出了软件工程经济学 KA、计算基础 KA、数学基础 KA、工程基础 KA。 整套知识体系科学完备，教育 KA 是 实践 KA 的基础和支撑，在实践的探索过程中，又不断地给予教育体系层面的反馈和优化。 完。","tags":[{"name":"软件工程","slug":"软件工程","permalink":"https://joshuaqyh.github.io/tags/软件工程/"},{"name":"系统分析与设计","slug":"系统分析与设计","permalink":"https://joshuaqyh.github.io/tags/系统分析与设计/"}]},{"title":"概念 | 必知的软件工程核心概念","date":"2019-03-01T06:31:22.000Z","path":"2019/03/01/软件工程-核心概念/","text":"软件与软件危机软件概念软件 = 程序 + 数据 + 文档 + （服务） 程序 = 数据结构 + 算法  软件是能够完成预定功能和性能的、可执行的计算机指令； 软件是使得程序能够适当地处理信息的数据结构； 软件是描述程序的操作和使用的文档。 软件的逻辑抽象性软件是一种逻辑实体，具备知识性的产品集合，是对物理世界的一种抽象化，同时又是一种人脑智力的成果，开发成本昂贵但可以复制。 而软件问题都是在软件开发和修改过程中引入的，开发工作仍未完全摆脱手工作坊式的低效开发方式。软件测试则是为了最小化软件问题和风险。 软件分类 软件产品的组成 软件危机 软件开发与软件工程软件开发基本过程 软件计划，确定产品定位和目标人群。 软件需求分析：根据客户需求，制定客户需求的产品功能，特性，性能，界面和具体规格。 根据需求进行设计：概要设计和详细设计。 编程实现并运行。 软件测试：确认用户需求，对设计和实现结果进行验证。 维护：维持软件运行，修改软件缺陷，增强完善功能，不断迭代软件版本。 软件开发成本 软件工程要点 软件工程原则 软件工程目标 软件开发方法 软件生命周期模型软件生命周期可行性分析与计划阶段 确定软件开发的总体目标，给出功能，性能，可靠性以及接口方面的要求，完成可行性分析。 估计软件开发所需要利用的各种资源，效益，成本，开发进度，制定开发计划 提交可行性分析报告，开发计划文档。 需求分析阶段 分析用户提出的要求，给出需求详细定义，确定软件系统的各项功能，性能需求和设计约束，确定对文档编制的要求。 提交软件需求说明，软件规格说明，数据要求说明等文档和初步用户手册。 设计阶段 概要设计：把各项需求转换成软件的体系结构，结构中的每一部分都是意义明确的模块，每个模块与某些需求对应/ 详细设计：对每个模块所完成的工作进行具体的描述，提供源程序编写的直接依据。 提交结构设计说明，详细设计说明和测试计划初稿等文档。 实现阶段 完成源代码的编码实现。保证程序结构良好，清晰易读，与设计一致。 编写进度日报，周报和月报（取决于项目的重要性和规模） 提交用户手册，操作手册等面向用户的文档编写工作 提交测试计划 测试阶段 全面测试目标软件系统，检查审阅与编制的文档，提交测试分析报告。逐项评价所生产的程序，文档以及开发工作本身，提交项目开发总结报告。 开发过程中（前5阶段），开发集体需要按月编写开发进度月报。 运行与维护阶段 软件提交给用户后，在运行使用过程中得到持续维护，根据用户的新需求进行必要的软件修改和升级。 软件维护包括正性维护（发现错误），适应性维护（适应运行环境变化）和完善性维护（增强功能） 软件生命周期模型SDM常见模型 瀑布模型 瀑布模型中的每一个开发活动具有下列特征： 本阶段活动的工作对象来自于上一项活动的输出，这些输出一般是代表本阶段活动结束的里程碑式的文档 根据本阶段的活动规程执行相应的任务 本阶段活动产出相关的软件工件，作为下一阶段活动的输入。 对本阶段活动执行情况进行评审 ​ 瀑布模型的优点： 降低软件开发的复杂程度，提高软件开发过程的透明性，提高软件开发过程的可管理性 推迟软件实现，强调在软件实现前必须进行分析和设计工作 以项目的阶段评审和文档控制为手段有效地对整个开发过程进行指导，保证了阶段之间的正确衔接，能够及时发现并纠正开发过程中存在的缺陷，使产品达到预期的质量要求 瀑布模型的缺点： 强调过程活动的线性顺序 缺乏灵活性，特别是无法解决软件需求不明确或不准确的问题 风险控制能力较弱 瀑布模型中的软件活动是文档驱动的，当阶段之间规定过多的文档时，会极大地增加系统的工作量 管理人员如果仅仅以文档的完成情况来评估项目完成进度，往往会产生错误的结论 V-W模型 W 模型是V 模型的演进 在V 模型中增加软件各开发阶段对应同步进行的测试。 W 模型中开发是一个“V”型，测试是与此并行的另一个“V”型。基于“尽早地和不断地进行软件测试”的原则，在软件的需求和设计阶段的测试活动遵循IEEE1012-1998《软件验证与确认(V&amp;V)》。 W 模型强调测试伴随着整个软件开发周期，而且测试的对象不仅仅是程序，需求、功能和设计同样要测试。测试与开发是同步进行的，从而有利于尽早地发现问题。 快速应用开发模型 （前端应用常用） 原型模型（重点） 问题产生 → 用户痛点 → 产生需求 ↓ —– 设计原型 —— 实现并实现模型： if 原型 exist problems， then 修改加强 （伴随新的需求） else 转为可用于生产环境的软件发行版本 所有的新技术，需要使用原型法来试验。 原型与原型方法 原型指模拟某种最终产品的原始模型 原型方法指在获得一组基本需求后，通过快速分析构造出一个小型的软件系统原型，满足用户的基本要求 用户通过使用原型系统，提出修改意见，从而减少用户与开发人员对系统需求的误解，使需求尽可能准确 原型方法主要用于明确需求，但也可以用于软件开发的其他阶段 原型方法的三种作用类型 探索型 澄清用户对目标系统的要求，确定用户期望的特性；探讨多种实现方案的可行性。主要针对需求模糊、用户和开发者对目标项目开发都缺乏经验的情况。 实验型 用于大规模开发和实现之前，考核技术实现方案是否合适、分析和设计的规格说明是否可靠。 进化型 在构造系统的过程中适应需求的变化，通过不断改进原型，逐步将原型进化成最终的系统。它将原型方法的思想扩展到软件开发的全过程，适用于需求经常变动的软件项目。 原型策略 原型方法与软件生命周期的联系！！","tags":[{"name":"软件工程","slug":"软件工程","permalink":"https://joshuaqyh.github.io/tags/软件工程/"}]},{"title":"机器学习 | 神经网络推导-前向&反向","date":"2019-02-28T02:44:48.000Z","path":"2019/02/28/机器学习-神经网络推导-前向-反向/","text":"以下BP神经网络推导过程是来自于NTU的李宏毅老师的ML课程。过程相当易懂，很好理解。为避免忘记，在此记录一下。视频推导链接如下（需要fq）: https://www.youtube.com/watch?v=ibJpTrp5mcE 局部网络图 前导知识我们必须了解到的就是BP神经网络本质就是一个多层级联神经元和对应连接权重和偏置构成的函数，我们输入该函数，然后得到函数值就是模型的输出结果。 该函数具备有权重参数和偏置参数，我们需要通过输入训练数据和标签来拟合得到一组权重参数和偏置参数。拟合的方式近似于最小二乘法，我们可以得到BP神经网络的损失函数。如下： 给定训练集标签向量$O_t$和训练结果$R_t$, 我们将其训练误差$L$表示为: $$L = \\frac{1}{2} \\sum_{t∈T}{(O_t - R_t)}^2 \\tag{1}$$ 其实也就是所有模型输出实例的预测结果减去标签真实结果的平方和的一半。我们将训练误差函数定义为一个BP神经网络模型的损失函数，我们的目标就是最小化该损失函数。求解思路看下。 求解核心思路BP神经网络参数（权重+bias）和损失函数L($\\theta$)已知，利用梯度下降法和链式法则可进行推导。 首先梯度下降法核心思想不变，我们需要重点关注梯度函数。 由于网络结构是多层的，需要使用到链式法则来求解梯度函数。 损失函数的微分（梯度函数）可以为关于$w_i$的多项偏微分之和。 利用链式法则,将梯度函数差分为主要的两项（红色方框标出），然后分别进行前向和反向的迭代计算，等整个网络收敛之后，计算得到整个网络的当前梯度值，然后利用梯度下降法更新网络参数。 前向过程特别简单，从网络结构上来看：微分值 = 前一层的输入之和。 反向过程较为复杂，以下详细展开。 反向推导先从输入层出发考虑，可以得到一个迭代式 可以看出上图右边式子的小红框部分和左边式子的左边构成一个迭代关系。只不过小红框部分是下一层的微分值。从这里就可以看出来，要计算当前的微分值需要提前知道下一层的微分值，由此可以将网络结构逆转，反向进行计算。代入$w_3,w_4,\\sigma’(z)$整理得到下述式子。 将输出层，当成输入层，激活函数为放大器。 迭代过程主要有两种情况：输出层和非输出层。 总结 利用梯度下降法和链式法则来求解BP神经网络的损失函数的最优参数解，可分为前向和后向两个过程。前向微分是直接将当前节点的输入值求和即可。而反向微分则是需要链式法则由下一层的微分值计算得到当前层的微分值，将整个网络逆转过来，而激活函数变为普通的放大器$\\sigma’(z)$。","tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://joshuaqyh.github.io/tags/机器学习/"}]},{"title":"机器学习 | 线性模型-手写推导和求解","date":"2019-02-25T18:02:44.000Z","path":"2019/02/26/机器学习-线性模型-手写推导和求解/","text":"写的好草啊，虽然这个有点简单，但如果涉及到对数回归就会相对麻烦一点了，这次就先这样，下次要更加规范一点： 字体不要太草 公式符号要特别标明 下面是简单记录模型的含义，以及如何利用梯度下降法来求解最小二乘法的问题。","tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://joshuaqyh.github.io/tags/机器学习/"},{"name":"数据挖掘","slug":"数据挖掘","permalink":"https://joshuaqyh.github.io/tags/数据挖掘/"}]},{"title":"机器学习 |  思考篇","date":"2019-02-25T15:53:56.000Z","path":"2019/02/25/机器学习-思考篇/","text":"机器学习的局限在哪里 缺乏可解释性 假设数据分布一致 需要大量数据 难以进行知识推理，只能基于统计归纳 机器学习未来的发展方向在哪里 提升可解释性，脱离黑盒模型 自解释和自推理 防止对抗攻击 神经网络压缩 强化学习","tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://joshuaqyh.github.io/tags/机器学习/"}]},{"title":"机器学习 | EM聚类算法","date":"2019-02-23T22:00:00.000Z","path":"2019/02/24/机器学习-EM聚类算法/","text":"EM算法的思想利用到了极大似然法，首先必须对极大似然有所了解。 极大似然估计法极大似然估计，简单来说就是通过抽取一部分样本，反推个体分布规律中的参数。比如从一个班抽取一部分同学，统计其身高，反推实际的高斯分布中的参数如均值$\\mu$ 和标准差$\\theta$。一般步骤就是： （1）写出似然函数； （2）对似然函数取对数，并整理； （3）求导数，令导数为0，得到似然方程； （4）解似然方程，得到的参数即为所求； 详细介绍如下： EM算法​ 期望最大算法是一种从不完全数据或有数据丢失的数据集（存在隐含变量）中求解概率模型参数的最大似然估计方法。 EM的算法流程： 初始化分布参数θ； 重复以下步骤直到收敛： ​ E步骤：根据参数初始值或上一次迭代的模型参数来计算出隐性变量的后验概率，其实就是隐性变量的期望。作为隐藏变量的现估计值： ​ ​ M步骤：将似然函数最大化以获得新的参数值： ​ ​ 这个不断的迭代，就可以得到使似然函数L(θ)最大化的参数θ了。那就得回答刚才的第二个问题了，它会收敛吗？ 感性的说，因为下界不断提高，所以极大似然估计单调增加，那么最终我们会到达最大似然估计的最大值。理性分析的话，就会得到下面的东西： img 具体如何证明的，看推导过程参考：Andrew Ng《The EM algorithm》 http://www.cnblogs.com/jerrylead/archive/2011/04/06/2006936.html EM算法用途EM的应用 ​ EM算法有很多的应用，最广泛的就是GMM混合高斯模型、聚类、HMM等等。具体可以参考JerryLead的cnblog中的Machine Learning专栏： （EM算法）The EM Algorithm 混合高斯模型（Mixtures of Gaussians）和EM算法 K-means聚类算法 使用 EM工具包直接使用sklearn中的工具包，获得GMM模型，先fit拟合，然后predict输出结果。 123456789101112131415161718192021222324252627282930313233343536373839404142# -*- coding: utf-8 -*-import pandas as pdimport csvimport matplotlib.pyplot as pltimport seaborn as snsfrom sklearn.mixture import GaussianMixturefrom sklearn.preprocessing import StandardScaler # 数据加载，避免中文乱码问题data_ori = pd.read_csv('./heros.csv', encoding = 'gb18030')features = [u'最大生命',u'生命成长',u'初始生命',u'最大法力', u'法力成长',u'初始法力',u'最高物攻',u'物攻成长',u'初始物攻',u'最大物防',u'物防成长',u'初始物防', u'最大每5秒回血', u'每5秒回血成长', u'初始每5秒回血', u'最大每5秒回蓝', u'每5秒回蓝成长', u'初始每5秒回蓝', u'最大攻速', u'攻击范围']data = data_ori[features] # 对英雄属性之间的关系进行可视化分析# 设置 plt 正确显示中文plt.rcParams['font.sans-serif']=['SimHei'] # 用来正常显示中文标签plt.rcParams['axes.unicode_minus']=False # 用来正常显示负号# 用热力图呈现 features_mean 字段之间的相关性corr = data[features].corr()plt.figure(figsize=(14,14))# annot=True 显示每个方格的数据sns.heatmap(corr, annot=True)plt.show() # 相关性大的属性保留一个，因此可以对属性进行降维features_remain = [u'最大生命', u'初始生命', u'最大法力', u'最高物攻', u'初始物攻', u'初始物攻', u'最大物防', u'初始物防', u'最大每5秒回血', u'最大每5秒回蓝', u'初始每5秒回蓝', u'最大攻速', u'攻击范围']data = data_ori[features_remain]data[u'最大攻速'] = data[u'最大攻速'].apply(lambda x: float(x.strip('%'))/100)data[u'攻击范围']=data[u'攻击范围'].map(&#123;'远程':1,'近战':0&#125;)# 采用 Z-Score 规范化数据，保证每个特征维度的数据均值为 0，方差为 1ss = StandardScaler()data = ss.fit_transform(data)# 构造 GMM 聚类gmm = GaussianMixture(n_components=5, covariance_type='full')gmm.fit(data)# 训练数据prediction = gmm.predict(data)print(prediction)# 将分组结果输出到 CSV 文件中data_ori.insert(0, '分组', prediction)data_ori.to_csv('./hero_out.csv', index=False, sep=',')","tags":[{"name":"数据分析","slug":"数据分析","permalink":"https://joshuaqyh.github.io/tags/数据分析/"},{"name":"机器学习","slug":"机器学习","permalink":"https://joshuaqyh.github.io/tags/机器学习/"},{"name":"数据挖掘","slug":"数据挖掘","permalink":"https://joshuaqyh.github.io/tags/数据挖掘/"}]},{"title":"常用的三种数据规范化的方法及python实现","date":"2019-02-23T19:35:40.000Z","path":"2019/02/24/常用的三种数据规范化的方法法/","text":"三种数据规范化方法介绍和使用Min-max 规范化Min-max 规范化方法是将原始数据变换到 [0,1] 的空间中。用公式表示就是： 新数值 =（原数值 - 极小值）/（极大值 - 极小值）。 即$new = \\frac{old - min}{max - min}$。 在如朴素贝叶斯方法和决策树方法中，规范化后的数值必须非负数，所以一般采用min-max规范化。 在python中使用如下： 1234567891011# coding:utf-8from sklearn import preprocessingimport numpy as np# 初始化数据，每一行表示一个样本，每一列表示一个特征x = np.array([[ 0., -3., 1.], [ 3., 1., 2.], [ 0., 1., -1.]])# 将数据进行 [0,1] 规范化min_max_scaler = preprocessing.MinMaxScaler() # 获得一个转换器对象minmax_x = min_max_scaler.fit_transform(x) # 使用转换器的方法进行转换print minmax_x Z-Score 规范化假设 A 与 B 的考试成绩都为 80 分，A 的考卷满分是 100 分（及格 60 分），B 的考卷满分是 500 分（及格 300 分）。虽然两个人都考了 80 分，但是 A 的 80 分与 B 的 80 分代表完全不同的含义。 那么如何用相同的标准来比较 A 与 B 的成绩呢？Z-Score 就是用来可以解决这一问题的。 我们定义：新数值 =（原数值 - 均值）/ 标准差。 这一方法其实就是把数据规范化成一个标准的正态分布。 假设 A 所在的班级平均分为 80，标准差为 10。B 所在的班级平均分为 400，标准差为 100。那么 A 的新数值 =(80-80)/10=0，B 的新数值 =(80-400)/100=-3.2。 那么在 Z-Score 标准下，A 的成绩会比 B 的成绩好。 我们能看到 Z-Score 的优点是算法简单，不受数据量级影响，结果易于比较。不足在于，它需要数据整体的平均值和方差，而且结果没有实际意义，只是用于比较。 在python中使用如下： 123456789from sklearn import preprocessingimport numpy as np# 初始化数据x = np.array([[ 0., -3., 1.], [ 3., 1., 2.], [ 0., 1., -1.]])# 将数据进行 Z-Score 规范化scaled_x = preprocessing.scale(x) # 直接调用 scale方法print scaled_x 小数定标规范化小数定标规范化就是通过移动小数点的位置来进行规范化。小数点移动多少位取决于属性 A 的取值中的最大绝对值。 举个例子，比如属性 A 的取值范围是 -999 到 88，那么最大绝对值为 999，小数点就会移动 3 位，即新数值 = 原数值 /1000。那么 A 的取值范围就被规范化为 -0.999 到 0.088。 在python中使用如下： 12345678910# coding:utf-8import numpy as np# 初始化数据x = np.array([[ 0., -3., 1.], [ 3., 1., 2.], [ 0., 1., -1.]])# 小数定标规范化j = np.ceil(np.log10(np.max(abs(x)))) # 获取小数点移动位数scaled_x = x/(10**j)print scaled_x","tags":[{"name":"python","slug":"python","permalink":"https://joshuaqyh.github.io/tags/python/"},{"name":"数据分析","slug":"数据分析","permalink":"https://joshuaqyh.github.io/tags/数据分析/"},{"name":"机器学习","slug":"机器学习","permalink":"https://joshuaqyh.github.io/tags/机器学习/"},{"name":"数据挖掘","slug":"数据挖掘","permalink":"https://joshuaqyh.github.io/tags/数据挖掘/"}]},{"title":"机器学习 | K-means 聚类算法","date":"2019-02-23T17:46:05.000Z","path":"2019/02/24/机器学习-kmeans-聚类/","text":"K-Means 工作原理 工作原理很简单： 选取 K 个点作为初始的类中心点，这些点一般都是从数据集中随机抽取的； 将每个点分配到最近的类中心点，这样就形成了 K 个类，然后重新计算每个类的中心点； 重复第二步，直到类不发生变化，或者你也可以设置最大迭代次数，这样即使类中心点发生变化，但是只要达到最大迭代次数就会结束。 使用 K-means 算法123from sklearn.cluster import KMeansKMeans(n_clusters=8, init='k-means++', n_init=10, max_iter=300, tol=0.0001, precompute_distances='auto', verbose=0, random_state=None, copy_x=True, n_jobs=1, algorithm='auto') 们能看到在 K-Means 类创建的过程中，有一些主要的参数： n_clusters: 即 K 值，一般需要多试一些 K 值来保证更好的聚类效果。你可以随机设置一些 K 值，然后选择聚类效果最好的作为最终的 K 值； max_iter： 最大迭代次数，如果聚类很难收敛的话，设置最大迭代次数可以让我们及时得到反馈结果，否则程序运行时间会非常长； n_init：初始化中心点的运算次数，默认是 10。程序是否能快速收敛和中心点的选择关系非常大，所以在中心点选择上多花一些时间，来争取整体时间上的快速收敛还是非常值得的。由于每一次中心点都是随机生成的，这样得到的结果就有好有坏，非常不确定，所以要运行 n_init 次, 取其中最好的作为初始的中心点。如果 K 值比较大的时候，你可以适当增大 n_init 这个值； init： 即初始值选择的方式，默认是采用优化过的 k-means++ 方式，你也可以自己指定中心点，或者采用 random 完全随机的方式。自己设置中心点一般是对于个性化的数据进行设置，很少采用。random 的方式则是完全随机的方式，一般推荐采用优化过的 k-means++ 方式； algorithm：k-means 的实现算法，有“auto” “full”“elkan”三种。一般来说建议直接用默认的”auto”。简单说下这三个取值的区别，如果你选择”full”采用的是传统的 K-Means 算法，“auto”会根据数据的特点自动选择是选择“full”还是“elkan”。我们一般选择默认的取值，即“auto” 。 在创建好 K-Means 类之后，就可以使用它的方法，最常用的是 fit 和 predict 这个两个函数。你可以单独使用 fit 函数和 predict 函数，也可以合并使用 fit_predict 函数。其中 fit(data) 可以对 data 数据进行 k-Means 聚类。 predict(data) 可以针对 data 中的每个样本，计算最近的类。 1234567891011121314151617181920# coding: utf-8from sklearn.cluster import KMeansfrom sklearn import preprocessingimport pandas as pdimport numpy as np# 输入数据data = pd.read_csv('data.csv', encoding='gbk')train_x = data[[\"2019 年国际排名 \",\"2018 世界杯 \",\"2015 亚洲杯 \"]]df = pd.DataFrame(train_x)kmeans = KMeans(n_clusters=3)# 规范化到 [0,1] 空间min_max_scaler=preprocessing.MinMaxScaler()train_x=min_max_scaler.fit_transform(train_x)# kmeans 算法kmeans.fit(train_x)predict_y = kmeans.predict(train_x)# 合并聚类结果，插入到原数据中result = pd.concat((data,pd.DataFrame(predict_y)),axis=1)result.rename(&#123;0:u'聚类'&#125;,axis=1,inplace=True)print(result) K-means 聚类分割1234567891011121314151617181920212223242526272829303132333435363738394041424344# 使用 K-means 对图像进行聚类，并显示聚类压缩后的图像import numpy as npimport PIL.Image as imagefrom sklearn.cluster import KMeansfrom sklearn import preprocessingimport matplotlib.image as mpimg# 加载图像，并对数据进行规范化def load_data(filePath): # 读文件 f = open(filePath,'rb') data = [] # 得到图像的像素值 img = image.open(f) # 得到图像尺寸 width, height = img.size for x in range(width): for y in range(height): # 得到点 (x,y) 的三个通道值 c1, c2, c3 = img.getpixel((x, y)) data.append([c1, c2, c3]) f.close() # 采用 Min-Max 规范化 mm = preprocessing.MinMaxScaler() data = mm.fit_transform(data) return np.mat(data), width, height# 加载图像，得到规范化的结果 img，以及图像尺寸img, width, height = load_data('./weixin.jpg')# 用 K-Means 对图像进行 2 聚类kmeans =KMeans(n_clusters=2)kmeans.fit(img)label = kmeans.predict(img)# 将图像聚类结果，转化成图像尺寸的矩阵label = label.reshape([width, height])# 创建个新图像 pic_mark，用来保存图像聚类的结果，并设置不同的灰度值pic_mark = image.new(\"L\", (width, height))for x in range(width): for y in range(height): # 根据类别设置图像灰度, 类别 0 灰度值为 255， 类别 1 灰度值为 127 pic_mark.putpixel((x, y), int(256/(label[x][y]+1))-1)pic_mark.save(\"weixin_mark.jpg\", \"JPEG\")","tags":[{"name":"python","slug":"python","permalink":"https://joshuaqyh.github.io/tags/python/"},{"name":"数据分析","slug":"数据分析","permalink":"https://joshuaqyh.github.io/tags/数据分析/"},{"name":"机器学习","slug":"机器学习","permalink":"https://joshuaqyh.github.io/tags/机器学习/"},{"name":"数据挖掘","slug":"数据挖掘","permalink":"https://joshuaqyh.github.io/tags/数据挖掘/"}]},{"title":"机器学习 | KNN算法","date":"2019-02-23T17:03:49.000Z","path":"2019/02/24/机器学习-KNN算法/","text":"KNN工作原理近朱者赤，近墨者黑”可以说是 KNN 的工作原理。整个计算过程分为三步： 计算待分类物体与其他物体之间的距离； 统计距离最近的 K 个邻居； 对于 K 个最近的邻居，它们属于哪个分类最多，待分类物体就属于哪一类。 K 值如何选择 你能看出整个 KNN 的分类过程，K 值的选择还是很重要的。那么问题来了，K 值选择多少是适合的呢？ 如果 K 值比较小，就相当于未分类物体与它的邻居非常接近才行。这样产生的一个问题就是，如果邻居点是个噪声点，那么未分类物体的分类也会产生误差，这样 KNN 分类就会产生过拟合。 如果 K 值比较大，相当于距离过远的点也会对未知物体的分类产生影响，虽然这种情况的好处是鲁棒性强，但是不足也很明显，会产生欠拟合情况，也就是没有把未分类物体真正分类出来。 所以 K 值应该是个实践出来的结果，并不是我们事先而定的。在工程上，我们一般采用交叉验证的方式选取 K 值。 交叉验证的思路就是，把样本集中的大部分样本作为训练集，剩余的小部分样本用于预测，来验证分类模型的准确性。所以在 KNN 算法中，我们一般会把 K 值选取在较小的范围内，同时在验证集上准确率最高的那一个最终确定作为 K 值。 距离如何计算 在 KNN 算法中，还有一个重要的计算就是关于距离的度量。两个样本点之间的距离代表了这两个样本之间的相似度。距离越大，差异性越大；距离越小，相似度越大。 关于距离的计算方式有下面五种方式： 欧氏距离； 曼哈顿距离； 闵可夫斯基距离； 切比雪夫距离； 余弦距离。 其中前三种距离是 KNN 中最常用的距离，我给你分别讲解下。 欧氏距离是我们最常用的距离公式，也叫做欧几里得距离。在二维空间中，两点的欧式距离就是： img 同理，我们也可以求得两点在 n 维空间中的距离： img 曼哈顿距离在几何空间中用的比较多。以下图为例，绿色的直线代表两点之间的欧式距离，而红色和黄色的线为两点的曼哈顿距离。所以曼哈顿距离等于两个点在坐标系上绝对轴距总和。用公式表示就是： img img 闵可夫斯基距离不是一个距离，而是一组距离的定义。对于 n 维空间中的两个点 x(x1,x2,…,xn) 和 y(y1,y2,…,yn) ， x 和 y 两点之间的闵可夫斯基距离为： img 其中 p 代表空间的维数，当 p=1 时，就是曼哈顿距离；当 p=2 时，就是欧氏距离；当 p→∞时，就是切比雪夫距离。 那么切比雪夫距离怎么计算呢？二个点之间的切比雪夫距离就是这两个点坐标数值差的绝对值的最大值，用数学表示就是：max(|x1-y1|,|x2-y2|)。 余弦距离实际上计算的是两个向量的夹角，是在方向上计算两者之间的差异，对绝对数值不敏感。在兴趣相关性比较上，角度关系比距离的绝对值更重要，因此余弦距离可以用于衡量用户对内容兴趣的区分度。比如我们用搜索引擎搜索某个关键词，它还会给你推荐其他的相关搜索，这些推荐的关键词就是采用余弦距离计算得出的。 KD 树其实从上文你也能看出来，KNN 的计算过程是大量计算样本点之间的距离。为了减少计算距离次数，提升 KNN 的搜索效率，人们提出了 KD 树（K-Dimensional 的缩写）。KD 树是对数据点在 K 维空间中划分的一种数据结构。在 KD 树的构造中，每个节点都是 k 维数值点的二叉树。既然是二叉树，就可以采用二叉树的增删改查操作，这样就大大提升了搜索效率。 在这里，我们不需要对 KD 树的数学原理了解太多，你只需要知道它是一个二叉树的数据结构，方便存储 K 维空间的数据就可以了。而且在 sklearn 中，我们直接可以调用 KD 树，很方便。 用 KNN 做回归KNN 不仅可以做分类，还可以做回归。首先讲下什么是回归。在开头电影这个案例中，如果想要对未知电影进行类型划分，这是一个分类问题。首先看一下要分类的未知电影，离它最近的 K 部电影大多数属于哪个分类，这部电影就属于哪个分类。 如果是一部新电影，已知它是爱情片，想要知道它的打斗次数、接吻次数可能是多少，这就是一个回归问题。 那么 KNN 如何做回归呢？ 对于一个新点，我们需要找出这个点的 K 个最近邻居，然后将这些邻居的属性的平均值赋给该点，就可以得到该点的属性。当然不同邻居的影响力权重可以设置成不同的。举个例子，比如一部电影 A，已知它是动作片，当 K=3 时，最近的 3 部电影是《战狼》，《红海行动》和《碟中谍 6》，那么它的打斗次数和接吻次数的预估值分别为 (100+95+105)/3=100 次、(5+3+31)/3=13 次。 KNN用途KNN 的理论简单直接，针对 KNN 中的搜索也有相应的 KD 树这个数据结构。KNN 的理论成熟，可以应用到线性和非线性的分类问题中，也可以用于回归分析。 不过 KNN 需要计算测试点与样本点之间的距离，当数据量大的时候，计算量是非常庞大的，需要大量的存储空间和计算时间。另外如果样本分类不均衡，比如有些分类的样本非常少，那么该类别的分类准确率就会低很多。 当然在实际工作中，我们需要考虑到各种可能存在的情况，比如针对某类样本少的情况，可以增加该类别的权重。 同样 KNN 也可以用于推荐算法，虽然现在很多推荐系统的算法会使用 TD-IDF、协同过滤、Apriori 算法，不过针对数据量不大的情况下，采用 KNN 作为推荐算法也是可行的。 手写体识别12345678910111213141516171819202122232425262728293031323334353637383940414243444546from sklearn.model_selection import train_test_splitfrom sklearn import preprocessingfrom sklearn.metrics import accuracy_scorefrom sklearn.datasets import load_digitsfrom sklearn.neighbors import KNeighborsClassifierfrom sklearn.svm import SVCfrom sklearn.naive_bayes import MultinomialNBfrom sklearn.tree import DecisionTreeClassifierimport matplotlib.pyplot as pltdigits = load_digits()data = digits.data# 分割数据，将 25% 的数据作为测试集，其余作为训练集（你也可以指定其他比例的数据作为训练集）train_x, test_x, train_y, test_y = train_test_split(data, digits.target, test_size=0.25, random_state=33)# 采用 Z-Score 规范化 Z-Score 会将数值规范化为一个标准的正态分布，即均值为 0，方差为 1，数值会包含负数。ss = preprocessing.StandardScaler()train_ss_x = ss.fit_transform(train_x)test_ss_x = ss.transform(test_x)knn = KNeighborsClassifier()knn.fit(train_ss_x, train_y) predict_y = knn.predict(test_ss_x) print(\"KNN 准确率: %.4lf\" % accuracy_score(predict_y, test_y))# 创建 SVM 分类器svm = SVC()svm.fit(train_ss_x, train_y)predict_y=svm.predict(test_ss_x)print('SVM 准确率: %0.4lf' % accuracy_score(predict_y, test_y))# 采用 Min-Max 规范化mm = preprocessing.MinMaxScaler()train_mm_x = mm.fit_transform(train_x)test_mm_x = mm.transform(test_x)# 创建 Naive Bayes 分类器mnb = MultinomialNB()mnb.fit(train_mm_x, train_y) predict_y = mnb.predict(test_mm_x) print(\"多项式朴素贝叶斯准确率: %.4lf\" % accuracy_score(predict_y, test_y))# 创建 CART 决策树分类器dtc = DecisionTreeClassifier()dtc.fit(train_mm_x, train_y) predict_y = dtc.predict(test_mm_x) print(\"CART 决策树准确率: %.4lf\" % accuracy_score(predict_y, test_y)) 1234KNN 准确率: 0.9756SVM 准确率: 0.9867多项式朴素贝叶斯准确率: 0.8844CART 决策树准确率: 0.8600","tags":[{"name":"python","slug":"python","permalink":"https://joshuaqyh.github.io/tags/python/"},{"name":"数据分析","slug":"数据分析","permalink":"https://joshuaqyh.github.io/tags/数据分析/"},{"name":"机器学习","slug":"机器学习","permalink":"https://joshuaqyh.github.io/tags/机器学习/"},{"name":"数据挖掘","slug":"数据挖掘","permalink":"https://joshuaqyh.github.io/tags/数据挖掘/"}]},{"title":"机器学习 | 使用SVM进行乳腺癌检测","date":"2019-02-18T13:14:26.000Z","path":"2019/02/18/机器学习-支持向量机SVM/","text":"关于SVM其基础知识和原理已经在一篇文章中提及到了，戳这里。 本文主要是谈谈如何利用sklearn包中的SVM来进行乳腺癌的检测。 在 sklearn中使用svm通过以下语句即可完成一个SVM模型的创建。 123456789from sklearn import svm# 创建分类模型classfier_model = svm.SVC(C = 1.0, kernel = 'rbf', degree=3, gamma='auto')# svm.LinearSVC 在数据线性可分时使用# 创建回归模型regression_model = svm.SVR(kernel = 'rbf', degree=3, gamma = 'auto')# svm.LinearSVR 在数据线性可分时使用 这里重点关注SVC 的构造函数：model = svm.SVC(kernel=‘rbf’, C=1.0, gamma=‘auto’)，这里有三个重要的参数 kernel、C 和 gamma。 kernel：代表核函数，默认为 rbf 高斯核函数，主要可选项有： inear：线性核函数，在数据为线性可分时，运算速度快，效果好，无法处理线性不可分的数据。 poly：多项式核函数，可以将数据从低维空间映射到高维空间，但是参数较多，计算两大。 rbf：高斯核函数（默认），将样本映射到高维空间，但是相较于多项式核函数来说参数较少，性能不错。 sigmoid：sigmoid 核函数，当选用sigmoid，svm实现的时多层神经网络。 C代表的是目标函数的惩罚系数，惩罚系数指的是分错样本时的惩罚程度。当 C 越大的时候，分类器的准确性越高，但同样容错率会越低，泛化能力会变差。相反，C 越小，泛化能力越强，但是准确性会降低。 gamma 代表核函数的系数，默认为样本特征数的倒数，即 gamma = 1 / n_features。 然后训练和预测的方式是： 12model.fit(train_X,train_y)model.predict(test_X) 使用SVM进行乳腺癌检测首先必须确定的是，乳腺癌检测是一个分类问题。 检测存在两个过程： 数据准备阶段： 数据加载：加载数据集； 数据清洗：删除无关的列，对列数据属性进行变换或者映射； 特征选择：一般是剔除无关特征，运用降维方式，用少量特征代表数据的特性，增强分类器的泛化能力，避免数据过拟合。 数据规范化：Z-score等等 分类阶段： 创建模型 训练模型 预测模型 评估模型 整个过程的代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263import pandas as pdimport matplotlib.pyplot as pltimport seaborn as snsfrom sklearn.model_selection import train_test_splitfrom sklearn import svmfrom sklearn import metricsfrom sklearn.preprocessing import StandardScaler\"\"\"代码来自：https://github.com/cystanford?tab=repositories\"\"\"# 加载数据集，你需要把数据放到目录中data = pd.read_csv(\"./breast_cancer_data.csv\")# 数据探索# 因为数据集中列比较多，我们需要把 dataframe 中的列全部显示出来pd.set_option('display.max_columns', None)print(data.columns)print(data.head(5))print(data.describe())# 将特征字段分成 3 组features_mean= list(data.columns[2:12])features_se= list(data.columns[12:22])features_worst=list(data.columns[22:32])# 数据清洗# ID 列没有用，删除该列data.drop(\"id\",axis=1,inplace=True)# 将 B 良性替换为 0，M 恶性替换为 1data['diagnosis']=data['diagnosis'].map(&#123;'M':1,'B':0&#125;)# 将肿瘤诊断结果可视化sns.countplot(data['diagnosis'],label=\"Count\")plt.show()# 用热力图呈现 features_mean 字段之间的相关性corr = data[features_mean].corr()plt.figure(figsize=(14,14))# annot=True 显示每个方格的数据sns.heatmap(corr, annot=True)plt.show()# 特征选择features_remain = ['radius_mean','texture_mean', 'smoothness_mean','compactness_mean','symmetry_mean', 'fractal_dimension_mean'] # 抽取 30% 的数据作为测试集，其余作为训练集train, test = train_test_split(data, test_size = 0.3)# in this our main data is splitted into train and test# 抽取特征选择的数值作为训练和测试数据train_X = train[features_remain]train_y=train['diagnosis']test_X= test[features_remain]test_y =test['diagnosis']# 采用 Z-Score 规范化数据，保证每个特征维度的数据均值为 0，方差为 1ss = StandardScaler()train_X = ss.fit_transform(train_X)test_X = ss.transform(test_X)# 创建模型classifier_model = svm.SVC(C = 1.0, kernel = 'rbf', degree=3, gamma='auto')classifier_model.fit(train_X, train_y)prediction = classifier_model.predict(test_X)print (\"准确率： \", metrics.accuracy_score(prediction, test_y)) 这是运行的结果： img img 其中的特征选择问题： 热力图中对角线上的为单变量自身的相关系数是 1。颜色越浅代表相关性越大。所以你能看出来 radius_mean、perimeter_mean 和 area_mean 相关性非常大，compactness_mean、concavity_mean、concave_points_mean 这三个字段也是相关的，因此我们可以取其中的一个作为代表。 特征选择的目的是降维，用少量的特征代表数据的特性，这样也可以增强分类器的泛化能力，避免数据过拟合。 所以我们可以将相关性较强的一组特征视为一类，然后选出一个特征代表该类。 我们能看到 mean、se 和 worst 这三组特征是对同一组内容的不同度量方式，我们可以保留 mean 这组特征，在特征选择中忽略掉 se 和 worst。同时我们能看到 mean 这组特征中，radius_mean、perimeter_mean、area_mean 这三个属性相关性大，compactness_mean、daconcavity_mean、concave points_mean 这三个属性相关性大。我们分别从这 2 类中选择 1 个属性作为代表，比如 radius_mean 和 compactness_mean。 这样我们就可以把原来的 10 个属性缩减为 6 个属性，代码如下： 1features_remain = ['radius_mean','texture_mean', 'smoothness_mean','compactness_mean','symmetry_mean', 'fractal_dimension_mean']","tags":[{"name":"python","slug":"python","permalink":"https://joshuaqyh.github.io/tags/python/"},{"name":"数据分析","slug":"数据分析","permalink":"https://joshuaqyh.github.io/tags/数据分析/"},{"name":"机器学习","slug":"机器学习","permalink":"https://joshuaqyh.github.io/tags/机器学习/"},{"name":"数据挖掘","slug":"数据挖掘","permalink":"https://joshuaqyh.github.io/tags/数据挖掘/"}]},{"title":"机器学习 | 朴素贝叶斯分类","date":"2019-02-18T11:27:58.000Z","path":"2019/02/18/机器学习-朴素贝叶斯分类/","text":"贝叶斯原理基本概念贝叶斯原理其实是在求解一个逆向概率的问题。 我们用一个题目来体会下：假设有一种病叫做“贝叶死”，它的发病率是万分之一，即 10000 人中会有 1 个人得病。现有一种测试可以检验一个人是否得病的准确率是 99.9%，它的误报率是 0.1%，那么现在的问题是，如果一个人被查出来患有“叶贝死”，实际上患有的可能性有多大？ 你可能会想说，既然查出患有“贝叶死”的准确率是 99.9%，那是不是实际上患“贝叶死”的概率也是 99.9% 呢？实际上不是的。你自己想想，在 10000 个人中，还存在 0.1% 的误查的情况，也就是 10 个人没有患病但是被诊断成阳性。当然 10000 个人中，也确实存在一个患有贝叶死的人，他有 99.9% 的概率被检查出来。所以你可以粗算下，患病的这个人实际上是这 11 个人里面的一员，即实际患病比例是 1/11≈9%。 以上涉及了贝叶斯原理的几个核心概念： 先验概率：通过经验来判断事情发生的概率，比如说“贝叶死”的发病率是万分之一，就是先验概率。再比如南方的梅雨季是 6-7 月，就是通过往年的气候总结出来的经验，这个时候下雨的概率就比其他时间高出很多。 后验概率：后验概率就是发生结果之后，推测原因的概率。比如说某人查出来了患有“贝叶死”，那么患病的原因可能是 A、B 或 C。患有“贝叶死”是因为原因 A 的概率就是后验概率。它是属于条件概率的一种。 条件概率：事件 A 在另外一个事件 B 已经发生条件下的发生概率，表示为 P(A|B)，读作“在 B 发生的条件下 A 发生的概率”。比如原因 A 的条件下，患有“贝叶死”的概率，就是条件概率。 联合概率：多个事件同时发生的概率。 联合分布：多个事件发生多个结果的概率分布情况。 似然函数：你可以把概率模型的训练过程理解为求参数估计的过程。举个例子，如果一个硬币在 10 次抛落中正面均朝上。那么你肯定在想，这个硬币是均匀的可能性是多少？这里硬币均匀就是个参数，似然函数就是用来衡量这个模型的参数。似然在这里就是可能性的意思，它是关于统计参数的函数。 贝叶斯公式一般的二元贝叶斯公式如下： 由此，我们可以得出通用的贝叶斯公式： img 其实贝叶斯原理的可以通过条件概率公式来推理得到。 $P(Y|X)P(X)=P(X|Y)P(Y)=P(XY)P(Y|X)P(X)=P(X|Y)P(Y)=P(XY)$ 放在实例中来观察贝叶斯公式的简单应用。在医疗诊断中，如果医生知道某一疾病发生某些症状的概率，那么可以利用贝叶斯公式估计得知当病人发生某症状时，推测病人发生某病的概率。 贝叶斯公式其实是反映了原因和结果之间的概率关系。 朴素贝叶斯算法朴素贝叶斯算法是一种简单但极为强大的预测建模算法。之所以称为朴素贝叶斯，是因为它假设每一个输入变量之间是独立的。 朴素贝叶斯模型由两种类型的概率组成： 每个类别的概率$P(C_j)$； 每个属性的条件概率$P(Ai|C_j)$。 朴素贝叶斯的公式如下： $P(Cause,Effect_1,Effect_2,Effect_3….Effect_n)=P(Cause)∏_nP(Effect_i|Cause)$ 为了训练朴素贝叶斯模型，我们需要先给出训练数据，以及这些数据对应的分类。那么上面这两个概率，也就是类别概率和条件概率。他们都可以从给出的训练数据中计算出来。一旦计算出来，概率模型就可以使用贝叶斯原理对新数据进行预测。 贝叶斯原理 贝叶斯分类 朴素贝叶斯之间的区别贝叶斯原理是最大的概念，它解决了概率论中“逆向概率”的问题，在这个理论基础上，人们设计出了贝叶斯分类器，朴素贝叶斯分类是贝叶斯分类器中的一种，也是最简单，最常用的分类器。朴素贝叶斯之所以朴素是因为它假设属性是相互独立的，因此对实际情况有所约束，如果属性之间存在关联，分类准确率会降低。不过好在对于大部分情况下，朴素贝叶斯的分类效果都不错。 img 朴素贝叶斯分类器工作流程朴素贝叶斯分类常用于文本分类，尤其是对于英文等语言来说，分类效果很好。它常用于垃圾文本过滤、情感预测、推荐系统等。 流程可以用下图表示： img 从图片你也可以看出来，朴素贝叶斯分类器需要三个流程，我来给你一一讲解下这几个流程。 第一阶段：准备阶段 在这个阶段我们需要确定特征属性，比如上面案例中的“身高”、“体重”、“鞋码”等，并对每个特征属性进行适当划分，然后由人工对一部分数据进行分类，形成训练样本。 这一阶段是整个朴素贝叶斯分类中唯一需要人工完成的阶段，其质量对整个过程将有重要影响，分类器的质量很大程度上由特征属性、特征属性划分及训练样本质量决定。 第二阶段：训练阶段 这个阶段就是生成分类器，主要工作是计算每个类别在训练样本中的出现频率及每个特征属性划分对每个类别的条件概率。 输入是特征属性和训练样本，输出是分类器。 第三阶段：应用阶段 这个阶段是使用分类器对新数据进行分类。输入是分类器和新数据，输出是新数据的分类结果。 利用朴素贝叶斯进行文档分类朴素贝叶斯分类最适合的场景就是文本分类、情感分析和垃圾邮件识别。其中情感分析和垃圾邮件识别都是通过文本来进行判断。从这里你能看出来，这三个场景本质上都是文本分类，这也是朴素贝叶斯最擅长的地方。所以朴素贝叶斯也常用于自然语言处理 NLP 的工具。 以下是高斯朴素贝叶斯分类器的类简单实现。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758class NaiveBayes: def __init__(self): self.model = None # 求一组数据的数学期望，静态方法无需传入self @staticmethod def mean(X): return sum(X) / float(len(X)) # 求一组数据的标准差（方差） def stdev(self, X): avg = self.mean(X) return math.sqrt(sum([pow(x-avg, 2) for x in X]) / float(len(X))) # 概率密度函数。正态分布函数 def gaussian_probability(self, x, mean, stdev): exponent = math.exp(-(math.pow(x-mean,2)/(2*math.pow(stdev,2)))) return (1 / (math.sqrt(2*math.pi) * stdev)) * exponent # 处理X_train，得到均值和标准差 def summarize(self, train_data): summaries = [(self.mean(i), self.stdev(i)) for i in zip(*train_data)] return summaries # 分类别求出数学期望和标准差，然后拟合。 def fit(self, X, y): labels = list(set(y)) data = &#123;label:[] for label in labels&#125; for f, label in zip(X, y): data[label].append(f) self.model = &#123;label: self.summarize(value) for label, value in data.items()&#125; return 'gaussianNB train done!' # 计算概率 def calculate_probabilities(self, input_data): # summaries:&#123;0.0: [(5.0, 0.37),(3.42, 0.40)], 1.0: [(5.8, 0.449),(2.7, 0.27)]&#125; # input_data:[1.1, 2.2] probabilities = &#123;&#125; for label, value in self.model.items(): probabilities[label] = 1 for i in range(len(value)): mean, stdev = value[i] probabilities[label] *= self.gaussian_probability(input_data[i], mean, stdev) return probabilities # 类别 def predict(self, X_test): # &#123;0.0: 2.9680340789325763e-27, 1.0: 3.5749783019849535e-26&#125; label = sorted(self.calculate_probabilities(X_test).items(), key=lambda x: x[-1])[-1][0] return label def score(self，X_test, y_test): right = 0 for X, y in zip(X_test, y_test): label = self.predict(X) if label == y: right += 1 return right / float(len(X_test)) 此外，我们直接使用 sklearn 机器学习包来帮助我们使用朴素贝叶斯分类算法。 sklearn 机器学习包sklearn 的全称叫 Scikit-learn，它给我们提供了 3 个朴素贝叶斯分类算法，分别是高斯朴素贝叶斯（GaussianNB）、多项式朴素贝叶斯（MultinomialNB）和伯努利朴素贝叶斯（BernoulliNB）。 这三种算法适合应用在不同的场景下，我们应该根据特征变量的不同选择不同的算法： 高斯朴素贝叶斯：特征变量是连续变量，符合高斯分布，比如说人的身高，物体的长度。 多项式朴素贝叶斯：特征变量是离散变量，符合多项分布，在文档分类中特征变量体现在一个单词出现的次数，或者是单词的 TF-IDF 值等。 伯努利朴素贝叶斯：特征变量是布尔变量，符合 0/1 分布，在文档分类中特征是单词是否出现。 伯努利朴素贝叶斯是以文件为粒度，如果该单词在某文件中出现了即为 1，否则为 0。而多项式朴素贝叶斯是以单词为粒度，会计算在某个文件中的具体次数。而高斯朴素贝叶斯适合处理特征变量是连续变量，且符合正态分布（高斯分布）的情况。比如身高、体重这种自然界的现象就比较适合用高斯朴素贝叶斯来处理。而文本分类是使用多项式朴素贝叶斯或者伯努利朴素贝叶斯。 TF-IDFTF-IDF 实际上是两个词组 Term Frequency 和 Inverse Document Frequency 的总称，两者缩写为 TF 和 IDF，分别代表了词频和逆向文档频率。 词频 TF计算了一个单词在文档中出现的次数，它认为一个单词的重要性和它在文档中出现的次数呈正比。 逆向文档频率 IDF，是指一个单词在文档中的区分度。它认为一个单词出现在的文档数越少，就越能通过这个单词把该文档和其他文档区分开。IDF 越大就代表该单词的区分度越大。 所以 TF-IDF 实际上是词频 TF 和逆向文档频率 IDF 的乘积。这样我们倾向于找到 TF 和 IDF 取值都高的单词作为区分，即这个单词在一个文档中出现的次数多，同时又很少出现在其他文档中。这样的单词适合用于分类。 首先我们看下词频 TF 和逆向文档概率 IDF 的公式。 img img 为什么 IDF 的分母中，单词出现的文档数要加 1 呢？因为有些单词可能不会存在文档中，为了避免分母为 0，统一给单词出现的文档数都加 1。 TF-IDF=TF*IDF。 你可以看到，TF-IDF 值就是 TF 与 IDF 的乘积, 这样可以更准确地对文档进行分类。比如“我”这样的高频单词，虽然 TF 词频高，但是 IDF 值很低，整体的 TF-IDF 也不高。 我在这里举个例子。假设一个文件夹里一共有 10 篇文档，其中一篇文档有 1000 个单词，“this”这个单词出现 20 次，“bayes”出现了 5 次。“this”在所有文档中均出现过，而“bayes”只在 2 篇文档中出现过。我们来计算一下这两个词语的 TF-IDF 值。 针对“this”，计算 TF-IDF 值： img img 所以 TF-IDF=0.02*(-0.0414)=-8.28e-4。 针对“bayes”，计算 TF-IDF 值： img img TF-IDF=0.005*0.5229=2.61e-3。 很明显“bayes”的 TF-IDF 值要大于“this”的 TF-IDF 值。这就说明用“bayes”这个单词做区分比单词“this”要好。 使用sklearn 来计算 TF-IDF1234567891011121314151617181920212223from sklearn.feature_extraction.text import TfidfVectorizer# create a object to calculate TF-IDF# TfidfVectorizer(stop_words=stop_words, token_pattern=token_pattern)# * stop_words 指的是：在分类中没有用的单词，对分类起不到作用，减少计算浪费。# * token_pattern 使用正则表达式定义过滤规则tfidf_vec = TfidfVectorizer()# the fitting datadocuments = [ 'this is the bayes document', 'this is the second second document', 'and the third one', 'is this the document']# calcualte TF-IDF，拟合模型，返回TF—IDF计算结果矩阵。tfidf_matrix = tfidf_vec.fit_transform(documents)print('不重复的词:', tfidf_vec.get_feature_names())print('每个单词的 ID:', tfidf_vec.vocabulary_)print('每个单词的 tfidf 值:', tfidf_matrix.toarray()) 对文档进行分类如果我们要对文档进行分类，有两个重要的阶段： img 基于分词的数据准备，包括分词、单词权重计算、去掉停用词； 应用朴素贝叶斯分类进行分类，首先通过训练集得到朴素贝叶斯分类器，然后将分类器应用于测试集，并与实际结果做对比，最终得到测试集的分类准确率。 分词在准备阶段，分词是比较重要的一个环节。在英文文档中分词的工具为NLTK包，而中文文档则是使用了 jieba包。 123import nltkword_list = nltk.word_tokenize(text) # 分词nltk.pos_tag(word_list) # 标注单词的词性 12import jiebaword_list = jieba.cut (text) # 中文分词 加载停用词表我们需要自己读取停用词表文件，从网上可以找到中文常用的停用词保存在 stop_words.txt，然后利用 Python 的文件读取函数读取文件，保存在 stop_words 数组中。 1stop_words = [line.strip().decode('utf-8') for line in io.open('stop_words.txt').readlines()] 计算单词的权重 TF-IDF直接创建 TfidfVectorizer 类，然后使用 fit_transform 方法进行拟合，得到 TF-IDF 特征空间 features，你可以理解为选出来的分词就是特征。我们计算这些特征在文档上的特征向量，得到特征空间 features。 12tf = TfidfVectorizer(stop_words=stop_words, max_df=0.5)features = tf.fit_transform(train_contents) 这里 max_df 参数用来描述单词在文档中的最高出现率。假设 max_df=0.5，代表一个单词在 50% 的文档中都出现过了，那么它只携带了非常少的信息，因此就不作为分词统计。 生成朴素贝叶斯分类器我们将特征训练集的特征空间 train_features，以及训练集对应的分类 train_labels 传递给贝叶斯分类器 clf，它会自动生成一个符合特征空间和对应分类的分类器。 这里我们采用的是多项式贝叶斯分类器，其中 alpha 为平滑参数。为什么要使用平滑呢？因为如果一个单词在训练样本中没有出现，这个单词的概率就会被计算为 0。但训练集样本只是整体的抽样情况，我们不能因为一个事件没有观察到，就认为整个事件的概率为 0。为了解决这个问题，我们需要做平滑处理。 当 alpha=1 时，使用的是 Laplace 平滑。Laplace 平滑就是采用加 1 的方式，来统计没有出现过的单词的概率。这样当训练样本很大的时候，加 1 得到的概率变化可以忽略不计，也同时避免了零概率的问题。 当 0&lt;alpha&lt;1 时，使用的是 Lidstone 平滑。对于 Lidstone 平滑来说，alpha 越小，迭代次数越多，精度越高。我们可以设置 alpha 为 0.001。 123# 多项式贝叶斯分类器from sklearn.naive_bayes import MultinomialNB # GuassianNB BernoulliNBclf = MultinomialNB(alpha=0.001).fit(train_features, train_labels) 使用生成的分类器做预测首先我们需要得到测试集的特征矩阵。 方法是用训练集的分词创建一个 TfidfVectorizer 类，使用同样的 stop_words 和 max_df，然后用这个 TfidfVectorizer 类对测试集的内容进行 fit_transform 拟合，得到测试集的特征矩阵 test_features。 12test_tf = TfidfVectorizer(stop_words=stop_words, max_df=0.5, vocabulary=train_vocabulary)test_features=test_tf.fit_transform(test_contents) 然后我们用训练好的分类器对新数据做预测。 方法是使用 predict 函数，传入测试集的特征矩阵 test_features，得到分类结果 predicted_labels。predict 函数做的工作就是求解所有后验概率并找出最大的那个。 1predicted_labels=clf.predict(test_features) 计算准确率12from sklearn import metricsprint metrics.accuracy_score(test_labels, predicted_labels)","tags":[{"name":"python","slug":"python","permalink":"https://joshuaqyh.github.io/tags/python/"},{"name":"数据分析","slug":"数据分析","permalink":"https://joshuaqyh.github.io/tags/数据分析/"},{"name":"机器学习","slug":"机器学习","permalink":"https://joshuaqyh.github.io/tags/机器学习/"},{"name":"数据挖掘","slug":"数据挖掘","permalink":"https://joshuaqyh.github.io/tags/数据挖掘/"}]},{"title":"机器学习 | 决策树","date":"2019-02-18T02:18:21.000Z","path":"2019/02/18/机器学习-决策树/","text":"决策树的工作原理定义决策树就是根据已有的规则条件进行评判，给出决策结果。 一棵决策树一般包括根结点，内部结点，和叶节点。根结点是一开始的判断条件，内部结点是中间过程的判断条件，而叶结点则对应着决策结果。 使用决策树时一般会经历两个阶段：构造和剪枝。 构造决策树的构造过程就是选择什么样的属性作为决策结点的过程。我们需要经过计算合理构造节点之间的关系。 在构造过程中，要解决三个重要的问题： 选择哪个属性作为根节点； 选择哪些属性作为子节点； 什么时候停止并得到目标状态，即叶节点。 ​ 剪枝剪枝相当于给决策瘦身，避免了许多无谓的决策判断，尤其在处理大型决策树的时候，剪枝尤为必要。同时这么做，也是为了防止过拟合的现象产生。 “过拟合”指的就是模型的训练结果“太好了”，以至于在实际应用的过程中，会存在“死板”的情况，导致分类错误。 造成过拟合的原因之一就是因为训练集中样本量较小。如果决策树选择的属性过多，构造出来的决策树一定能够“完美”地把训练集中的样本分类，但是这样就会把训练集中一些数据的特点当成所有数据的特点，但这个特点不一定是全部数据的特点，这就使得这个决策树在真实的数据分类中出现错误，也就是模型的“泛化能力”差。 泛化能力指的分类器是通过训练集抽象出来的分类能力，你也可以理解是举一反三的能力。如果我们太依赖于训练集的数据，那么得到的决策树容错率就会比较低，泛化能力差。因为训练集只是全部数据的抽样，并不能体现全部数据的特点。 剪枝的方法 预剪枝（pre-pruning） 后剪枝（post-pruning) 预剪枝就是在决策树开始构造的时候就进行剪枝，方法是在构造的过程中对节点进行评估，如果对某个节点进行划分，在验证集中就不能带来准确性的提升，那么对该节点就没有必要进行划分，此时就将当前节点视为叶节点。 后剪枝就是在生成决策树之后再进行剪枝，通常会从决策树的叶节点开始，逐层向上对每个节点进行评估。如果剪掉这个节点子树，与保留该节点子树在分类准确性上差别不大，或者剪掉该节点子树，能在验证集中带来准确性的提升，那么就可以把该节点子树进行剪枝。方法是：用这个节点子树的叶子节点来替代该节点，类标记为这个节点子树中最频繁的那个类。 决策树构造指标如何构造一个根据天气情况来判断是否去打篮球的决策树？以下是一个简单的数据集。 接下来进行简单的构造，我们必须思考以下问题： 哪个属性划分效果做好，作为根节点？ 哪些属性作为后继节点？ 什么时候停止划分，得到叶节点？ 我们使用信息熵（entropy）来作为划分的指标，它表示了信息的不确定性。我们假设随机变量 $I$ 具有值 $i$，$i$ 的概率为$p_i$。 信息熵的数学公式如下：$H(x) = - \\sum_{i =1}^{n} p_i log_2p_i$ 同样还有其他信息指标： conditional entropy（条件熵）: $H(X|Y)=\\sum{P(X|Y)}\\log_2{P(X|Y)}$ information gain（信息增益） : $g(D, A)=H(D)-H(D|A)$ information gain ratio（信息增益比）: $g_R(D, A) = \\frac{g(D,A)}{H(A)}$ gini index（基尼指数）:$Gini(D)=\\sum_{k=1}^{K}p_k\\log{p_k}=1-\\sum_{k=1}^{K}p_k^2$ 信息增益越大越好，分类更正确 信息增益越大，信息给你带来的混乱程度越小。 信息论中熵越大，混乱程度越大，信息量越小，信息增益更小。 故信息增益越大的特征，在决策树上的越高。 存在多种决策树： ID3 决策树 （基于信息增益划分） C4.5 决策树（基于信息增益比） CART 决策树 （基尼指数 ） ID3算法简单，但解释性强，但存在缺陷，有些属性对分类任务没有太大作用，但是依旧有可能被选为最优属性。 在针对ID3算法，做了改进，于是又了C4.5算法。在 C4.5 中，会在决策树构造之后采用悲观剪枝（PEP），这样可以提升决策树的泛化能力。 悲观剪枝是后剪枝技术中的一种，通过递归估算每个内部节点的分类错误率，比较剪枝前后这个节点的分类错误率来决定是否对其进行剪枝。这种剪枝方法不再需要一个单独的测试数据集。 C4.5 可以处理连续属性的情况，对连续的属性进行离散化的处理。比如打篮球存在的“湿度”属性，不按照“高、中”划分，而是按照湿度值进行计算，那么湿度取什么值都有可能。该怎么选择这个阈值呢，C4.5 选择具有最高信息增益的划分所对应的阈值。 C4.5 在 ID3 的基础上，用信息增益率代替了信息增益，解决了噪声敏感的问题，并且可以对构造树进行剪枝、处理连续数值以及数值缺失等情况，但是由于 C4.5 需要对数据集进行多次扫描，算法效率相对较低。 决策树构造代码 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116# 定义节点类 二叉树class Node: def __init__(self, root=True, label=None, feature_name=None, feature=None): self.root = root self.label = label self.feature_name = feature_name self.feature = feature self.tree = &#123;&#125; self.result = &#123;'label:': self.label, 'feature': self.feature, 'tree': self.tree&#125; def __repr__(self): return '&#123;&#125;'.format(self.result) def add_node(self, val, node): self.tree[val] = node def predict(self, features): if self.root is True: return self.label return self.tree[features[self.feature]].predict(features) class DTree: def __init__(self, epsilon=0.1): self.epsilon = epsilon self._tree = &#123;&#125; # 熵 @staticmethod def calc_ent(datasets): data_length = len(datasets) label_count = &#123;&#125; for i in range(data_length): label = datasets[i][-1] if label not in label_count: label_count[label] = 0 label_count[label] += 1 ent = -sum([(p/data_length)*log(p/data_length, 2) for p in label_count.values()]) return ent # 经验条件熵 def cond_ent(self, datasets, axis=0): data_length = len(datasets) feature_sets = &#123;&#125; for i in range(data_length): feature = datasets[i][axis] if feature not in feature_sets: feature_sets[feature] = [] feature_sets[feature].append(datasets[i]) cond_ent = sum([(len(p)/data_length)*self.calc_ent(p) for p in feature_sets.values()]) return cond_ent # 信息增益 @staticmethod def info_gain(ent, cond_ent): return ent - cond_ent def info_gain_train(self, datasets): count = len(datasets[0]) - 1 ent = self.calc_ent(datasets) best_feature = [] for c in range(count): c_info_gain = self.info_gain(ent, self.cond_ent(datasets, axis=c)) best_feature.append((c, c_info_gain)) # 比较大小 best_ = max(best_feature, key=lambda x: x[-1]) return best_ def train(self, train_data): \"\"\" input:数据集D(DataFrame格式)，特征集A，阈值eta output:决策树T \"\"\" _, y_train, features = train_data.iloc[:, :-1], train_data.iloc[:, -1], train_data.columns[:-1] # 1,若D中实例属于同一类Ck，则T为单节点树，并将类Ck作为结点的类标记，返回T if len(y_train.value_counts()) == 1: return Node(root=True, label=y_train.iloc[0]) # 2, 若A为空，则T为单节点树，将D中实例树最大的类Ck作为该节点的类标记，返回T if len(features) == 0: return Node(root=True, label=y_train.value_counts().sort_values(ascending=False).index[0]) # 3,计算最大信息增益 同5.1,Ag为信息增益最大的特征 max_feature, max_info_gain = self.info_gain_train(np.array(train_data)) max_feature_name = features[max_feature] # 4,Ag的信息增益小于阈值eta,则置T为单节点树，并将D中是实例数最大的类Ck作为该节点的类标记，返回T if max_info_gain &lt; self.epsilon: return Node(root=True, label=y_train.value_counts().sort_values(ascending=False).index[0]) # 5,构建Ag子集 node_tree = Node(root=False, feature_name=max_feature_name, feature=max_feature) feature_list = train_data[max_feature_name].value_counts().index for f in feature_list: sub_train_df = train_data.loc[train_data[max_feature_name] == f].drop([max_feature_name], axis=1) # 6, 递归生成树 sub_tree = self.train(sub_train_df) node_tree.add_node(f, sub_tree) # pprint.pprint(node_tree.tree) return node_tree def fit(self, train_data): self._tree = self.train(train_data) return self._tree def predict(self, X_test): return self._tree.predict(X_test) datasets, labels = create_data()data_df = pd.DataFrame(datasets, columns=labels)dt = DTree()tree = dt.fit(data_df) CART算法我们使用CART算法来生成一个分类回归决策树。ID3 和 C4.5算法可以生成多叉树，但是CART只支持二叉树。 分类树可以处理离散数据，也就是数据种类有限的数据，它输出的是样本的类别，而回归树可以对连续型的数值进行预测，也就是数据在某个区间内都有取值的可能，它输出的是一个数值。 我们使用基尼系数 来对样本进行划分。基尼系数越小，越稳定。 假设 t 为节点，那么该节点的 GINI 系数的计算公式为： img 这里 p(Ck|t) 表示节点 t 属于类别 Ck 的概率，节点 t 的基尼系数为 1 减去各类别 Ck 概率平方和。 通过下面这个例子，我们计算一下两个集合的基尼系数分别为多少： 集合 1：6 个都去打篮球； 集合 2：3 个去打篮球，3 个不去打篮球。 针对集合 1，所有人都去打篮球，所以 p(Ck|t)=1，因此 GINI(t)=1-1=0。 针对集合 2，有一半人去打篮球，而另一半不去打篮球，所以，p(C1|t)=0.5，p(C2|t)=0.5，GINI(t)=1-（0.50.5+0.50.5）=0.5。 通过两个基尼系数你可以看出，集合 1 的基尼系数最小，也证明样本最稳定，而集合 2 的样本不稳定性更大。 在 CART 算法中，基于基尼系数对特征属性进行二元分裂。 假设属性 A 将节点 D 划分成了 D1 和 D2，如下图所示： img 节点 D 的基尼系数等于子节点 D1 和 D2 的归一化基尼系数之和，用公式表示为： img 归一化基尼系数代表的是每个子节点的基尼系数乘以该节点占整体父亲节点 D 中的比例。 分类决策树我们使用python中的 sklearn库来完成CART分类决策树。 123456789101112131415161718192021# encoding=utf-8from sklearn.model_selection import train_test_splitfrom sklearn.metrics import accuracy_scorefrom sklearn.tree import DecisionTreeClassifierfrom sklearn.datasets import load_iris# 准备数据集iris=load_iris()# 获取特征集和分类标识features = iris.datalabels = iris.target# 随机抽取 33% 的数据作为测试集，其余为训练集train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.33, random_state=0)# 创建 CART 分类树clf = DecisionTreeClassifier(criterion='gini')# 拟合构造 CART 分类树clf = clf.fit(train_features, train_labels)# 用 CART 分类树做预测test_predict = clf.predict(test_features)# 预测结果与测试集结果作比对score = accuracy_score(test_labels, test_predict)print(\"CART 分类树准确率 %.4lf\" % score) 回归决策树CART 回归树划分数据集的过程和分类树的过程是一样的，只是回归树得到的预测结果是连续值，而且评判“不纯度”的指标不同。在 CART 分类树中采用的是基尼系数作为标准，那么在 CART 回归树中，如何评价“不纯度”呢？实际上我们要根据样本的混乱程度，也就是样本的离散程度来评价“不纯度”。 样本的离散程度具体的计算方式是，先计算所有样本的均值，然后计算每个样本值到均值的差值。我们假设 x 为样本的个体，均值为 u。为了统计样本的离散程度，我们可以取差值的绝对值，或者方差。 其中差值的绝对值为样本值减去样本均值的绝对值： img 方差为每个样本值减去样本均值的平方和除以样本个数： img 所以这两种节点划分的标准，分别对应着两种目标函数最优化的标准，即用最小绝对偏差（LAD），或者使用最小二乘偏差（LSD）。这两种方式都可以让我们找到节点划分的方法，通常使用最小二乘偏差的情况更常见一些。 我们可以通过一个例子来看下如何创建一棵 CART 回归树来做预测。 这里我们使用到 sklearn 自带的波士顿房价数据集，该数据集给出了影响房价的一些指标，比如犯罪率，房产税等，最后给出了房价。 根据这些指标，我们使用 CART 回归树对波士顿房价进行预测，代码如下： 123456789101112131415161718192021222324# encoding=utf-8from sklearn.metrics import mean_squared_errorfrom sklearn.model_selection import train_test_splitfrom sklearn.datasets import load_bostonfrom sklearn.metrics import r2_score,mean_absolute_error,mean_squared_errorfrom sklearn.tree import DecisionTreeRegressor# 准备数据集boston=load_boston()# 探索数据print(boston.feature_names)# 获取特征集和房价features = boston.dataprices = boston.target# 随机抽取 33% 的数据作为测试集，其余为训练集train_features, test_features, train_price, test_price = train_test_split(features, prices, test_size=0.33)# 创建 CART 回归树dtr=DecisionTreeRegressor()# 拟合构造 CART 回归树dtr.fit(train_features, train_price)# 预测测试集中的房价predict_price = dtr.predict(test_features)# 测试集的结果评价print('回归树二乘偏差均值:', mean_squared_error(test_price, predict_price))print('回归树绝对值偏差均值:', mean_absolute_error(test_price, predict_price)) CART 决策树的剪枝CART 决策树的剪枝主要采用的是 CCP 方法，它是一种后剪枝的方法，英文全称叫做 cost-complexity prune，中文叫做代价复杂度。这种剪枝方式用到一个指标叫做节点的表面误差率增益值，以此作为剪枝前后误差的定义。用公式表示则是： img 其中 Tt 代表以 t 为根节点的子树，C(Tt) 表示节点 t 的子树没被裁剪时子树 Tt 的误差，C(t) 表示节点 t 的子树被剪枝后节点 t 的误差，|Tt|代子树 Tt 的叶子数，剪枝后，T 的叶子数减少了|Tt|-1。 所以节点的表面误差率增益值等于节点 t 的子树被剪枝后的误差变化除以剪掉的叶子数量。 因为我们希望剪枝前后误差最小，所以我们要寻找的就是最小α值对应的节点，把它剪掉。这时候生成了第一个子树。重复上面的过程，继续剪枝，直到最后只剩下根节点，即为最后一个子树。 得到了剪枝后的子树集合后，我们需要用验证集对所有子树的误差计算一遍。可以通过计算每个子树的基尼指数或者平方误差，取误差最小的那个树，得到我们想要的结果。","tags":[{"name":"python","slug":"python","permalink":"https://joshuaqyh.github.io/tags/python/"},{"name":"数据分析","slug":"数据分析","permalink":"https://joshuaqyh.github.io/tags/数据分析/"},{"name":"机器学习","slug":"机器学习","permalink":"https://joshuaqyh.github.io/tags/机器学习/"}]},{"title":"10 个 python可视化实例 | matplotlib & seaborn","date":"2019-02-17T09:08:32.000Z","path":"2019/02/17/python可视化实例-matplotlib-seaborn/","text":"本文主要介绍了 10 种常用且易于上手的可视化方法，基于python3.7实现。主要使用了两个图形可视化库，matplotlib &amp; seaborn。这两个库的图形效果有细微差别，matplotlib较为流行且支持的可视化图形较多，seaborn也有特有的图形效果，二者搭配使用较佳。 以下提供10种方式的可视化供参考和上手！简单给出示例代码和效果图。 只要记住API的调用方式就能迅速掌握了！ 1. 散点图 scatter123456789101112131415import numpy as npimport pandas as pdimport matplotlib.pyplot as pltimport seaborn as sns# 数据准备N = 1000x = np.random.randn(N)y = np.random.randn(N)# 用 Matplotlib 画散点图plt.scatter(x, y,marker='x')plt.show()# 用 Seaborn 画散点图df = pd.DataFrame(&#123;'x': x, 'y': y&#125;)sns.jointplot(x=\"x\", y=\"y\", data=df, kind='scatter');plt.show() 2. 折线图 plot12345678910111213import pandas as pdimport matplotlib.pyplot as pltimport seaborn as sns# 数据准备x = [2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019]y = [5, 3, 6, 20, 17, 16, 19, 30, 32, 35]# 使用 Matplotlib 画折线图plt.plot(x, y)plt.show()# 使用 Seaborn 画折线图df = pd.DataFrame(&#123;'x': x, 'y': y&#125;)sns.lineplot(x=\"x\", y=\"y\", data=df)plt.show() 3. 直方图 histogram123456789101112131415import numpy as npimport pandas as pdimport matplotlib.pyplot as pltimport seaborn as sns# 数据准备a = np.random.randn(100)s = pd.Series(a) # 用 Matplotlib 画直方图plt.hist(s)plt.show()# 用 Seaborn 画直方图sns.distplot(s, kde=False)plt.show()sns.distplot(s, kde=True)plt.show() 4. 条形图 bar1234567891011import matplotlib.pyplot as pltimport seaborn as sns# 数据准备x = ['Cat1', 'Cat2', 'Cat3', 'Cat4', 'Cat5']y = [5, 4, 8, 12, 7]# 用 Matplotlib 画条形图plt.bar(x, y)plt.show()# 用 Seaborn 画条形图sns.barplot(x, y)plt.show() 5. 箱线图 boxplot1234567891011# 数据准备# 生成 0-1 之间的 10*4 维度数据data=np.random.normal(size=(10,4)) lables = ['A','B','C','D']# 用 Matplotlib 画箱线图plt.boxplot(data,labels=lables)plt.show()# 用 Seaborn 画箱线图df = pd.DataFrame(data, columns=lables)sns.boxplot(data=df)plt.show() 6. 饼图 pie1234567import matplotlib.pyplot as plt# 数据准备nums = [25, 37, 33, 37, 6]labels = ['High-school','Bachelor','Master','Ph.d', 'Others']# 用 Matplotlib 画饼图plt.pie(x = nums, labels=labels)plt.show() 7. 热力图 heat map较为直观的多元变量分析方法。 12345678import matplotlib.pyplot as pltimport seaborn as sns# 数据准备,使用seaborn自带数据集flightsflights = sns.load_dataset(\"flights\")data=flights.pivot('year','month','passengers')# 用 Seaborn 画热力图sns.heatmap(data)plt.show() 8. 蜘蛛图1234567891011121314151617181920import numpy as npimport matplotlib.pyplot as pltimport seaborn as snsfrom matplotlib.font_manager import FontProperties # 数据准备labels=np.array([u\" 推进 \",\"KDA\",u\" 生存 \",u\" 团战 \",u\" 发育 \",u\" 输出 \"])stats=[83, 61, 95, 67, 76, 88]# 画图数据准备，角度、状态值angles=np.linspace(0, 2*np.pi, len(labels), endpoint=False)stats=np.concatenate((stats,[stats[0]]))angles=np.concatenate((angles,[angles[0]]))# 用 Matplotlib 画蜘蛛图fig = plt.figure()ax = fig.add_subplot(111, polar=True) ax.plot(angles, stats, 'o-', linewidth=2)ax.fill(angles, stats, alpha=0.25)# 设置中文字体font = FontProperties(fname=r\"C:\\Windows\\Fonts\\simhei.ttf\", size=14) ax.set_thetagrids(angles * 180/np.pi, labels, FontProperties=font)plt.show() 9. 二元分布图12345678910import matplotlib.pyplot as pltimport seaborn as sns# 数据准备tips = sns.load_dataset(\"tips\")print(tips.head(10))# 用 Seaborn 画二元变量分布图（散点图，核密度图，Hexbin 图）sns.jointplot(x=\"total_bill\", y=\"tip\", data=tips, kind='scatter')sns.jointplot(x=\"total_bill\", y=\"tip\", data=tips, kind='kde')sns.jointplot(x=\"total_bill\", y=\"tip\", data=tips, kind='hex')plt.show() 10. 成对关系图1234567import matplotlib.pyplot as pltimport seaborn as sns# 数据准备iris = sns.load_dataset('iris')# 用 Seaborn 画成对关系sns.pairplot(iris)plt.show() 这里我们用 Seaborn 中的 pairplot 函数来对数据集中的多个双变量的关系进行探索，如下图所示。从图上你能看出，一共有 sepal_length、sepal_width、petal_length 和 petal_width4 个变量，它们分别是花萼长度、花萼宽度、花瓣长度和花瓣宽度。 下面这张图相当于这 4 个变量两两之间的关系。比如矩阵中的第一张图代表的就是花萼长度自身的分布图，它右侧的这张图代表的是花萼长度与花萼宽度这两个变量之间的关系。 更多可视化示例可参考matplotlib 官网上的例子。https://matplotlib.org/gallery/index.html","tags":[{"name":"python","slug":"python","permalink":"https://joshuaqyh.github.io/tags/python/"},{"name":"数据可视化","slug":"数据可视化","permalink":"https://joshuaqyh.github.io/tags/数据可视化/"}]},{"title":"堆栈——C语言实现顺序存储和链式存储","date":"2019-02-09T15:06:33.000Z","path":"2019/02/09/数据结构-堆栈-C语言实现顺序存储和链式存储/","text":"堆栈的顺序存储实现堆栈的顺序存储实现其实是利用了定长数组来模拟堆栈先进后出的规则，由此决定了堆栈的固定容量, 同时需要两个头尾指针来指示栈顶和栈底的位置。 以下展示各部分的代码实现。 定义结构体 1234567typedef int Position;struct QNode &#123; ElementType *Data; /* 存储元素的数组 */ Position Front, Rear; /* 队列的头、尾指针 */ int MaxSize; /* 队列最大容量 */&#125;;typedef struct QNode *Queue; 创建队列 12345678Queue CreateQueue( int MaxSize )&#123; Queue Q = (Queue)malloc(sizeof(struct QNode)); Q-&gt;Data = (ElementType *)malloc(MaxSize * sizeof(ElementType)); Q-&gt;Front = Q-&gt;Rear = 0; Q-&gt;MaxSize = MaxSize; return Q;&#125; 判断堆栈队列是否已满 1234bool IsFull( Queue Q )&#123; return ((Q-&gt;Rear+1)%Q-&gt;MaxSize == Q-&gt;Front);&#125; 添加栈顶元素 123456789101112bool AddQ( Queue Q, ElementType X )&#123; if ( IsFull(Q) ) &#123; printf(\"队列满\"); return false; &#125; else &#123; Q-&gt;Rear = (Q-&gt;Rear+1)%Q-&gt;MaxSize; Q-&gt;Data[Q-&gt;Rear] = X; return true; &#125;&#125; 判断堆栈是否为空 1234bool IsEmpty( Queue Q )&#123; return (Q-&gt;Front == Q-&gt;Rear);&#125; 弹出栈顶元素 1234567891011ElementType DeleteQ( Queue Q )&#123; if ( IsEmpty(Q) ) &#123; printf(\"队列空\"); return ERROR; &#125; else &#123; Q-&gt;Front =(Q-&gt;Front+1)%Q-&gt;MaxSize; return Q-&gt;Data[Q-&gt;Front]; &#125;&#125; 堆栈的链式存储实现堆栈的链式结构实现原理是将栈中的每一个元素视为链表中的每一个结点，利用链表的尾部的增删来实现先进后出的堆栈特点。 定义结构体 123456typedef struct SNode * PtrToSNode;struct SNode &#123; ElementType Data; PtrToSNode Next;&#125;;typedef PtrToSNode Stack; 创建一个链式堆栈 12345678Stack CreateStack( ) &#123; /* 构建一个堆栈的头结点，返回该结点指针 */ Stack S; S = (Stack)malloc(sizeof(struct SNode)); S-&gt;Next = NULL; return S;&#125; 判断堆栈链表是否为空 1234bool IsEmpty ( Stack S )&#123; /* 判断堆栈S是否为空，若是返回true；否则返回false */ return ( S-&gt;Next == NULL );&#125; 元素压入栈顶 12345678910bool Push( Stack S, ElementType X )&#123; /* 将元素X压入堆栈S */ PtrToSNode TmpCell; TmpCell = (PtrToSNode)malloc(sizeof(struct SNode)); TmpCell-&gt;Data = X; TmpCell-&gt;Next = S-&gt;Next; S-&gt;Next = TmpCell; return true;&#125; 弹出栈顶元素 1234567891011121314151617ElementType Pop( Stack S ) &#123; /* 删除并返回堆栈S的栈顶元素 */ PtrToSNode FirstCell; ElementType TopElem; if( IsEmpty(S) ) &#123; printf(\"堆栈空\"); return ERROR; &#125; else &#123; FirstCell = S-&gt;Next; TopElem = FirstCell-&gt;Data; S-&gt;Next = FirstCell-&gt;Next; free(FirstCell); return TopElem; &#125;&#125; ​","tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://joshuaqyh.github.io/tags/数据结构/"},{"name":"C","slug":"C","permalink":"https://joshuaqyh.github.io/tags/C/"}]},{"title":"CH3 | Vector Spaces and Subspaces","date":"2019-02-09T07:28:03.000Z","path":"2019/02/09/CH3-Vector-Spaces-and-Subspaces/","text":"向量空间向量空间定义一个空间 $R^n$ 包含着 所有的 n 维的列向量 v，那么该空间就是向量空间。 还有三种特殊的向量空间 M、F、Z。 子空间 对于子空间的任意两个 v w向量（包括 零向量），满足 v + w 存在子空间中，cv 也在子空间中（可推导得到 v w 的线性组合都在子空间中）。 此时子空间记为 span{v，w} 即： 包含零向量 向量加法封闭 向量乘法封闭 ​ 列空间 对于 Ax = b，我们探讨 A的列空间。 列空间就是矩阵（A）中所有列向量的所有可能线性组合（Ax）的结果 （b），这些结果构成矩阵 （A）列空间C(A)。 对于一个 系统 Ax = b，若是可解的，当且仅当b位于A的列空间之中。 A的零空间：解决 Ax = 0 零空间内部的向量x，经过矩阵A变换，得到的解为0向量。 例子： 给出一个矩阵A的零空间的特殊解，该零空间是特殊解的所有可能的线性组合的结果。 行阶梯矩阵 秩和行简化的形式秩定义矩阵的秩用来描述矩阵的大小，矩阵 A 的秩等于 rank A = 矩阵主元的个数，同时也是矩阵列空间的维数，此外我们也可以用秩来描述矩阵的独立行的个数。 主元 自由变量主元（pivot）的含义就是在简化后矩阵的每一行第一个非0值就是主元.。 自由变量的含义就是就是可以任取的变量，位置处于非主元列的非主元元素。 主元列 自由列主元所在的列叫做主元列，非主元列称为自由列。 自由列可以由未化简之前的主元列进行线性组合得到，线性组合的结果就是特殊解。 从自由列和自由变量可以发现特殊解。 零空间的生成集我们可以利用自由变量和主元来求出零空间的一个生成集。主元可以用其他自由变量线性组合得到，代入原式可以得到一组自由变量作为权的向量组合。 秩为1的矩阵 Ax = b的完全解之前求解Ax = 0 就是 Ax = b 的一个特殊情况（b = 0 向量） 求解Ax = b，我们先设计一个增广矩阵[ A b ],对其进行行简化。 求出一个通解和一个特殊解，然后 完全解 = 通解 + 特殊解 满列秩满列秩矩阵就是主元的个数等于矩阵的行数的矩阵，所有列都具有主元。其性质如下： 满行秩满行秩矩阵的每一行都存在主元。 对于一个 m × n 矩阵，其秩 r 与 m n 之间存在四种可能的情况： 独立性 基 和维度 线性独立 对于一个矩阵来说，线性独立意味着 Ax = 0的解只有 x = 0。零空间中只有 x = 0. 对于一组向量来说，若都处于同一平面的话，则成向量线性依赖，若不在同一平面内，则这组向量线性独立。（一组向量也可以看成一个矩阵） 公式化结果如下： 展开成子空间一组向量扩展成一个空间的条件就是该组向量的线性组合能够填充整个空间。 矩阵A的行空间是$A^T$ 的列空间。 向量基对于一个空间$R^n$，可存在多组向量基。每一组向量基可展开填满空间$R^n$。 每一组基有n个基向量，这些基向量线性独立（即不在同一平面内）并且展开可填满整个$R^n$空间。 如果基向量相互垂直（正交），那么称为标准正交基。 此时空间的维度就等于每一组基中向量的个数。 矩阵空间和函数空间的基 四个子空间的维度","tags":[{"name":"线性代数","slug":"线性代数","permalink":"https://joshuaqyh.github.io/tags/线性代数/"}]},{"title":"Ch2 | Solving Linear Equations","date":"2019-02-07T15:54:13.000Z","path":"2019/02/07/Ch2-Solving-Linear-Equations/","text":"向量与线性方程组行图像在二维平面中，行图像就是每一道方程所对应的线相交与一点。（更高维情况，就是低一维的对象相交得到低两维的对象）。点的坐标就是线性方程组的解。 列图像列图像就是将线性方程组写成线性组合的形式，在平面内进行几何向量的运算。 线性组合中的列向量就是方程中每一个未知数所有系数构成的向量 线性组合中的系数就是方程组的未知数 线性组合中的结果就是方程组的解构成的列向量 矩阵-向量乘法 以上内容都是基于二阶线性方程组和二维平面内进行的，在高维的情况下可直接推广。这里不做赘述。 Elimination 消去通常在求解一个线性方程组，无法直接构造适用的线性系统A，需要对原方程组进行一定的变化，这些变化方法统称为 消去，最终得到一个上三角矩阵 A。（主对角线以下都是0的方阵称为上三角矩阵） 上三角矩阵具备以下性质： 1、上三角矩阵的行列式为对角线元素相乘； 2、上三角矩阵乘以系数后也是上三角矩阵； 3、上三角矩阵间的加减法和乘法运算的结果仍是上三角矩阵； 4、上三角矩阵的逆矩阵也仍然是上三角矩阵。 5、这些事实说明：所有上三角矩阵的集合以及相应的运算构成一个方形矩阵集合的一个子代数。 一般需要对原方程组进行 行交换，乘以系数，或者方程相减等操作，从而得到化简后的上三角矩阵。 Matrix Multiplication 矩阵乘法定义矩阵乘法的规则（考虑3列的情形）： $$AB = A [b_1 \\, b_2 b_3] = [Ab_1\\, Ab_2\\, Ab_3] \\tag{1}$$ A 为 m × n 的矩阵，B为 n × o 的矩阵，乘法结果就是 m × o 的矩阵。 A B 矩阵需要满足上述的行列数目规则， A的列数等于B的行数。 乘法性质 结合律成立 交换律不成立 常见操作利用一些置换矩阵来完成矩阵操作： 行交换 消除某些行 增广矩阵对于 Ax = b，其增广矩阵为 [ A b ] 矩阵运算法则矩阵相乘 运算律 块矩阵和块乘法 逆矩阵定义 但是不是所有矩阵都有逆矩阵！ 若矩阵可逆，那么该矩阵和逆矩阵相乘的结果就是单位矩阵！ 引理关于逆矩阵有以下几个引理，常用的有 Note5. 矩阵乘法的逆矩阵如果矩阵 A，B都是可逆矩阵，那么 AB 的逆矩阵就是 $$(AB)^{-1} = B^{-1}A^{-1} \\tag{2}$$ 以此类推，有：$$(ABC\\dots Z)^{-1} = Z^{-1}\\dots C^{-1}B^{-1}A^{-1} \\tag{3}$$ Calculating $A^{-1}$ by Gauss-Jordan Elimination考虑三列的情形： $$AA^{-1} = A[x_1\\, x_2\\, x_3 ] = [e_1 \\, e_2 \\, e_3] = I$$ 处理成近似 Ax = b的情况。 构造增广矩阵 $[A \\, e_1 \\, e_2 \\,e_3] $ , 利用消去运算，将增广矩阵改造成 $[I \\, A^{-1}]$，从而得到 $A^{-1}$。 A = LU 矩阵因式分解概述 给定一个A矩阵，要找出一个下三角矩阵L和一个上三角矩阵U，使得 A = LU L和U的好处就是将稠密的A矩阵转为两个稀疏矩阵L、U，减低计算复杂度，提升计算速度。 计算 L和U对于一个式子 A = LU，各矩阵解释如下： A 为一个初始矩阵，待分解。 U 为 A矩阵经过矩阵消元得到的上三角矩阵。 L 为一个下三角矩阵，可以根据行变换的倍数和行，在单元矩阵上填充非0数。 转置定义 性质 对称矩阵 定义 对称矩阵的生成方法 $R^T R $ 给定任意的一个矩阵 R，我们可以使用 其转置$R^T$与R相乘，得到一个正方形的对称矩阵。 对称矩阵的分解性质 $LDL^T$ 对于一个矩阵 A，我们考虑其因式分解 A = LDU。如果A为对称矩阵，那么U = $L^T$ 。 置换矩阵 置换就是对原矩阵进行变换，包括系数变换，行交换。","tags":[{"name":"线性代数","slug":"线性代数","permalink":"https://joshuaqyh.github.io/tags/线性代数/"}]},{"title":"Ch1| Introduction to Vectors","date":"2019-02-07T13:52:08.000Z","path":"2019/02/07/CH1_Introduction-to-Vectors/","text":"线性组合和列向量定义线性组合可以理解为许多系数乘以对应的列向量（其实就是向量都是一列的hhh），然后相加，最终得到一个新的列向量。其中一个例子如下： $$cv + dw = c \\left[ \\begin{matrix} 1 \\ 1 \\end{matrix} \\right] + d \\left[ \\begin{matrix} 2 \\ 3 \\end{matrix} \\right] = \\left[\\begin{matrix} c+2d \\ c + 3d\\end{matrix} \\right] \\tag{1}$$ 其中 v w 为列向量，c，d为系数。列向量可以为多个维度(行），系数代表实数。 我们定义对于多个列向量 v，… ,w，其线性组合就为 cv+…+dw。 运算关于列向量，需要了解的运算： 列向量相加：向量对应的位置的值直接相加 标量和列向量相乘：系数直接乘以向量对应的位置 几何意义列向量$\\left[ \\begin{matrix} a \\ b \\ c \\end{matrix}\\right]$就是理解为空间中的原点到点$(a,b,c)$ 的一条有向线段。 线性组合的几何含义就是空间中的列向量根据矢量相加的法则，最终得到一条新的有向线段（2维）或者更高维的平面。 与线性方程组的关系与 式子 （1）的线性组合相对应的线性方程组如下： $$c + 2d = x \\ c + 3d = y \\, = &gt; \\left[ \\begin{matrix} 1 &amp; 2 \\ 1 &amp; 3 \\end{matrix}\\right] \\left[ \\begin{matrix} c \\ d\\end{matrix}\\right] = \\left[ \\begin{matrix} x \\ y \\end{matrix}\\right] \\tag{2}$$ 构造系数矩阵和未知数列向量，相乘，得到结果向量。 向量点乘和长度两个向量的点乘定义对于两个向量v = (v1, v2) 和 w = (w1, w2) ，我们将这两个向量的点乘定义为 $$v \\cdot w = v1 w1 + v2 w2 \\tag{3}$$ 也就是向量对应位置的数值相乘，然后求和得结果。 向量长度对于一个向量 v 的长度，我们定义为 $length = ||v|| = \\sqrt{v \\cdot v}\\tag{4}$ 也就是向量和自身进行点乘运算，然后开方得到结果。更直观的表达就是，向量每一个元素进行平方求和，然后再开方。 单位向量单位向量 u 就是长度为 1 的向量，该向量与自身点乘结果为1 即 $u \\cdot u = 1 $。 对于每一个向量 v，要得到对应的单位向量，方法就是该向量除以向量长度，得到单位向量 u。用以下式子表示： $u = \\frac{v}{||v||} \\tag{5} $ 其中单位向量 u 与 对应的向量 v 的方向相同。 向量之间的夹角对于两个非零向量 v w，夹角 $\\theta$, 其之间存在的关系是 $$ \\frac{v \\cdot w}{||v||||w||} = \\cos{\\theta} \\tag{6}$$ 其中需要注意一种特殊情况，就是两个向量垂直的情况，也就是所谓的正交, 即 $v \\cdot w = 0$ 重要不等式关于向量点乘，存在一条不等式，如下： $$ | v \\cdot w | \\le ||v|| \\,||w|| \\tag{7}$$ 含义是：两个向量点乘的结果的绝对值 $\\le $ 两个向量的长度相乘的结果。 关于向量相加，存咋一条不等式如下： $$||v + w|| \\le ||v|| + ||w|| \\tag{8}$$ 含义是：两个向量相加的结果的绝对值 $\\le$ 两个向量长度之和 矩阵Ax = b 与线性组合的关系线性组合能够转换成矩阵相乘的形式 $Ax = b$，以下是书中的一个例子。 线性组合和矩阵相乘 Ax = b，各部分的意思是： A 代表一个矩阵，矩阵的列向量就是线性组合中的所有向量 x 代表一个向量，其元素是线性组合中所有的系数 b 是一个向量，是线性组合中的结果 对于每一个输入向量 x，与差分矩阵 A 相乘，得到的结果都包含在 b 向量内部。 线性方程组 线性方程组和矩阵相乘 Ax = b，各部分的意思是： A 该矩阵的各个列向量就是方程组左边部分对应未知数的系数组合。 x 该向量代表方程组左边未知数的组合 b 该向量代表方程组右边的数的组合 逆矩阵逆矩阵其实就是 Ax = b 的逆过程所用到的矩阵, 记为 S。 Ax = b 含义就是输入一个向量x，经过线性矩阵系统A运算，得到新的向量b； 求逆过程就是 x = Sb，含义是：b 经过 逆矩阵系统 S 运算得到原来的输入向量 x。 该关系记为： $$ A x = b \\; is\\, solved \\,by \\,x = A^{-1}b = Sb \\tag{9} $$ 周期差分矩阵 Cx 之后运算得到的向量各个元素相加之和为0，那么 C 就是 周期差分矩阵。 独立性和依赖性 独立性 如果我们知道 u v …w 这多个向量之中，任意一个向量都不在另外其他所有向量构成的平面内，则称这些向量相互独立。 依赖性 区别于独立性，依赖性就是向量都处在同一平面，任意一个向量可由其他所有向量线性组合得到。也就是说存在一个线性组合使得结果为0。那么向量组就存在依赖性。","tags":[{"name":"线性代数","slug":"线性代数","permalink":"https://joshuaqyh.github.io/tags/线性代数/"}]},{"title":"线性表——C语言实现顺序存储和链式存储","date":"2019-02-04T11:22:52.000Z","path":"2019/02/04/数据结构-线性表/","text":"线性表的实现大致有两种方式：定长数组定义的定长线性以及指针定义的变长线性表。本文结合中国大学MOOC浙江大学的数据结构课程，对链表相关的基础知识进行了梳理和总结。 线性表表定长链表123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172typedef int Position;typedef struct LNode *List;#define MAXSIZE 100/*定长链表结构*/struct LNode &#123; ElementType Data[MAXSIZE]; Position Last;&#125;; /* 初始化 */List MakeEmpty()&#123; List L; L = (List)malloc(sizeof(struct LNode)); L-&gt;Last = -1; return L;&#125; /* 查找 */#define ERROR -1 Position Find( List L, ElementType X )&#123; Position i = 0; while( i &lt;= L-&gt;Last &amp;&amp; L-&gt;Data[i]!= X ) i++; if ( i &gt; L-&gt;Last ) return ERROR; /* 如果没找到，返回错误信息 */ else return i; /* 找到后返回的是存储位置 */&#125; /* 插入 *//*注意:在插入位置参数P上与课程视频有所不同，课程视频中i是序列位序（从1开始），这里P是存储下标位置（从0开始），两者差1*/bool Insert( List L, ElementType X, Position P ) &#123; /* 在L的指定位置P前插入一个新元素X */ Position i; if ( L-&gt;Last == MAXSIZE-1) &#123; /* 表空间已满，不能插入 */ printf(\"表满\"); return false; &#125; if ( P&lt;0 || P&gt;L-&gt;Last+1 ) &#123; /* 检查插入位置的合法性 */ printf(\"位置不合法\"); return false; &#125; for( i=L-&gt;Last; i&gt;=P; i-- ) L-&gt;Data[i+1] = L-&gt;Data[i]; /* 将位置P及以后的元素顺序向后移动 */ L-&gt;Data[P] = X; /* 新元素插入 */ L-&gt;Last++; /* Last仍指向最后元素 */ return true; &#125; /* 删除 *//*注意:在删除位置参数P上与课程视频有所不同，课程视频中i是序列位序（从1开始），这里P是存储下标位置（从0开始），两者差1*/bool Delete( List L, Position P )&#123; /* 从L中删除指定位置P的元素 */ Position i; if( P&lt;0 || P&gt;L-&gt;Last ) &#123; /* 检查空表及删除位置的合法性 */ printf(\"位置%d不存在元素\", P ); return false; &#125; for( i=P+1; i&lt;=L-&gt;Last; i++ ) L-&gt;Data[i-1] = L-&gt;Data[i]; /* 将位置P+1及以后的元素顺序向前移动 */ L-&gt;Last--; /* Last仍指向最后元素 */ return true; &#125; 变长链表123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566typedef struct LNode *PtrToLNode;struct LNode &#123; ElementType Data; PtrToLNode Next;&#125;;typedef PtrToLNode Position;typedef PtrToLNode List; /* 查找 */#define ERROR NULL Position Find( List L, ElementType X )&#123; Position p = L; /* p指向L的第1个结点 */ while ( p &amp;&amp; p-&gt;Data!=X ) p = p-&gt;Next; /* 下列语句可以用 return p; 替换 */ if ( p ) return p; else return ERROR;&#125; /* 带头结点的插入 *//*注意:在插入位置参数P上与课程视频有所不同，课程视频中i是序列位序（从1开始），这里P是链表结点指针，在P之前插入新结点 */bool Insert( List L, ElementType X, Position P )&#123; /* 这里默认L有头结点 */ Position tmp, pre; /* 查找P的前一个结点 */ for ( pre=L; pre&amp;&amp;pre-&gt;Next!=P; pre=pre-&gt;Next ) ; if ( pre==NULL ) &#123; /* P所指的结点不在L中 */ printf(\"插入位置参数错误\\n\"); return false; &#125; else &#123; /* 找到了P的前一个结点pre */ /* 在P前插入新结点 */ tmp = (Position)malloc(sizeof(struct LNode)); /* 申请、填装结点 */ tmp-&gt;Data = X; tmp-&gt;Next = P; pre-&gt;Next = tmp; return true; &#125;&#125; /* 带头结点的删除 *//*注意:在删除位置参数P上与课程视频有所不同，课程视频中i是序列位序（从1开始），这里P是拟删除结点指针 */bool Delete( List L, Position P )&#123; /* 这里默认L有头结点 */ Position tmp, pre; /* 查找P的前一个结点 */ for ( pre=L; pre&amp;&amp;pre-&gt;Next!=P; pre=pre-&gt;Next ) ; if ( pre==NULL || P==NULL) &#123; /* P所指的结点不在L中 */ printf(\"删除位置参数错误\\n\"); return false; &#125; else &#123; /* 找到了P的前一个结点pre */ /* 将P位置的结点删除 */ pre-&gt;Next = P-&gt;Next; free(P); return true; &#125;&#125;","tags":[{"name":"数据结构","slug":"数据结构","permalink":"https://joshuaqyh.github.io/tags/数据结构/"},{"name":"C","slug":"C","permalink":"https://joshuaqyh.github.io/tags/C/"}]},{"title":"LaTex 常用数学公式符号速记","date":"2019-01-24T08:44:22.000Z","path":"2019/01/24/LaTex-常用数学公式符号速记/","text":"公式LaTex的行内公式和行间公式区别如下：123456789\\usepackage&#123;amsmath&#125; % 此处引入数学公式的包% 行内公式This is an inline formula. $a = \\sqrt&#123;b + c&#125;$.% 行间公式, 带编号\\begin&#123;equation&#125;E = mc^2\\end&#123;equation&#125; 以下均以行内公式呈现。| 数学公式类型 | 例子 | LaTex代码 || ————– | ———————————————————— | ———————————————————— || 分式 | $\\frac{1+ 2x}{3 + 2y}$ | \\frac{1+ 2x}{3 + 2y} || 下标 | $a_{2}$ | a_{2} || 上标 | $a^{2}$ | a^{2} || 平均数 | $\\bar{a}$ | \\bar{a} || 向量 | $\\vec{a}$ | \\vec{a} || 二项式系数 | $\\binom{a}{b + c}$ | \\binom{a}{b + c} || 变量省略号 | $F(x_{1}, x_{2}, \\ldots , x_{n})$ | F(x_{1}, x_{2}, \\ldots , x_{n}) || 公式内省略号 | $x_{1} + x_{2} + \\cdots + x_{n}$ | x_{1} + x_{2} + \\cdots + x_{n} || 矩阵(无修饰) | $\\begin{matrix}a + b + c &amp; uv &amp; x - y &amp; 27\\a + b &amp; u + v &amp; z &amp; 134\\end{matrix}$ | \\ begin{matrix}a + b + c &amp; uv &amp; x - y &amp; 27\\ \\a + b &amp; u + v &amp; z &amp; 134\\ end{matrix} || 矩阵(带小括号) | $\\begin{pmatrix}a + b + c &amp; uv\\a + b &amp; u + v\\end{pmatrix}$ | \\ begin{pmatrix}a + b + c &amp; uv \\\\a + b&amp;u + v \\ end{pmatrix} || 矩阵(带竖号) | $\\begin{vmatrix}a + b + c &amp; uv\\a + b &amp; u + v\\end{vmatrix}$ | \\ begin{vmatrix}a + b + c &amp; uv \\\\ a + b&amp;u + v \\ end{vmatrix} || 开方 | $\\sqrt[n]{t}$ | \\sqrt[n]{t} || 累加 | $\\sum_{i=1}^{n} x_{i}^{2} $ | \\sum_{i=1}^{n} x_{i}^{2} || 累积 | $\\prod_{i=1}^{n} x_{i}^{2}$ | \\prod_{i=1}^{n} x_{i}^{2} || 极限 | $\\lim_{x \\to a}{ \\frac{f(x) - f(a)}{x - a}}$ | \\lim_{x \\to a}{ \\frac{f(x) - f(a)}{x - a}} || 积分 | $\\int_{a}^b f(x)\\, dx$ | \\int_{a}^b f(x) \\, dx |（注：矩阵表示中 ‘\\’ 和begin，end之间无空格。因为如果有空格，csdn渲染无法显示源码。。更多内容访问链接。 符号 更多符号访问链接[PDF], 或博客。 需要美赛LaTex模板及使用方法，请访问此博文。","tags":[{"name":"Math_Model","slug":"Math-Model","permalink":"https://joshuaqyh.github.io/tags/Math-Model/"},{"name":"LaTex","slug":"LaTex","permalink":"https://joshuaqyh.github.io/tags/LaTex/"},{"name":"Writing","slug":"Writing","permalink":"https://joshuaqyh.github.io/tags/Writing/"}]},{"title":"The template of the MCM/ICM paper","date":"2019-01-24T08:29:54.000Z","path":"2019/01/24/The-template-of-the-MCM-ICM-paper/","text":"The templates of the paperSummary SheetThe main points that should be showed are follows: start a restatement of the problem. the importance if the problem is solved. what models or methods are put forward to solve the problem. illustrate the model further. analyze the model with data. (what ? how ? ) give a conclusion of the model. draw a final and whole conclusion of the model. ​ The restatement of the problem Our goal is… that (minimizes the time ) We determine the … by analyzing… After mathematically analyzing the ……problem, our modeling group would like to present our conclusions, strategies,(and recommendations )to the ……. Aimed to look for the best strategy with the three options listed to maintain the dam, we employ … model to filter factors and determine two most influential criteria, including…. The importance if the problem is solved Without implementing defensive measure, the university is exposed to an expected loss of $8.9 million per year. The Institute of Risk Management of South Africa has just warned that the Kariba dam is in desperate need of rehabilitation, otherwise the whole dam would collapse, putting 3.5 million people at risk. The models put forward to solve the problem According to our choice, we are required to offer…. Regarding it as a set covering problem, we develop a …. model to minimize the number of smallerwhile … Applying … evaluation method to get the demand of the electricity and water, we solve this problem with ….. algorithm and get an approximate optimal solution with …. We address the problem of optimizing …. We formulate the problem as ….. We divide the jump into three phases: 1…. 2….. 3… To address this situation, our paper provides a detailed analysis of one option Illustrate the model further We build a model to determine how to …. We examined the mathematical effects of……. We developed a detailed……(simulation methodology) to test our ideas and to quantify the differences between (among) different …… (strategies). Analyze the model with data Using historical data from the United States, we determine initial conditions for our model. this model leads to a computer simulation of catch-can tests of the irrigation system and …… We provide a strategy that… Finally, these statistics could help us simulate…. Give a conclusion of the model We show that this strategy is not optimal but can be improved by assigning differentnumbers…… We modify the model to reflect (some trend such as exponentially increasing……) andgeneralize the model to (other field). For various situations, we propose an optimal solution. The sensitivity analysis of our model has pointed out that …. Draw a final and whole conclusion of the model Our suggested solution, which is easy to implement, includes a detailed timetable and the arrangement of pipes. Since our model is based on…… it can be applied to (other domain). Our analysis began by determining what factor impact……, Our conclusions are presented…… Introduction A simple background. Restatement and Our Work We are required to provide an overview of … Then we need to establish a model to determine …. In addition, we should consider …. so that we could give out … In order to solve those problems, we will proceed as follows: In our model, we first establish a ….. model and use ….. algorithm to determine …. Besides, we add some constraints …. We employ the genetic algorithm to solve the optimal problem to …. Literature Review ​ Assumptions and JustificationsStarting: To simplify our problems, we make the following basic assumptions, each of which is properlyjustified. Reason: Because it’s more convenient to build and also with less cost, which can be easily implemented. Owing to the fact that …. Taking into account of …. According to … NotationIn this paper we use the nomenclature in Table.1 to descibe our model. Other symbolsthat are used only once will be described later. The Design of the ModelsModel OverviewOur first model allows us to determine… On the account that the optimal problem is difficult to solve in polynomial time, so we use genetic algorithm to get the solution… After determining the numbers and the location, we establish a joint operation of dam systemmodel to gain a strategy about modulating water flow in different condition… In conclusion, we use programming and heuristic algorithm to solve the problem …. Establishment of the ModelIf it is a multi-objective model, then: The objectives ​ The Constraints Model Implementation and ResultsSensitivity Analysis Change condition1 Analysis ….. Result ….. Strengths and WeaknessesStrengths Our main model’s strength is its enormous edibility. For instance,……..Including all these factors into a single, robust framework, our model enables We developed a theoretical line formation model which agrees without rough data. Our computer model agrees with both despite working on different principles, implying it behaves as we want. This allows us to make substantive conclusions about Finally, our model is strong because of The Monte Carlo simulation has been perfectly used in our models, and the simulation results are consistent with the reality. We introduced …… in order to improve the exchange quality. The chain rules can also modified in a degree. The models used in our paper is promotional, in view of different consideration, we can modify our models conveniently. the model is independent of the site simulated( )… Weaknesses Some special data can’t be found, and it makes that we have to do some proper assumption before the solution of our models. A more abundant data resource can guarantee a better result in our models. Current line length is not taken into account by the line formation model. In real life…… Weaknesses of the model included assumptions made for simplicity that likely do not hold. For instance, in most runs of our model on(sides……), cases(impact/conclusion) to…… This feature is likely a result of our assumption that/The primary weakness of this model is the( ), It should be possible to eliminate this, another weakness that could be corrected with more analysis is ( )` The primary weakness of this model is the… Another weakness that could be corrected with more analysis is… Parameters have to be derived from physical occurrences. The other primary weakness of our model is our lack of metrics forcomparison. Although we list the model’s comprehensive, discrete simulation asa strength, it is (Paradoxically) also the most notable weakness. Our results lack clear….Second ,our model demands great attention to….While its general structure and methodology are valid, the specific figures embedded in its code are not airtight. Although we list the model’s comprehensive, …… as a strength, it is (paradoxically) also the most notable weakness. Our results lack clear illustrative power; data manipulated through a computer program cannot achieve the same effect as …… Indeed, there is a fundamental trade off here between realism and elegance, and our model arguably veers toward over realism. Conclusion Through the establishment of three models, we evaluate the three plans respectively. Through the AHP analysis, we draw the conclusion that option three is a relatively good solution. we establish a multi-objective optimization model to determine We also use genetic algorithm to solve the problem and find that…. We already know how well our results worked for…… We next developed a detailed simulation engine to perform simulations. Our simulationsallowed us to …… We also wish to tie our exploration of sensitive…… ​ ​","tags":[{"name":"Math_Model","slug":"Math-Model","permalink":"https://joshuaqyh.github.io/tags/Math-Model/"},{"name":"Writing","slug":"Writing","permalink":"https://joshuaqyh.github.io/tags/Writing/"}]},{"title":"信息安全 | 防火墙","date":"2018-12-28T02:10:09.000Z","path":"2018/12/28/防火墙/","text":"防火墙概念在两个网络之间实现访问控制地一组软件或硬件系统。主要功能是屏蔽和允许指定的数据通信。依赖一组访问控制策略，由访问控制策略决定通讯的合法性。 用处： 管理控制网络流通数据流 数据包检测 连接状态 状态包检测 作为中间媒介阻塞不安全的服务和协议 通过隔离外部网络来保护本地主机 避免直接与外接互动 保护资源，强化网络安全策略。将所有安全软件配置在防火墙上。采取某些手段如Finger来屏蔽透露内部细节的服务。 报告和记录事件，对网络存取和访问进行监控审计。 ​ 防火墙的种类第一代：包过滤（网络级防火墙）工作在网络层以下，基于路由器本身的分组过滤功能，检索流经数据包包头信息，决定对数据包的动作。 第二代： 状态过滤（状态检测防火墙）工作在网络层，采用状态检测的技术，是包过滤技术的拓展。使用一个检查引擎或数据包并抽取与应用层状态相关的信息，以此决定是否接收该连接。 第三代： 应用层过滤（应用层网关）应用层代理防火墙。应用层网关代理服务器有效伪装成因特网上的真实服务器，并对请求做出评估，决定允许或者拒绝。 应用层网关能够理解应用级上的协议，完成较为复杂的访问控制。每一种协议需要相应的代理软件，效率不如网络级防火墙。 第四代：基于安全操作系统的防火墙 托管防火墙三种托管防火墙的方式： Bastion Host 堡垒主机。具备三层过滤和代理控制的功能。主要用于处理安全事件。 Host-Based Firewall。严格过滤数据流。 Personal Firewall。 例子Windows 防火墙。 包过滤防火墙最基本的防火墙，通常工作在OSI的三层及以下。可控内容包括报文的源地址，报文的目标地址，服务类型，以及第二层数据链路层可控的MAC地址。 包过滤技术允许符合安全过滤规则的数据包通过。同时执行预先定义的操作，记录过滤信息，发送报警信息。 过滤分析： 分析数据包包头字段。包括IP PORT，TCP。。。 一个访问控制列表，每一条记录定义了对符合记录条件的数据包所要执行的动作。 优点： 高速，只对包头进行检查 对用户透明 缺点： 无法根据数据内容进行过滤 提供简单的日志信息 ACL配置困难 端口暴露在外网，安全风险 ​ 状态检测防火墙 状态检测技术主要在传输层和网络层工作。 动态过滤规则存储在连接状态表中，并由防火墙维护。 对表中记录设置超时参数。 只对连接的初始报文进行检查。 优点： 只对初始报文进行检查，后续报文不做检查，可以快速通过 可以区分连接的发起方和接收方，通过状态分析阻断更多的复杂攻击行为，以及分析打开相应的端口。 缺点： 主要工作在网络层和传输层，对报文的数据部分检查很少，安全性低。 对初始报文内容检测相对增多，对防火墙的响应速度提出了更高的要求。 应用层网关Proxy（ALG）应用层网关防火墙也叫应用层代理，负责内部网络和外部网络之间的通讯。网络连接通过中介来实现，设定符合预定的访问控制规则，所以恶意侵害无法伤害被保护的真实网络设备。 提供一些复杂的访问控制： 认证机制 内容过滤 成熟的日志记录 优点： 提供高速缓存 屏蔽内联网络 连接基于服务 代理服务建立在应用层 规则简单 缺点： 专用 延迟 用户不透明 不完全支持所有协议 对特定操作系统有依赖性 速度较慢。 堡垒主机Bastion","tags":[{"name":"信息安全","slug":"信息安全","permalink":"https://joshuaqyh.github.io/tags/信息安全/"},{"name":"计算机网络","slug":"计算机网络","permalink":"https://joshuaqyh.github.io/tags/计算机网络/"}]},{"title":"机器学习|支持向量机算法原理及实现","date":"2018-12-24T12:33:53.000Z","path":"2018/12/24/机器学习-支持向量机算法原理及实现/","text":"基本原理基本概念最简单的支持向量机是一个二分类的分类器。分类思想是给定一组包含正负样本的集合，然后找到一个超平面（可以是一维或者多维），来对正负样本进行分割。 该方法对于解决小样本，非线性，及高维模式识别中表现出许多的优势。 以下图的直线就是概念中的超平面，将样本划分为两个类别。在解决实际的多分类问题中可以转化为多个二分类问题。 其中的超平面方程由以下线性方程来描述。 ​ $$g(x) = w^Tx + b = 0$$ 其中$x$为样本的特征向量，$w^T$ 代表平面的法向量，而 $b$ 代表超平面的偏移量。 假设输入样本为 $x_0$，使得 $g(x_0) &gt; 0$ 的样本为正样本，反之为负样本，正负标签记为 ${+1, -1} $。 函数间隔 函数的间隔指的是正负样本点中到超平面的最近距离。对数据点进行分类，当超平面离数据点的间隔越大，分类的确信度越高。故当多个超平面的分类准确率一致时，我们要着重考虑最大间隔的分类器。 所以支持向量机的最终目标就是找到一个最大间隔的分类器。可以理解为一个约束优化问题，用以下式子来表示。 $$max \\, \\frac{r^}{||w||} \\ subject\\, to \\, y_i (w^Tx_i + b ) \\ge r^ $$ 其中 $r^*$为函数间隔。 ① 该方程并非凸函数求解，所以将方程转化为凸函数。转化为以下约束优化问题。 $$min \\, \\frac{1}{||w||} \\ subject \\,to\\, y_i(w^Tx_i + b) \\geq r*$$ 转为凸函数以后，使用拉格朗日乘子法和KTT条件求解对偶问题。 ②用拉格朗日乘子法和KKT条件求解最优值： $$\\min\\ \\frac{1}{2}||w||^2$$ $$s.t.\\ -y_i(w^Tx_i+b)+1\\leq 0,\\ i=1,2,..,m$$ 整合成： $$L(w, b, \\alpha) = \\frac{1}{2}||w||^2+\\sum^m_{i=1}\\alpha_i(-y_i(w^Tx_i+b)+1)$$ 推导：$\\min\\ f(x)=\\min \\max\\ L(w, b, \\alpha)\\geq \\max \\min\\ L(w, b, \\alpha)$ 根据KKT条件： $$\\frac{\\partial }{\\partial w}L(w, b, \\alpha)=w-\\sum\\alpha_iy_ix_i=0,\\ w=\\sum\\alpha_iy_ix_i$$ $$\\frac{\\partial }{\\partial b}L(w, b, \\alpha)=\\sum\\alpha_iy_i=0$$ 带入$ L(w, b, \\alpha)$ $\\min\\ L(w, b, \\alpha)=\\frac{1}{2}||w||^2+\\sum^m_{i=1}\\alpha_i(-y_i(w^Tx_i+b)+1)$ $\\qquad\\qquad\\qquad=\\frac{1}{2}w^Tw-\\sum^m_{i=1}\\alpha_iy_iw^Tx_i-b\\sum^m_{i=1}\\alpha_iy_i+\\sum^m_{i=1}\\alpha_i$ $\\qquad\\qquad\\qquad=\\frac{1}{2}w^T\\sum\\alpha_iy_ix_i-\\sum^m_{i=1}\\alpha_iy_iw^Tx_i+\\sum^m_{i=1}\\alpha_i$ $\\qquad\\qquad\\qquad=\\sum^m_{i=1}\\alpha_i-\\frac{1}{2}\\sum^m_{i=1}\\alpha_iy_iw^Tx_i$ $\\qquad\\qquad\\qquad=\\sum^m_{i=1}\\alpha_i-\\frac{1}{2}\\sum^m_{i,j=1}\\alpha_i\\alpha_jy_iy_j(x_ix_j)$ 再把max问题转成min问题： $\\max\\ \\sum^m_{i=1}\\alpha_i-\\frac{1}{2}\\sum^m_{i,j=1}\\alpha_i\\alpha_jy_iy_j(x_ix_j)=\\min \\frac{1}{2}\\sum^m_{i,j=1}\\alpha_i\\alpha_jy_iy_j(x_ix_j)-\\sum^m_{i=1}\\alpha_i$ $s.t.\\ \\sum^m_{i=1}\\alpha_iy_i=0,$ $ \\alpha_i \\geq 0,i=1,2,…,m$ 以上为SVM对偶问题的对偶形式 kernel在低维空间计算获得高维空间的计算结果，也就是说计算结果满足高维（满足高维，才能说明高维下线性可分）。 soft margin &amp; slack variable引入松弛变量$\\xi\\geq0$，对应数据点允许偏离的functional margin 的量。 目标函数：$\\min\\ \\frac{1}{2}||w||^2+C\\sum\\xi_i\\qquad s.t.\\ y_i(w^Tx_i+b)\\geq1-\\xi_i$ 对偶问题： $$\\max\\ \\sum^m_{i=1}\\alpha_i-\\frac{1}{2}\\sum^m_{i,j=1}\\alpha_i\\alpha_jy_iy_j(x_ix_j)=\\min \\frac{1}{2}\\sum^m_{i,j=1}\\alpha_i\\alpha_jy_iy_j(x_ix_j)-\\sum^m_{i=1}\\alpha_i$$ $$s.t.\\ C\\geq\\alpha_i \\geq 0,i=1,2,…,m\\quad \\sum^m_{i=1}\\alpha_iy_i=0,$$ Sequential Minimal Optimization首先定义特征到结果的输出函数：$u=w^Tx+b$. 因为$w=\\sum\\alpha_iy_ix_i$ 有$u=\\sum y_i\\alpha_iK(x_i, x)-b$ $\\max \\sum^m_{i=1}\\alpha_i-\\frac{1}{2}\\sum^m_{i=1}\\sum^m_{j=1}\\alpha_i\\alpha_jy_iy_j&lt;\\phi(x_i)^T,\\phi(x_j)&gt;$ $s.t.\\ \\sum^m_{i=1}\\alpha_iy_i=0,$ $ \\alpha_i \\geq 0,i=1,2,…,m$ 参考资料： [1] :Lagrange Multiplier and KKT [2] :推导SVM [3] :机器学习算法实践-支持向量机(SVM)算法原理 [4] :Python实现SVM python 实现以下是利用sklearn的一个简单实现。 1234567891011121314151617181920212223242526import numpy as npimport pandas as pdfrom sklearn.datasets import load_irisfrom sklearn.model_selection import train_test_splitimport matplotlib.pyplot as plt%matplotlib inline# datadef create_data(): iris = load_iris() df = pd.DataFrame(iris.data, columns=iris.feature_names) df['label'] = iris.target df.columns = ['sepal length', 'sepal width', 'petal length', 'petal width', 'label'] data = np.array(df.iloc[:100, [0, 1, -1]]) for i in range(len(data)): if data[i,-1] == 0: data[i,-1] = -1 # print(data) return data[:,:2], data[:,-1]## 生成数据集并显示 X, y = create_data()X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)plt.scatter(X[:50,0],X[:50,1], label='0')plt.scatter(X[50:,0],X[50:,1], label='1')plt.legend() 数据集如上。 SVM实现如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141class SVM: def __init__(self, max_iter=100, kernel='linear'): self.max_iter = max_iter self._kernel = kernel def init_args(self, features, labels): self.m, self.n = features.shape self.X = features self.Y = labels self.b = 0.0 # 将Ei保存在一个列表里 self.alpha = np.ones(self.m) self.E = [self._E(i) for i in range(self.m)] # 松弛变量 self.C = 1.0 def _KKT(self, i): y_g = self._g(i)*self.Y[i] if self.alpha[i] == 0: return y_g &gt;= 1 elif 0 &lt; self.alpha[i] &lt; self.C: return y_g == 1 else: return y_g &lt;= 1 # g(x)预测值，输入xi（X[i]） def _g(self, i): r = self.b for j in range(self.m): r += self.alpha[j]*self.Y[j]*self.kernel(self.X[i], self.X[j]) return r # 核函数 def kernel(self, x1, x2): if self._kernel == 'linear': return sum([x1[k]*x2[k] for k in range(self.n)]) elif self._kernel == 'poly': return (sum([x1[k]*x2[k] for k in range(self.n)]) + 1)**2 return 0 # E（x）为g(x)对输入x的预测值和y的差 def _E(self, i): return self._g(i) - self.Y[i] def _init_alpha(self): # 外层循环首先遍历所有满足0&lt;a&lt;C的样本点，检验是否满足KKT index_list = [i for i in range(self.m) if 0 &lt; self.alpha[i] &lt; self.C] # 否则遍历整个训练集 non_satisfy_list = [i for i in range(self.m) if i not in index_list] index_list.extend(non_satisfy_list) for i in index_list: if self._KKT(i): continue E1 = self.E[i] # 如果E2是+，选择最小的；如果E2是负的，选择最大的 if E1 &gt;= 0: j = min(range(self.m), key=lambda x: self.E[x]) else: j = max(range(self.m), key=lambda x: self.E[x]) return i, j def _compare(self, _alpha, L, H): if _alpha &gt; H: return H elif _alpha &lt; L: return L else: return _alpha def fit(self, features, labels): self.init_args(features, labels) for t in range(self.max_iter): # train i1, i2 = self._init_alpha() # 边界 if self.Y[i1] == self.Y[i2]: L = max(0, self.alpha[i1]+self.alpha[i2]-self.C) H = min(self.C, self.alpha[i1]+self.alpha[i2]) else: L = max(0, self.alpha[i2]-self.alpha[i1]) H = min(self.C, self.C+self.alpha[i2]-self.alpha[i1]) E1 = self.E[i1] E2 = self.E[i2] # eta=K11+K22-2K12 eta = self.kernel(self.X[i1], self.X[i1]) + self.kernel(self.X[i2], self.X[i2]) - 2*self.kernel(self.X[i1], self.X[i2]) if eta &lt;= 0: # print('eta &lt;= 0') continue alpha2_new_unc = self.alpha[i2] + self.Y[i2] * (E2 - E1) / eta alpha2_new = self._compare(alpha2_new_unc, L, H) alpha1_new = self.alpha[i1] + self.Y[i1] * self.Y[i2] * (self.alpha[i2] - alpha2_new) b1_new = -E1 - self.Y[i1] * self.kernel(self.X[i1], self.X[i1]) * (alpha1_new-self.alpha[i1]) - self.Y[i2] * self.kernel(self.X[i2], self.X[i1]) * (alpha2_new-self.alpha[i2])+ self.b b2_new = -E2 - self.Y[i1] * self.kernel(self.X[i1], self.X[i2]) * (alpha1_new-self.alpha[i1]) - self.Y[i2] * self.kernel(self.X[i2], self.X[i2]) * (alpha2_new-self.alpha[i2])+ self.b if 0 &lt; alpha1_new &lt; self.C: b_new = b1_new elif 0 &lt; alpha2_new &lt; self.C: b_new = b2_new else: # 选择中点 b_new = (b1_new + b2_new) / 2 # 更新参数 self.alpha[i1] = alpha1_new self.alpha[i2] = alpha2_new self.b = b_new self.E[i1] = self._E(i1) self.E[i2] = self._E(i2) return 'train done!' def predict(self, data): r = self.b for i in range(self.m): r += self.alpha[i] * self.Y[i] * self.kernel(data, self.X[i]) return 1 if r &gt; 0 else -1 def score(self, X_test, y_test): right_count = 0 for i in range(len(X_test)): result = self.predict(X_test[i]) if result == y_test[i]: right_count += 1 return right_count / len(X_test) def _weight(self): # linear model yx = self.Y.reshape(-1, 1)*self.X self.w = np.dot(yx.T, self.alpha) return self.w","tags":[{"name":"人工智能","slug":"人工智能","permalink":"https://joshuaqyh.github.io/tags/人工智能/"},{"name":"python","slug":"python","permalink":"https://joshuaqyh.github.io/tags/python/"},{"name":"机器学习","slug":"机器学习","permalink":"https://joshuaqyh.github.io/tags/机器学习/"}]},{"title":"机器学习|K近邻算法及python实现","date":"2018-12-24T12:05:05.000Z","path":"2018/12/24/机器学习-K近邻算法/","text":"基本概念 k 近邻算法是一种经典且简单的机器学习算法之一，用于分类和回归。在本文只探讨分类问题中的 k 近邻法。 k 近邻算法是一种少数服从多数的思想。给定一个训练数据集，数据集中的每一条数据都由一个特征向量表出如$(x_1, x_2…)$，每一条数据对应一个类别即标签。 我们输入一个新数据的向量到该数据集中，我们找到与该实例最邻近的 $K$ 个实例，这$K$个实例中的多数属于某个类, 那么我们就把该输入实例分类到这个类中。（注：需要保证样本特征向量的长度一致）。 数据样本之间的距离可以用欧式距离和曼哈顿距离来衡量。 算法实现欧氏距离计算 123456789def L(x, y, p=2): # x1 = [1, 1], x2 = [5,1] if len(x) == len(y) and len(x) &gt; 1: sum = 0 for i in range(len(x)): sum += math.pow(abs(x[i] - y[i]), p) return math.pow(sum, 1/p) else: return 0 Knn算法实现 1234567891011121314151617181920212223242526272829303132333435363738class KNN: def __init__(self, X_train, y_train, n_neighbors=3, p=2): \"\"\" parameter: n_neighbors 临近点个数 parameter: p 距离度量 \"\"\" self.n = n_neighbors self.p = p self.X_train = X_train # 特征向量 self.y_train = y_train # 标签 def predict(self, X): # 输入单一测试样例，给出分类 # 取出n个点 knn_list = [] for i in range(self.n): dist = np.linalg.norm(X - self.X_train[i], ord=self.p) knn_list.append((dist, self.y_train[i])) for i in range(self.n, len(self.X_train)): max_index = knn_list.index(max(knn_list, key=lambda x: x[0])) dist = np.linalg.norm(X - self.X_train[i], ord=self.p) if knn_list[max_index][0] &gt; dist: knn_list[max_index] = (dist, self.y_train[i]) # 统计 knn = [k[-1] for k in knn_list] count_pairs = Counter(knn) max_count = sorted(count_pairs, key=lambda x:x)[-1] return max_count def score(self, X_test, y_test): # 测试集的准确率 right_count = 0 n = 10 for X, y in zip(X_test, y_test): label = self.predict(X) if label == y: right_count += 1 return right_count / len(X_test)","tags":[{"name":"人工智能","slug":"人工智能","permalink":"https://joshuaqyh.github.io/tags/人工智能/"},{"name":"python","slug":"python","permalink":"https://joshuaqyh.github.io/tags/python/"},{"name":"机器学习","slug":"机器学习","permalink":"https://joshuaqyh.github.io/tags/机器学习/"}]},{"title":"人工智能 | 人工神经网络学习","date":"2018-12-17T12:06:03.000Z","path":"2018/12/17/人工神经网络学习/","text":"神经元结构神经元结构就是一个函数发生器：输入+函数运算+输出。 输入是多个输入点$a$ 的加权(w)求和。 函数运算：激活函数。常用sigmoid函数。 输出：一个输出值，可能作为其他神经元的输入点之一。 前馈网络单层前馈神经网络（感知器） ​ 输入直接连接到输出。","tags":[{"name":"人工智能","slug":"人工智能","permalink":"https://joshuaqyh.github.io/tags/人工智能/"},{"name":"神经网络","slug":"神经网络","permalink":"https://joshuaqyh.github.io/tags/神经网络/"}]},{"title":"基于以太坊的DApp学习开发之路","date":"2018-12-11T13:47:18.000Z","path":"2018/12/11/DApp学习之路/","text":"准备的知识前端React.js + Redux 用于前端组件设计和状态管理。拟学习MD组件库。 web3.js 与区块链数据交互通信 webpack 服务端web3.js 与区块链交互 + express 响应请求/路由功能+mongodb基本增删该查。 区块链智能合约+测试部署+调用 solc + ganache + influa + truffle + metamask ！ IPFS 学习链接https://medium.com/ethereum-developers/the-ultimate-end-to-end-tutorial-to-create-and-deploy-a-fully-descentralized-dapp-in-ethereum-18f0cf6d7e0e 学习记录通过一个简单应用体会全栈Dapp过程。涉及框架 truffle ，IPFS，webpack，react，babel，web3 开发核心步骤步骤 Setup the project Program the Solidity contracts Create the frontend application Deploy the application online with IPFS Use a custom domain for the application Play with the final Dapp!","tags":[{"name":"Ethereum","slug":"Ethereum","permalink":"https://joshuaqyh.github.io/tags/Ethereum/"},{"name":"DApp","slug":"DApp","permalink":"https://joshuaqyh.github.io/tags/DApp/"},{"name":"前端开发","slug":"前端开发","permalink":"https://joshuaqyh.github.io/tags/前端开发/"},{"name":"React","slug":"React","permalink":"https://joshuaqyh.github.io/tags/React/"}]},{"title":"编译原理 | 语法制导翻译法","date":"2018-12-11T02:04:36.000Z","path":"2018/12/11/语法制导翻译法/","text":"SDTS基本概念$语法制导翻译法SDTS = 一个源语言 + 一个目标语言 + 一组翻译规则$ SDTS的翻译规则是文法中的产生式再加上语义动作。 SDTS其形式定义T如下： $$T = (V_T, V_N, \\delta, R, S)$$ $V_T$ 是一个有穷的输入字母表，包含源语言中的符号。 $V_N$ 是一个有穷的非终结符号集合。 $\\delta$ 是一个有穷的输出字母表，包含出现翻译串或输出串中的那些符号。 $R$是形如$A\\rightarrow w,y$的规则的有穷集合。 $S ∈ V_N$是一个开始符号。 解释R中$A\\rightarrow w, y$ 。 w 是终结符和（或）非终结符组成的串； y是由$V_N$和（或）$\\delta$中符号组成的串。 w 为规则的源成分；y为规则的翻译成分，出现在w，y中的非终结符必须是一一对应的。 T的基础源文法 SDTS的基础源文法是一个CFG(上下文无关文法context-free-grammar）：$(V_N, V_T, P,S)$ $P $是形如$A\\rightarrow w（w$ 为源程序成分 )的产生式的集合。 从T中去掉输出字母表$\\delta$ ，再从T的规则中移走翻译成分y,就可以得到T的基础源文法。 T 的基础目标文法 类似地，从T中去掉字母表$V_T$ 并从T的规则中移去源成分。 CFG：$(V_N, P, \\delta, S)$。 P是形如$A \\rightarrow y$(y为目标成分)产生式的集合。","tags":[{"name":"编译原理","slug":"编译原理","permalink":"https://joshuaqyh.github.io/tags/编译原理/"}]},{"title":"我的React学习路线","date":"2018-12-07T08:30:51.000Z","path":"2018/12/07/我的React学习路线/","text":"官方文档入门初步体会一个react的小应用 1234567891011121314151617//利用组件定义标签class ShoppingList extends React.Component &#123; render() &#123; return ( &lt;div className=\"shopping-list\"&gt; &lt;h1&gt;Shopping List for &#123;this.props.name&#125;&lt;/h1&gt; &lt;ul&gt; &lt;li&gt;Instagram&lt;/li&gt; &lt;li&gt;WhatsApp&lt;/li&gt; &lt;li&gt;Oculus&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; ); &#125;&#125;// Example usage: &lt;ShoppingList name=\"Mark\" /&gt; JSX语法：js内嵌html。 组件之间传值：通过props 基本流程：就是继承react组件基类，自定义组件及其行为。实例化之后填入html某一个标签中。 组件内部结构： 构造函数（如果要维护内部的state需要有，否则可删除） 内部自定义函数 render函数 12345678910111213141516171819202122232425262728293031323334353637383940414243 class Game extends React.Component &#123; constructor(props) &#123; super(props); this.state = &#123; history: [&#123; squares: Array(9).fill(null), &#125;], xIsNext: true, &#125;; &#125; render() &#123; const history = this.state.history; const current = history[history.length - 1]; const winner = calculateWinner(current.squares); let status; if (winner) &#123; status = 'Winner: ' + winner; &#125; else &#123; status = 'Next player: ' + (this.state.xIsNext ? 'X' : 'O'); &#125; return ( &lt;div className=\"game\"&gt; &lt;div className=\"game-board\"&gt; &lt;Board squares=&#123;current.squares&#125; onClick=&#123;(i) =&gt; this.handleClick(i)&#125;/&gt; &lt;/div&gt; &lt;div className=\"game-info\"&gt; &lt;div&gt;&#123;status&#125;&lt;/div&gt; &lt;ol&gt;&#123;/* TODO */&#125;&lt;/ol&gt; &lt;/div&gt; &lt;/div&gt; ); &#125; &#125; // ======================================== // 调用函数进行渲染 ReactDOM.render( &lt;Game /&gt;, document.getElementById('root') );// 组件结构 12345678910111213141516171819202122class example extends React.Componet&#123; construct(props)&#123; super(props); this.state = &#123; // state 存储本组件的变量成员 变量： 值， // props 上层组件调用的传入的变量 &#125;; &#125; // 其他处理的函数 func()&#123; &#125; // 最后的渲染函数，返回html元素 render()&#123; // 一些变量处理逻辑 return(&lt;div&gt; &lt;div/&gt;); &#125;&#125; ReactDOM.render( &lt;example /&gt;, // 此处将组件作为标签渲染 document.getElementById('root') // 查找root 标签，将组件填入 ); 慕课网视频生命周期 上述是一些hook函数，可以以下面的方式调用 绑定事件定义事件 1234567891011121314151617var test = React.createClass(&#123; change: function(event)&#123; var tipE = React.findDOMNode(\"tip\"); if(tip.display == 'none') tip.display = 'inline'; else tip.display = 'none'; event.stopPropagation(); evnet.preventDefault(); &#125;render: function()&#123; return ( &lt;button onClick = &#123;this.change&#125;&gt; click &lt;button/&gt;&lt;span ref = \"tip\"&gt; &lt;span/&gt; ); &#125; &#125;); React 项目 yomen使用学习 体会网页版的todoapp https://yeoman.io/codelab/review-generated-files.html 画廊应用 facebook creact-react-app 项目 https://github.com/facebook/create-react-app npm init react-app my-app Material design学习 https://material-ui.com/getting-started/page-layout-examples/ react 路由实现组件之间的切换 https://www.jianshu.com/p/8fcf8d27b9fe 多人投票项目，待办 MERN 全栈开发 pdf ，待办。 Redux 学习https://redux-docs.netlify.com/introduction/learning-resources 官方介绍和推荐学习资源 ！ http://cn.redux.js.org/ 中文文档 action 组件可能的行为，需要先定义分类type，然后再生成行为createaction reducer 根据当前状态行为确定下一步状态，(previousState, action) =&gt; newState It’s very important that the reducer stays pure. Things you should never do inside a reducer: Mutate its arguments; Perform side effects like API calls and routing transitions; Call non-pure functions, e.g. Date.now() or Math.random() container将redux和react组件绑定在一起 store 维持应用状态 Holds application state; Allows access to state via getState(); Allows state to be updated via dispatch(action); Registers listeners via subscribe(listener); Handles unregistering of listeners via the function returned by subscribe(listener). 官方代码学习： 一个简单的计时器应用123456789101112131415161718192021// 入口文件 index.jsimport React from 'react'import ReactDOM from 'react-dom'import &#123; createStore &#125; from 'redux' import Counter from './components/Counter'import counter from './reducers'const store = createStore(counter) // 获取存储const rootEl = document.getElementById('root')const render = () =&gt; ReactDOM.render( &lt;Counter value=&#123;store.getState()&#125; // 将store中的state值传入组件的值 onIncrement=&#123;() =&gt; store.dispatch(&#123; type: 'INCREMENT' &#125;)&#125; //为组件注册store中的方法 onDecrement=&#123;() =&gt; store.dispatch(&#123; type: 'DECREMENT' &#125;)&#125; /&gt;, rootEl)render() // 渲染store.subscribe(render) // 为渲染结果进行stroe的订阅 1234567891011// reducer 文件，根据传入的行为定义响应结果export default (state = 0, action) =&gt; &#123; switch (action.type) &#123; case 'INCREMENT': return state + 1 case 'DECREMENT': return state - 1 default: return state &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354// 定义时钟组件import React, &#123; Component &#125; from 'react'import PropTypes from 'prop-types'class Counter extends Component &#123; constructor(props) &#123; super(props); this.incrementAsync = this.incrementAsync.bind(this); this.incrementIfOdd = this.incrementIfOdd.bind(this); &#125; incrementIfOdd() &#123; if (this.props.value % 2 !== 0) &#123; this.props.onIncrement() &#125; &#125; incrementAsync() &#123; setTimeout(this.props.onIncrement, 1000) &#125; render() &#123; const &#123; value, onIncrement, onDecrement &#125; = this.props //获取上层调用的参数 return ( &lt;p&gt; Clicked: &#123;value&#125; times // 将上层传来的值绑定在组件的属性之上 &#123;' '&#125; &lt;button onClick=&#123;onIncrement&#125;&gt; // 将上层定义的事件绑定给下层组件 + &lt;/button&gt; &#123;' '&#125; &lt;button onClick=&#123;onDecrement&#125;&gt; - &lt;/button&gt; &#123;' '&#125; &lt;button onClick=&#123;this.incrementIfOdd&#125;&gt; Increment if odd &lt;/button&gt; &#123;' '&#125; &lt;button onClick=&#123;this.incrementAsync&#125;&gt; Increment async &lt;/button&gt; &lt;/p&gt; ) &#125;&#125;Counter.propTypes = &#123; // 组件的属性 value: PropTypes.number.isRequired, onIncrement: PropTypes.func.isRequired, onDecrement: PropTypes.func.isRequired&#125;export default Counter Todos 简单应用学习 react-redux中Provider的概念，相当于一个顶层的组件，直接存储了store。 12345678910111213141516// 入口文件import React from 'react' // import &#123; render &#125; from 'react-dom' // render 对象import &#123; createStore &#125; from 'redux' // 从redux引入createStore方法创建storeimport &#123; Provider &#125; from 'react-redux' // 引入顶层组件，注册storeimport App from './components/App' // 引入App组件，核心组件import rootReducer from './reducers' // 一次性引入多个reducerconst store = createStore(rootReducer) render( &lt;Provider store=&#123;store&#125;&gt; &lt;App /&gt; &lt;/Provider&gt;, document.getElementById('root')) 学习reducer 如何向其他reducer托管处理行为的逻辑。 reducer中，index.js中combineReducers为汇总的reducer。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152// reducers/index.jsimport &#123; combineReducers &#125; from 'redux'import todos from './todos'import visibilityFilter from './visibilityFilter'export default combineReducers(&#123; //联合其他reducer todos, visibilityFilter&#125;)///////////////////////////////////////////////////////////////// /reducers/todos.js ??const todos = (state = [], action) =&gt; &#123; switch (action.type) &#123; case 'ADD_TODO': // 添加一条todo return [ ...state, &#123; id: action.id, text: action.text, completed: false &#125; ] case 'TOGGLE_TODO': // 完成todo return state.map(todo =&gt; (todo.id === action.id) ? &#123;...todo, completed: !todo.completed&#125; : todo ) default: return state &#125;&#125;export default todos////////////////////////////////////////////////////////////////////////// reducers/visibilityFillter.jsimport &#123; VisibilityFilters &#125; from '../actions' // 将行为交给其他模块const visibilityFilter = (state = VisibilityFilters.SHOW_ALL, action) =&gt; &#123; switch (action.type) &#123; case 'SET_VISIBILITY_FILTER': // 设置可视化条件 return action.filter default: return state &#125;&#125;export default visibilityFilter 定义行为类型 123456789101112131415161718192021222324// 可以把type和 actioncreator分开let nextTodoId = 0export const addTodo = text =&gt; (&#123; type: 'ADD_TODO', id: nextTodoId++, text&#125;) // 添加todo 行为export const setVisibilityFilter = filter =&gt; (&#123; type: 'SET_VISIBILITY_FILTER', filter&#125;) // 设置可视化条件，点击active 按钮或者completedexport const toggleTodo = id =&gt; (&#123; type: 'TOGGLE_TODO', id&#125;) // 删除待办export const VisibilityFilters = &#123; SHOW_ALL: 'SHOW_ALL', SHOW_COMPLETED: 'SHOW_COMPLETED', SHOW_ACTIVE: 'SHOW_ACTIVE'&#125; // 可视化 表面组件和容器组件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179// 三个组件import React from 'react'import Footer from './Footer'import AddTodo from '../containers/AddTodo'import VisibleTodoList from '../containers/VisibleTodoList'const App = () =&gt; ( &lt;div&gt; &lt;AddTodo /&gt; &lt;VisibleTodoList /&gt; &lt;Footer /&gt; &lt;/div&gt;)export default App//////////////////////////////////////////////////////////////////////// AddTodo.js// 这个逻辑比较简单，分发add todo 事件即可import React from 'react'import &#123; connect &#125; from 'react-redux'import &#123; addTodo &#125; from '../actions'const AddTodo = (&#123; dispatch &#125;) =&gt; &#123; let input return ( &lt;div&gt; &lt;form onSubmit=&#123;e =&gt; &#123; e.preventDefault() if (!input.value.trim()) &#123; return &#125; dispatch(addTodo(input.value)) // 分发addtodo行为，在action中定义好了 input.value = '' &#125;&#125;&gt; &lt;input ref=&#123;node =&gt; input = node&#125; /&gt; &lt;button type=\"submit\"&gt; Add Todo &lt;/button&gt; &lt;/form&gt; &lt;/div&gt; )&#125;export default connect()(AddTodo) // 将react组件使用connect建立起redux和react之间的联系/////////////////////////////////////////////////////////////////////////// FilterLink.jsimport &#123; connect &#125; from 'react-redux'import &#123; setVisibilityFilter &#125; from '../actions'import Link from '../components/Link'const mapStateToProps = (state, ownProps) =&gt; (&#123; active: ownProps.filter === state.visibilityFilter&#125;) // Link组件的属性active，通过比较组件当前状态和上级传入状态，确定是否隐藏const mapDispatchToProps = (dispatch, ownProps) =&gt; (&#123; onClick: () =&gt; dispatch(setVisibilityFilter(ownProps.filter))&#125;) // link组件的点击事件，根据分发事件来确定export default connect( mapStateToProps, mapDispatchToProps)(Link) // 将两个事件处理绑定在link组件中///// 组件之中无需注意事件分发逻辑，只需要暴露组件事件分发的接口import React from 'react'import PropTypes from 'prop-types'const Link = (&#123; active, children, onClick &#125;) =&gt; ( &lt;button onClick=&#123;onClick&#125; disabled=&#123;active&#125; style=&#123;&#123; marginLeft: '4px', &#125;&#125; &gt; &#123;children&#125; &lt;/button&gt;)Link.propTypes = &#123; active: PropTypes.bool.isRequired, children: PropTypes.node.isRequired, onClick: PropTypes.func.isRequired&#125;export default Link///////////////////////////////////////////////////////////////////////////// visibletodolist.jsimport &#123; connect &#125; from 'react-redux'import &#123; toggleTodo &#125; from '../actions'import TodoList from '../components/TodoList'import &#123; VisibilityFilters &#125; from '../actions'// 根据fiter 确定reducer todos如何确定操作const getVisibleTodos = (todos, filter) =&gt; &#123; switch (filter) &#123; // fiter是state.visibilityFilter，一个reducer，会根据分发的action确定返回action.filter,即是显示active还是显示completed，然后todos也是一个reducer将会根据显示条件，对todo进行分类， case VisibilityFilters.SHOW_ALL: return todos case VisibilityFilters.SHOW_COMPLETED: return todos.filter(t =&gt; t.completed) case VisibilityFilters.SHOW_ACTIVE: return todos.filter(t =&gt; !t.completed) default: throw new Error('Unknown filter: ' + filter) &#125;&#125;const mapStateToProps = state =&gt; (&#123; // 得到状态，显示todo todos: getVisibleTodos(state.todos, state.visibilityFilter) // state代表一个全局顶层的reducer&#125;) // state.todos 代表一个reducer，第二个参数也是，返回一个todo的显示与否的结果const mapDispatchToProps = dispatch =&gt; (&#123; // 分发事件的行为，点击待办，删除 toggleTodo: id =&gt; dispatch(toggleTodo(id)) // 按id区分行为&#125;)export default connect( mapStateToProps, mapDispatchToProps)(TodoList) // 对组件todolist todos和toggleTodo属性进行状态和分发事件的绑定////////////////////////// todolist 事件import React from 'react'import PropTypes from 'prop-types'import Todo from './Todo'const TodoList = (&#123; todos, toggleTodo &#125;) =&gt; ( &lt;ul&gt; &#123;todos.map(todo =&gt; &lt;Todo key=&#123;todo.id&#125; &#123;...todo&#125; // 按照id来分配是否toggletodo事件 onClick=&#123;() =&gt; toggleTodo(todo.id)&#125; // 先确定行为属于toggleTodo，然后reducer解决处理，确定todo的completed的值，todo.id ,todo代表状态todos中的一条todo，todo.id为todo的序号，传入id后将会对该todo的completed取反，结果会导致本来是横线会变无横线，或者无横线变有横线 /&gt; )&#125; &lt;/ul&gt;)TodoList.propTypes = &#123; todos: PropTypes.arrayOf(PropTypes.shape(&#123; id: PropTypes.number.isRequired, completed: PropTypes.bool.isRequired, text: PropTypes.string.isRequired &#125;).isRequired).isRequired, toggleTodo: PropTypes.func.isRequired&#125;export default TodoList/// todo.jsimport React from 'react'import PropTypes from 'prop-types'// 单条todo的三个属性const Todo = (&#123; onClick, completed, text &#125;) =&gt; ( &lt;li onClick=&#123;onClick&#125; style=&#123;&#123; // 属性与上层todolist绑定 textDecoration: completed ? 'line-through' : 'none' &#125;&#125; &gt; &#123;text&#125; &lt;/li&gt;)Todo.propTypes = &#123; onClick: PropTypes.func.isRequired, completed: PropTypes.bool.isRequired, text: PropTypes.string.isRequired&#125;export default Todo todos-with-undo使用redux undo实现用更少的代码撤销或者回退上一步（取消撤销） 123456789101112131415161718192021222324252627282930313233343536// 定义好todos 这一个reducer，然后下面这句，最后export undoabletodosconst undoableTodos = undoable(todos, &#123; filter: includeAction(['ADD_TODO', 'TOGGLE_TODO']) &#125;)// 在redo 和undo按钮中，注册redo import React from 'react'import &#123; ActionCreators as UndoActionCreators &#125; from 'redux-undo'import &#123; connect &#125; from 'react-redux'let UndoRedo = (&#123; canUndo, canRedo, onUndo, onRedo &#125;) =&gt; ( &lt;p&gt; &lt;button onClick=&#123;onUndo&#125; disabled=&#123;!canUndo&#125;&gt; Undo &lt;/button&gt; &lt;button onClick=&#123;onRedo&#125; disabled=&#123;!canRedo&#125;&gt; Redo &lt;/button&gt; &lt;/p&gt;)const mapStateToProps = (state) =&gt; (&#123; canUndo: state.todos.past.length &gt; 0, //state.todos相当于undoableTodos canRedo: state.todos.future.length &gt; 0&#125;)const mapDispatchToProps = (&#123; onUndo: UndoActionCreators.undo, // 这一步是 考虑组件变化记忆？？？ onRedo: UndoActionCreators.redo&#125;)UndoRedo = connect( mapStateToProps, mapDispatchToProps)(UndoRedo)export default UndoRedo redux中数据的生命周期主要是以下四个步骤： 你调用事件分发 store.dispatch(action) redux 的store调用给定好的reducer函数 root reducer将多个reducers函数的输出值装入一个单一的状态树 ​","tags":[{"name":"前端开发","slug":"前端开发","permalink":"https://joshuaqyh.github.io/tags/前端开发/"},{"name":"React","slug":"React","permalink":"https://joshuaqyh.github.io/tags/React/"}]},{"title":"IPSec 学习","date":"2018-12-07T02:11:34.000Z","path":"2018/12/07/IPSec-学习/","text":"IP Sec 定义IPSec全称是Internet Protocol Security ，因特网协议安全，由IETF官方定义。 RFC-1825 to RFC-1827。属于一种协议套件，通过认证和加密数据包来保证因特网安全通信。 属于端到端的安全模式。 保护跨IP网络的应用层通信。但应用层无需设计使用ＩＰＳｅｃ。 可以使用SSL（安全套接字），TLS（传输层安全），安全壳（SSH）。 ＩＰＳｅｃ是ISO标准网络层安全协议的后继者。 IP协议的安全性：使用IPＳｅｃ解决 IPＳｅｃ提供网络层加密方案，在网络层对内容先加密再传输。 数据加密方式有 传输模式：对数据部分ｐａｙｌｏａｄ加密。 隧道模式：对整个IP分组进行加密。 数据保护措施 数据保密：使用各种加密手法。主要是对称加密技术。要保证公钥的合法性，我们需要确认发送证书的一方不是伪装的攻击者。Ｘ．５０９证书作为可信第三方为通信双方做身份验证。或者使用预共享的密钥，RSA密钥。 数据完整性度量：保证数据完整。数据做摘要，完整接收后再进行摘要比对。 来源认证：确认收发双方，以信息摘要的方式解决。信息摘要种包含了发送方的地址信息HMAC 防止重放攻击：加上时间戳＋随机数，保证消息唯一区分。 IPSec 的一些基本理念AH认证头协议AH比ESP相比具有更强的认证能力。能有效在数据传送过程中对数据进行完整性度量度量和来源认证，防止重放攻击。 工作原理：在IP数据报前加上一个身份验证报头，报头中有一个带密钥的Hash值。 可单独使用，也可以和ESP协议结合使用。 ESP封装安全载荷协议能够对数据进行完整性度量，来源认证和加密，防止重放攻击。 ESP服务依据建立的SA，对可选项目有所限制 完整性检查和验证一起进行 加密服务是可选的。启用加密，那么也就启用了完整性检车和认证。 一般情况下，ESP只加密数据报中有效载荷部分（传输模式），在端对端的隧道通信下，需要开启隧道模式。 ESP报头位置在IP报头之后，在TCP，UDP报头之前。 可以与AH协议结合使用，也可以单独使用。 ​ Tunnel隧道模式加密原IP报文，作为数据内容，在这段数据内容之前，加上ESP或AH协议头，加上新的IP头，形成IPSec报文进行传输。 Transport Mode传输模式仅保护IP报文中的有效载荷部分，在该过程中原报文结构被修改。然后在修改后有效载荷前加上新的ESP或AH协议头，装回原来的IP地址，形成IPSec报文。 SA安全关联。可以认为是某一连接被IPSec保护的唯一标识。 SA是单向的，一次连接，通信双方都需要创建一个SA。 SAD 安全关联数据库。 SAD条目： 顺序号计数器 顺序号溢出计数器 防止回放窗口 SA有效期 AH协议中所使用的算法和密钥 ESP协议 涉及加密认证的算法和密钥 IPSec运行模式 PMTU 两个通信设备间的MTU 除了SAD外还有 SPI，SPD，IKE ESP协议１. 主要了解隧道模式下IPSec数据报结构。 新IP头 + ESP头 + 加密原数据报 + 加密ESP尾 + ESP的MAC验证码 ２. 传输模式下的ＩＰＳｅｃ数据报结构 原IP头＋ESP头＋加密的原IP数据报文＋加密的ESP尾＋ESP－MAC AH协议不加密，供验证。消息高，不防窃听。 IKE 因特网密钥交换几种IKE协议。 ISAKMP：用于建立SA，密钥。 Oakley：允许在非安全连接中安全交换密钥 SKEME：安全密钥交换机制。 Gateway 模式和Road Warrior模式IPSec适用于： 两个私有网络通过因特网对接 因特网接入私有网络 需要保护好通信数据。 Gateway模式是网关之间的通信，只需要在网关上设置好IPSec模式。 Road Warrior模式一头是网关，另外一头是单个客户端。 注： 私有网络内部主机默认为安全，没有必要对私有网络中的每一个设备配置ＩＰｓｅｃ","tags":[{"name":"信息安全","slug":"信息安全","permalink":"https://joshuaqyh.github.io/tags/信息安全/"}]},{"title":"Java实现MD算法并验证","date":"2018-12-06T16:44:10.000Z","path":"2018/12/07/Java实现MD算法并验证/","text":"一、实验环境说明操作系统：window10 编程语言：Java （JDK版本 11.0.1） 使用IDE：Intellij IDEA 二、算法原理概述实验流程 整个MD5（信息摘要算法5）的基本过程可以概括为以下几个步骤： 填充：消息为 $K$ bits的原始消息数据尾部填充长度为$P$ bits的标识$1000…0 \\, 1\\le P \\le 512$ （至少要填充一个bit) 。使得填充后的消息位数满足$K + P \\equiv 448 (mod \\, 512)$ (注：当$K \\equiv 448(mod \\, 512)$)时，$P = 512$。 填充好的消息尾部需要在附加 $K$值的低64位即$K \\, mod \\,2^{64}$。 最终结果得到 $K + P + 64 \\equiv 0 (mod \\, 512)$的填充消息。 分块：把填充之后的消息结果分割为$L$个$512-bit$ 分组：$Y_0..Y_{L-1}$ 。也是$L$个64字节的分组。 缓冲区初始化：初始化一个$128-bit$的MD缓冲区，记为$CV_q$，表示成4个$32-bit (4个byte)$ 的寄存器$(A,B,C,D)$；$CV_0 = IV (IV为16进制初值)$。 循环压缩 ：对L个消息分组$Y_q(q = 0, 1,…L-1)$ ，逐个经过4重循环的压缩算法。表示为： $$CV_0 = IV$$ $$CV_i = H_{MD5}(CV_{i-1}, Y_i)$$ 得出结果：最后一个消息分组经过$H_{MD5}$压缩得到MD5结果为MD值，即$MD = CV_L$。 ​ 核心压缩步骤 总控流程：$H_{MD5}$ 从$CV$输入128位，分配到缓冲区$(A,B,C,D)$，从消息分组输入512位$Y_q$ ，经过4轮循环，每次循环16次迭代（共64次迭代）之后，得到用于下一轮的输入的$CV$值。如果$Yq = Y_{L-1}$，即输出MD5值。 每轮循环：结合T表元素$T[]$和消息分组的不同部分$X[]$，每轮固定不同的生成函数$F，G，H，I$做16次迭代运算，生成下一轮循环的输入。 四个生成函数$F,G,H,I$ 消息分组的内容：需要靠下标k来进行运算得到参与 迭代的消息部分，代表当前处理消息分组的第$k$个$(k = 0…15)32$位字，即$M_{q × 16 + k}$。 在各轮循环中第$i$ 次迭代$(i = 1..16)$ 使用的$X[k]$ 的确定： ​ 设$j = i -1$：◌ 第1轮迭代：$k = j$. 顺序使用 $ X[0, 1, 2, 3, 4, 5, 6, 7, 8, 9,10,11,12,13,14,15]$ ◌ 第2轮迭代：$k = (1 + 5j) mod 16$. 顺序使用$X[1, 6,11, 0, 5,10,15, 4, 9,14, 3, 8,13, 2, 7,12]$ ◌ 第3轮迭代：$k = (5 + 3j) mod 16$. 顺序使用$X[5, 8,11,14, 1, 4, 7,10,13, 0, 3, 6, 9,12,15, 2]$ ◌ 第4轮迭代：$k = 7j mod 16$. 顺序使用$X[0, 7,14, 5,12, 3,10, 1, 8,15, 6,13, 4,11, 2, 9]$ T 表元素的生成：共有64个元素，用于64次的迭代，每个元素的计算如下。 $$T[i] = int(2_{32}×|sin(i)|)$$$$ int为 取整函数，sin正弦函数，以i 作为弧度输入。$$ 移位数s的确定：s表共有64个元素，用于64次迭代，各次迭代运算采用的左循环移位的s 值：$$s[ 1..16] = { 7, 12, 17, 22, 7, 12, 17, 22, 7, 12, 17, 22, 7, 12, 17, 22 }$$$$s[17..32] = { 5, 9, 14, 20, 5, 9, 14, 20, 5, 9, 14, 20, 5, 9, 14, 20 } $$$$s[33..48] = { 4, 11, 16, 23, 4, 11, 16, 23, 4, 11, 16, 23, 4, 11, 16, 23 }$$$$s[49..64] = { 6, 10, 15, 21, 6, 10, 15, 21, 6, 10, 15, 21, 6, 10, 15, 21 }$$ 一次迭代运算逻辑: $a,b,c,d$为寄存器$A,B,C,D$的内容，每轮循环重的一次迭代运算逻辑如下: 对寄存器A进行迭代：$a \\leftarrow b + ((a + g(b,c,d) + X[k] + T[i]) &lt;&lt;&lt; s)$ 对缓冲区的内容进行向左循环变换，即$(B,C,D,A) \\leftarrow (A,B,C,D)$。$X[k]$为消息分组的部分内容，$g(b,c,d)$为生成函数，$T[i]$为T表元素，$s$为移位数。​ 三、程序设计数据结构本程序使用的数据数据结构如下： 123456789101112static byte[] M; /* 存放消息字节数组 */ static long[] T = new long[64]; /* 迭代运算的T表， 64个元素，每个元素有32bits，16进制8位 */ /*在迭代中的消息数组*/ static long[] X = new long[16]; /*四个寄存器A，B，C，D，构成128bits的迭代缓冲区*/ static long A = 0x67452301; static long B = 0xEFCDAB89; static long C = 0x98BADCFE; static long D = 0x10325476; 消息数组M的生成如下： 123456789101112131415161718FileInputStream fis = new FileInputStream(inputString); // 读入文件流BufferedInputStream bis = new BufferedInputStream(fis); // 将文件流读入缓冲区DataInputStream dis = new DataInputStream(bis); // 将缓冲区数据写入数据流M = new byte[(int) (length + paddingLength + 8)]; // 填充消息最终长度 满足于 length + padding + 8 = 0 mod 64 字节// 将文件内容读入全部字节数组M中并填充for(int i = 0; i &lt; length + paddingLength; i++)&#123; if( i &lt; length)&#123; M[i] = (byte)dis.read(); &#125; else if(i == length)&#123; M[i] = (byte)128; &#125; else&#123; M[i] = 0; &#125;&#125; 迭代运算中的T表数据生成如下： 123456/*生成迭代的T表格*/public static void create_T_Table()&#123; for(int i = 0;i &lt; 64;i++)&#123; T[i] = (long) (Math.floor(Math.abs(Math.sin(i+1)) * (long)Math.pow(2,32))); &#125;&#125; 处理消息分组X[]的生成如下： 12345/*将 512bit的消息处理为 16个字的X数组*/for(j=0,k=0;j&lt;16;j++,k+=4)&#123; X[j] = ((int)M[i * 64 + k] &amp; 0xFF) | ((int)M[i*64+k+1] &amp; 0xFF) &lt;&lt; 8 | ((int)M[i*64+k+2] &amp; 0xFF) &lt;&lt; 16 | ((int)M[i*64+k+3] &amp; 0xFF) &lt;&lt; 24;&#125; 重要模块步骤循环左移s位模块 12345678/* * @ param x 被移数* @ param s 左移的位数* */public static long rotateLeft(long x, long s)&#123; return (x &lt;&lt; s)| (x &gt;&gt; (32 - s)) &amp; 0xFFFFFFFL;&#125;///////////////////////////////////////////////////////////////////// 四个生成函数和四个迭代函数。 1234567891011121314151617181920212223242526/*四重循环使用的函数*//** @param a b c d 为四个缓冲区的内容* k 为X[k]* s 为移位数目* i为 T[j] */public static long F_Func(long a,long b,long c,long d,long k,long s, long i)&#123; return (b + rotate_left(((a + ((b &amp; c) | ((~b) &amp; d)) + k + i) &amp; 0xFFFFFFFFL),s)) &amp; 0xFFFFFFFFL;&#125;public static long G_Func(long a,long b,long c,long d,long k,long s, long i)&#123; return (b + rotate_left(((a + ((b &amp; d) | (c &amp; (~d))) + k + i) &amp; 0xFFFFFFFFL),s)) &amp; 0xFFFFFFFFL;&#125;public static long H_Func(long a,long b,long c,long d,long k,long s, long i)&#123; return (b + rotate_left(((a + (b ^ c ^ d) + k + i) &amp; 0xFFFFFFFFL) , s)) &amp; 0xFFFFFFFFL;&#125;public static long I_Func(long a,long b,long c,long d,long k,long s, long i)&#123; return (b + rotate_left(((a + (c ^ (b | (~d))) + k + i) &amp; 0xFFFFFFFFL), s)) &amp; 0xFFFFFFFFL;&#125;/*将小端形式转为大端形式*/public static long encode(long t)&#123; return ((t &gt;&gt; 24) &amp; 0xff) | ((t &gt;&gt; 16) &amp; 0xff) &lt;&lt; 8 | ((t &gt;&gt; 8) &amp; 0xff) &lt;&lt; 16 | (t &amp; 0xff) &lt;&lt; 24;&#125; 将数据从小端转为大端的形式 1234/*将小端形式转为大端形式*/ public static long encode(long t)&#123; return ((t &gt;&gt; 24) &amp; 0xff) | ((t &gt;&gt; 16) &amp; 0xff) &lt;&lt; 8 | ((t &gt;&gt; 8) &amp; 0xff) &lt;&lt; 16 | (t &amp; 0xff) &lt;&lt; 24; &#125; 获取填充的位数 1234567891011121314String inputString = \"test1.txt\"; // 输入的文件名 File file = new File(inputString); // 文件操作对象 length = file.length(); // 获取文件的字节长度1 // 获取填充的位数 if(length % 64 &lt; 56)&#123; paddingLength = (int)(56 - length % 64); // 字节 &#125; else if(length % 64 == 56)&#123; paddingLength = 64; // 64 字节 &#125; else if(length % 64 &gt; 56)&#123; paddingLength = (int) (64 - (length % 64 - 56)); &#125; 将消息分块 123// 该循环的作用是：对全部原始消息进行分块，每块大小为64个字节，共512位 for(int i = 0; i &lt; (length + paddingLength + 8)/64; i++)&#123; ... 进入4次循环，共64次迭代 123// 进入 4 轮循环，每次循环16次迭代，一共64次迭代 for(j = 0; j &lt; 64; j ++)&#123; int div16 = j / 16; // div16 代表每次循环的迭代次数 每次循环的迭代过程 1234567891011121314151617181920212223switch (div16)&#123; case 0: // 第一轮循环，16次迭代 j_factor = j ; k_index = j_factor; // 分四个A、B、C、D 缓冲区处理 if(j % 4 == 0) &#123; A = F_Func(A,B,C,D,X[k_index],7,T[j]); &#125; else if(j % 4 == 1) &#123; D = F_Func(D,A,B,C,X[k_index],12,T[j]); &#125; else if(j % 4 == 2) &#123; C = F_Func(C,D,A,B,X[k_index],17,T[j]); &#125; else if(j % 4 == 3) &#123; B = F_Func(B,C,D,A,X[k_index],22,T[j]); &#125; break; 原寄存器内容与4重循环后的寄存器内容相加，得到下一轮压缩的寄存器值。 1234A = (A + tmpA) &amp; 0xFFFFFFFFL;B = (B + tmpB) &amp; 0xFFFFFFFFL;C = (C + tmpC) &amp; 0xFFFFFFFFL;D = (D + tmpD) &amp; 0xFFFFFFFFL; 全部消息压缩后，输出结果。 123456System.out.format(\"小端形式MD5：%x %x %x %x\\n\", A,B,C,D);A = encode(A); // 转为大端形式B = encode(B);C = encode(C);D = encode(D);System.out.format(\"大端形式MD5：%x %x %x %x\\n\",A,B,C,D); 使用java自带的MD5函数进行比对验证。 12345678910111213141516/*调用java自带md5函数 输出md5值*/ public static String getMd5ForFile(String fileName) throws IOException, NoSuchAlgorithmException &#123; FileInputStream in = null; File file = new File(fileName); in = new FileInputStream(file); MessageDigest md5 = MessageDigest.getInstance(\"MD5\"); byte[] cache = new byte[2048]; int len; while ((len = in.read(cache)) != -1) &#123; md5.update(cache, 0, len); &#125; in.close(); BigInteger bigInt = new BigInteger(1, md5.digest()); return bigInt.toString(16); &#125;","tags":[{"name":"algorithm","slug":"algorithm","permalink":"https://joshuaqyh.github.io/tags/algorithm/"},{"name":"信息安全","slug":"信息安全","permalink":"https://joshuaqyh.github.io/tags/信息安全/"},{"name":"Java","slug":"Java","permalink":"https://joshuaqyh.github.io/tags/Java/"}]},{"title":"C++实现二叉树各种遍历","date":"2018-12-06T16:08:04.000Z","path":"2018/12/07/C-实现二叉树各种遍历/","text":"前言本文主要使用C++ 实现二叉树的遍历： 前序，中序，后序遍历的递归和非递归实现 层序遍历 深度优先遍历 结点数据结构1234567// Definition for binary tree struct TreeNode &#123; int val; TreeNode *left; TreeNode *right; TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125;&#125;; 前序遍历递归实现1234567void preOrder(TreeNode* root)&#123; if(root != NULL)&#123; cout &lt;&lt; root-&gt;val &lt;&lt; \" \"; preOrder(root-&gt;left); preOrder(root-&gt;right); &#125;&#125; 非递归实现思路： 初始化一个栈用于存储结点指针 若结点非空，访问其值，然后将该结点push入栈。并将左孩子置为当前结点。 若结点为空，那么将当前结点置为栈顶结点的右孩子，并弹出栈顶结点。 重复2，3，直到栈为空或者无结点。 12345678910111213141516void preOrder(TreeNode* root)&#123; if(root == NULL) return; stack&lt;TreeNode*&gt; S; TreeNode* node = root; while(node!=NULL || !S.empty())&#123; if(node != NULL)&#125;&#123; cout &lt;&lt; node-&gt;val &lt;&lt; \" \"; S.push(node); node = node-&gt;left; &#125; else&#123; node = S.top()-&gt;right; S.pop(); &#125; &#125;&#125; 中序遍历递归实现1234567void preOrder(TreeNode* root)&#123; if(root != NULL)&#123; preOrder(root-&gt;left); cout &lt;&lt; root-&gt;val &lt;&lt; \" \"; preOrder(root-&gt;right); &#125;&#125; 非递归实现思想同前序遍历一致，利用栈来实现，唯一不同之处就是访问结点的顺序是在结点出栈的时候才进行。 12345678910111213141516void preOrder(TreeNode* root)&#123; if(root == NULL) return; stack&lt;TreeNode*&gt; S; TreeNode* node = root; while(node!=NULL || !S.empty())&#123; if(node != NULL)&#125;&#123; S.push(node); node = node-&gt;left; &#125; else&#123; cout &lt;&lt; node-&gt;val &lt;&lt; \" \"; node = S.top()-&gt;right; S.pop(); &#125; &#125;&#125; 后续遍历递归实现1234567void preOrder(TreeNode* root)&#123; if(root != NULL)&#123; preOrder(root-&gt;left); preOrder(root-&gt;right); cout &lt;&lt; root-&gt;val &lt;&lt; \" \"; &#125;&#125; 非递归实现难！！！ 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253//后序遍历void PostOrderWithoutRecursion(BTNode* root)&#123; if (root == NULL) return; stack&lt;BTNode*&gt; s; //pCur:当前访问节点，pLastVisit:上次访问节点 BTNode* pCur, *pLastVisit; //pCur = root; pCur = root; pLastVisit = NULL; //先把pCur移动到左子树最下边 while (pCur) &#123; s.push(pCur); pCur = pCur-&gt;lchild; &#125; while (!s.empty()) &#123; //走到这里，pCur都是空，并已经遍历到左子树底端(看成扩充二叉树，则空，亦是某棵树的左孩子) pCur = s.top(); s.pop(); //一个根节点被访问的前提是：无右子树或右子树已被访问过 if (pCur-&gt;rchild == NULL || pCur-&gt;rchild == pLastVisit) &#123; cout &lt;&lt; setw(4) &lt;&lt; pCur-&gt;data; //修改最近被访问的节点 pLastVisit = pCur; &#125; /*这里的else语句可换成带条件的else if: else if (pCur-&gt;lchild == pLastVisit)//若左子树刚被访问过，则需先进入右子树(根节点需再次入栈) 因为：上面的条件没通过就一定是下面的条件满足。仔细想想！ */ else &#123; //根节点再次入栈 s.push(pCur); //进入右子树，且可肯定右子树一定不为空 pCur = pCur-&gt;rchild; while (pCur) &#123; s.push(pCur); pCur = pCur-&gt;lchild; &#125; &#125; &#125; cout &lt;&lt; endl;&#125;--------------------- 作者：苏叔叔 来源：CSDN 原文：https://blog.csdn.net/zhangxiangDavaid/article/details/37115355 版权声明：本文为博主原创文章，转载请附上博文链接！ 层次优先遍历使用队列来实现，每访问一个结点就将该结点左右孩子（如果有）加入队列末尾，然后将结点从队头弹出。 1234567891011121314void levelOrder(TreeNode* root)&#123; if(root == NULL) return; queue&lt;TreeNode*&gt; Q; Q.push(root); while(!Q.empty())&#123; TreeNpde* node = Q.front(); Q.pop(); cout &lt;&lt; node-&gt;val &lt;&lt; \" \"; if(node-&gt;left != NULL) Q.push(node-&gt;left); if(node-&gt;right != NULL) Q.push(node-&gt;right); &#125;&#125; 深度优先遍历使用栈来实现，原理同前序，中序遍历。 12345678910111213void depthOrder(TreeNode* root)&#123; if(root == NULL) return; stack&lt;int&gt; S; S.push(root); while(!S.empty())&#123; TreeNode* node = S.pop(); cout &lt;&lt; node-&gt;val &lt;&lt; \" \"; if(node-&gt;left != NULL) S.push(node-&gt;left); if(node-&gt;right != NULL) S.push(node-&gt;right); &#125;&#125;","tags":[{"name":"C++","slug":"C","permalink":"https://joshuaqyh.github.io/tags/C/"},{"name":"algorithm","slug":"algorithm","permalink":"https://joshuaqyh.github.io/tags/algorithm/"},{"name":"数据结构","slug":"数据结构","permalink":"https://joshuaqyh.github.io/tags/数据结构/"}]},{"title":"Leetcode | 关于树","date":"2018-12-06T08:26:17.000Z","path":"2018/12/06/Leetcode-Practice-1/","text":"以下问题，主要是练习递归的使用，体会递归的思想。 Problem 654 最大数二叉树Medium C++123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114/*********************************Given an integer array with no duplicates. A maximum tree building on this array is defined as follow:The root is the maximum number in the array.The left subtree is the maximum tree constructed from left part subarray divided by the maximum number.The right subtree is the maximum tree constructed from right part subarray divided by the maximum number.Construct the maximum tree by the given array and output the root node of this tree.Example 1:Input: [3,2,1,6,0,5]Output: return the tree root node representing the following tree: 6 / \\ 3 5 \\ / 2 0 \\ 1Note:The size of the given array will be in the range [1,1000].***********************************/#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;stdlib.h&gt;#include &lt;sstream&gt;#include &lt;queue&gt;using namespace std;struct TreeNode &#123; int val; TreeNode *left; TreeNode *right; TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125; &#125;;class Solution &#123;public: // method 1 使用迭代器 快了一点 TreeNode* constructMaximumBinaryTree(vector&lt;int&gt;&amp; nums) &#123; if (nums.empty()) &#123; return nullptr; &#125; auto it = max_element(nums.begin(), nums.end()); TreeNode* root = new TreeNode(*it); vector&lt;int&gt; left(nums.begin(), it); vector&lt;int&gt; right(next(it), nums.end()); root-&gt;left = constructMaximumBinaryTree(left); root-&gt;right = constructMaximumBinaryTree(right); return root; &#125; // method 2 性能差 TreeNode* construct(vector&lt;int&gt;&amp; nums) &#123; return build(nums, 0, nums.size()); &#125; TreeNode* build(vector&lt;int&gt; num, int start, int end) &#123; if (start == end) &#123; return nullptr; &#125; int maxIndex = findMax(num, start, end); TreeNode* root = new TreeNode(num[maxIndex]); root-&gt;left = build(num, start, maxIndex); root-&gt;right = build(num, maxIndex + 1, end); return root; &#125; int findMax(vector&lt;int&gt; num, int start, int end) &#123; int index = start; int max = num[start]; for (int i = start; i &lt; end; i++) &#123; if (num[i] &gt; max) &#123; index = i; max = num[i]; &#125; &#125; return index; &#125;&#125;;总结：1. 使用迭代器速度快了一些2. 递归循环查找速度显然慢了3. 非递归版本速度更快，可利用栈实现以下是 O(n)实现方式（摘自大佬）class Solution &#123;public: TreeNode* constructMaximumBinaryTree(vector&lt;int&gt;&amp; nums) &#123; vector&lt;TreeNode*&gt; stk; for (int i = 0; i &lt; nums.size(); ++i) &#123; TreeNode* cur = new TreeNode(nums[i]); while (!stk.empty() &amp;&amp; stk.back()-&gt;val &lt; nums[i]) &#123; cur-&gt;left = stk.back(); stk.pop_back(); &#125; if (!stk.empty()) stk.back()-&gt;right = cur; stk.push_back(cur); &#125; return stk.front(); &#125;&#125;; 递归统计二叉树结点在某区间内的和123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/**************************************************Given the root node of a binary search tree, return the sum of values of all nodes with value between L and R (inclusive).The binary search tree is guaranteed to have unique values.Example 1:Input: root = [10,5,15,3,7,null,18], L = 7, R = 15Output: 32Example 2:Input: root = [10,5,15,3,7,13,18,1,null,6], L = 6, R = 10Output: 23Note:The number of nodes in the tree is at most 10000.The final answer is guaranteed to be less than 2^31.*******************************************************/#include &lt;iostream&gt;using namespace std;struct TreeNode &#123; int val; TreeNode *left; TreeNode *right; TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125;&#125;;class Solution &#123;public: int sum = 0; int rangeSumBST(TreeNode* root, int L, int R) &#123; tranverse(root, L, R); // 递归统计 return sum; &#125; void tranverse(TreeNode* root, int L, int R) &#123; if (root == NULL) return; if (root-&gt;val &lt;= R &amp;&amp; root-&gt;val &gt;= L) &#123; sum += root-&gt;val; &#125; tranverse(root-&gt;left, L, R); tranverse(root-&gt;right, L, R); &#125;&#125;; 简单二叉树剪枝1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253/*Question:We are given the head node root of a binary tree,where additionally every node's value is either a 0 or a 1.Return the same tree where every subtree (of the given tree) not containing a 1 has been removed.(Recall that the subtree of a node X is X, plus every node that is a descendant of X.)Author: qiuyhDate: 18/09/16描述：一个二叉树，节点值为0或1，我们要对一棵给定的二叉树剪枝，将其子树的节点值全为0的去除掉思路：利用递归实现，将每一个节点视为根节点，递归判断是否全为0，为0则该点置为null*/#include &lt;iostream&gt;#include &lt;string&gt;using namespace std;struct TreeNode &#123; int val; TreeNode *left; TreeNode *right; TreeNode(int x) : val(x), left(NULL), right(NULL) &#123;&#125;&#125;;class Solution &#123; TreeNode* resultNode;public: TreeNode * pruneTree(TreeNode* root) &#123; // 找到空节点，就返回 if (root == NULL) return root; // 继续下溯，若返回值可能为空或者不为空 root-&gt;left = pruneTree(root-&gt;left); root-&gt;right = pruneTree(root-&gt;right); // 左右节点都为空而且值为0，则返回一个空指针 if (root-&gt;left == NULL &amp;&amp; root-&gt;right == NULL &amp;&amp; root-&gt;val == 0) &#123; return nullptr; &#125; // 最后返回剪枝后的节点 return root; &#125;&#125;; 矩阵递归搜索1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859/*Question:An image is represented by a 2-D array of integers, each integer representing the pixel value of the image (from 0 to 65535).Given a coordinate (sr, sc) representing the starting pixel (row and column) of the flood fill,and a pixel value newColor, \"flood fill\" the image.To perform a \"flood fill\", consider the starting pixel, plus any pixels connected 4-directionally to the starting pixel of the same color as the starting pixel, plus any pixels connected 4-directionally to those pixels (also with the same color as the starting pixel), and so on. Replace the color of all of the aforementioned pixels with the newColor.At the end, return the modified image.Author:qiuyhDate: 18/09/16描述：给定一个二维矩阵，和一个起点和一个颜色， 该起点会向相邻水平竖直四个方向的点进行染色， 然后被染色的点成为新的点思路：1.从起点开始，进行行列扫描，遇到相邻且颜色相同的点， 继续加入起点，然后继续行列扫描， 时间复杂度大，不建议 2. */#include &lt;iostream&gt;#include &lt;vector&gt;using namespace std;class Solution &#123;public: vector&lt;vector&lt;int&gt;&gt; floodFill(vector&lt;vector&lt;int&gt;&gt;&amp; image, int sr, int sc, int newColor) &#123; if (image[sr][sc] == newColor) return image; int oldColor = image[sr][sc]; image[sr][sc] = newColor; if (sc + 1 &lt; image[sr].size() &amp;&amp; oldColor == image[sr][sc + 1]) &#123; floodFill(image, sr, sc + 1, newColor); &#125; if (sc - 1 &gt;= 0 &amp;&amp; oldColor == image[sr][sc - 1]) &#123; floodFill(image, sr, sc - 1, newColor); &#125; if (sr + 1 &lt; image.size() &amp;&amp; oldColor == image[sr + 1][sc]) &#123; floodFill(image, sr + 1, sc, newColor); &#125; if (sr - 1 &gt;= 0 &amp;&amp; oldColor == image[sr - 1][sc]) &#123; floodFill(image, sr - 1, sc, newColor); &#125; return image; &#125;&#125;; 递归的思想和步骤： 递归就是找到重复相似的步骤，重复调用同一函数实现。 需要找到递归的终结条件。 明确多重递归之间的参数变量关系。","tags":[{"name":"C++","slug":"C","permalink":"https://joshuaqyh.github.io/tags/C/"},{"name":"algorithm","slug":"algorithm","permalink":"https://joshuaqyh.github.io/tags/algorithm/"},{"name":"Leetcode","slug":"Leetcode","permalink":"https://joshuaqyh.github.io/tags/Leetcode/"}]},{"title":"深度学习 |人脸属性数据集 CelebA","date":"2018-12-06T08:26:17.000Z","path":"2018/12/06/人脸属性数据集CelebA/","text":"人脸属性数据集CelebACelebA 解释数据集基本描述 10177 个名人 202599张人脸图片 40个属性标记 人脸bbox标注框 5个人脸特征点坐标 由香港中文大学开放提供，网址在这里 网盘文件夹描述如下： img Anno是bbox、landmark及attribute注释文件；（标注文件夹） Eval是training、validation及testing数据集的划分注释；（划分描述文件夹） Img则是存放相应的人脸图像，（人脸图片文件夹） README.txt是CelebA介绍文件； 虽然img文件夹提供了多种格式的图片，我们一般只需要用到 .jpg（img_align_celeba.zip)，文件内部的图片都是有排序的。 标签解释 人脸标注框 人脸5个特征点， align代表着图片经过处理对齐。 40个特征属性标记 每个属性代表的含义是： 5_o_Clock_Shadow：刚长出的双颊胡须 Arched_Eyebrows：柳叶眉 Attractive：吸引人的 Bags_Under_Eyes：眼袋 Bald：秃头 Bangs：刘海 Big_Lips：大嘴唇 Big_Nose：大鼻子 Black_Hair：黑发 Blond_Hair：金发 Blurry：模糊的 Brown_Hair：棕发 Bushy_Eyebrows：浓眉 Chubby：圆胖的 Double_Chin：双下巴 Eyeglasses：眼镜 Goatee：山羊胡子 Gray_Hair：灰发或白发 Heavy_Makeup：浓妆 High_Cheekbones：高颧骨 Male：男性 Mouth_Slightly_Open：微微张开嘴巴 Mustache：胡子，髭 Narrow_Eyes：细长的眼睛 No_Beard：无胡子 Oval_Face：椭圆形的脸 Pale_Skin：苍白的皮肤 Pointy_Nose：尖鼻子 Receding_Hairline：发际线后移 Rosy_Cheeks：红润的双颊 Sideburns：连鬓胡子 Smiling：微笑 Straight_Hair：直发 Wavy_Hair：卷发 Wearing_Earrings：戴着耳环 Wearing_Hat：戴着帽子 Wearing_Lipstick：涂了唇膏 Wearing_Necklace：戴着项链 Wearing_Necktie：戴着领带 Young：年轻人","tags":[{"name":"深度学习","slug":"深度学习","permalink":"https://joshuaqyh.github.io/tags/深度学习/"},{"name":"计算机视觉","slug":"计算机视觉","permalink":"https://joshuaqyh.github.io/tags/计算机视觉/"}]},{"title":"消息认证和哈希算法","date":"2018-12-03T09:59:20.640Z","path":"2018/12/03/消息认证和哈希函数/","text":"消息认证概述网络通信针对消息内容的攻击方法： 伪造消息 篡改消息内容 改变消息顺序 消息重放或者延迟 消息认证过程： 接收者确信消息未被改变 接收者确信消息来自所生成的发送者 消息中含有序列号，保证正确的消息顺序 消息认证的三种方式： 消息认证加密。对消息加密，以密文作为消息的认证标识。 消息认证码MAC。使用一个公开函数，加上密钥，为消息产生一个数据块，作为消息的认证标识并附加到消息中一起传输。 哈希方法。使用一个公开函数，将消息映射到一个固定长度的散列值，并作为消息认证标识附加到消息中一起传输。 数字签名。基于非对称密码技术的数字签名将签名与被签文件绑定，提供了不可依赖不可伪造，容易验证的功能。 ​ MAC 消息认证码消息验证码有三部分算法（G：密钥生成算法；S：签名算法；V：消息验证算法） 基本结构： MAC方法双方使用一个共享的密钥，为目标消息生成一个固定的数据块，并加入到消息中，该数据块被称为消息认证码，或者是密码校验和。 MAC函数类似于加密函数，但不需要 可逆性，因此收到攻击的弱点在数学上比加密算法要少。 使用MAC的理由： 主要提供真实性。 与加密算法比较，代价算法较小。 认证和保密函数分离较为灵活 很多信息需要真实性而不是保密性。 模型 只用于消息认证的MAC模型 用于与明文相关的消息认证和保密性的MAC模型 用于与密文相关的消息认证和保密性的MAC模型 与数字签名都用于消息认证。MAC是通讯双方共享一个私有密钥。而数字签名则是利用公钥密码技术实现。 ##HASH 输入变长的消息，经过hash输出定常的散列值。 哈希函数的一些基本要求 能够映射任意长的分组数据 产生定长的哈希结果 可计算，易于计算 单向性 抗碰撞（强弱） 分类 按规避碰撞能力分： 强无碰撞 弱无碰撞 按是否需要密钥分： 不带密钥的hash 带密钥的hash ​ 生日攻击理论：计算哈希碰撞的概率和计算量之间的关系 hash函数通用模型由merkle提出的模型结构: 将消息M划分为一些固定长度的块Yi 最后一块padding并使其包含消息M的长度 设定初始值CV0 采用压缩函数f，CVi = f（CVi-1， Yi-1） 最后一个CVi为hash值。 MD5 算法信息摘要5算法。确保信息传输的完整性和一致性。 使用小端模式，输入不定长度信息，以512bit进行分组，生成4个32bit的数据，最后联合输出固定128bit的信息摘要。 小端模式，低字节放在低地址处。 算法逻辑 填充 在长度为 $K$ bits的原始消息数据尾部填充长度为 $P$ bits的标识$100…0 。$ $ 1 \\le P \\le 512$ ,使得填充后的消息位数为$K + P \\equiv 448(mod \\, 512)$。 注意：当$K \\equiv 448 (mod\\,512)$时，$P = 512$。 向上述填充好的消息尾部附加$K$值得低64位，即$(K \\, mod \\, 2^{64})$。最后得到一个长度位数为$K + P + 64 \\equiv 0 (mod \\, 512)$。 分块 将填充后得消息结果分割为$L$ 个$512-bit$分组,记为:$Y_0, Y_1, …, Y_{L-1}$ 分组结果表示为$N$个$32-bit$字记为$M_0, M_1, …, M_{N-1}, N = L×16 $ 初始化 初始化一个$128-bit$ 的MD缓冲区，记为$CV_q$,表示成4个$32-bit$寄存器$(A,B,C,D)$； $CV_0 = IV$。迭代在MD缓冲区进行，最后一步的$128-bit$输出即为算法的结果。","tags":[{"name":"信息安全","slug":"信息安全","permalink":"https://joshuaqyh.github.io/tags/信息安全/"},{"name":"加密技术","slug":"加密技术","permalink":"https://joshuaqyh.github.io/tags/加密技术/"}]},{"title":"机器学习| K-means and mean-shift","date":"2018-12-03T04:51:17.000Z","path":"2018/12/03/机器学习-聚类算法-K-means-and-mean-shift/","text":"聚类算法K-means 算法算法步骤 随机确定好 k个聚类中心 根据离聚类中心最近的原则给样本点分类 根据分类后的样本点集合进行平均重新 计算聚类中心。返回2； 存在聚类中心差异小的时候，结束计算。 K值的挑选 cost function ： 分类后的样本点和聚类中心的方差作为代价函数。 K值变大，cost function 变小 Elbow method 可以确定变化的骤变点。该点是 K-cost function图像上曲率最大的点。 使用K-means进行图像分割 特征聚类 亮度聚类 颜色空间聚类 优点： 类密集且区别明显的时候，分类效果好 强的一致性 算法复杂度O(NMt)，处理大数据集是高效的 缺点： 初始化中心的选择影响收敛 需要预先给出k值 噪声敏感 收敛到局部最优解，可能效果感人。。 Mean shift在数据空间中，确定一个圆区域，计算圆内数据质心，然后圆心漂移到质心，重新在圆内计算质心，直到圆心等于质心。即收敛，达到局部最小值。 另外一种表述，在窗口中计算均值漂移向量，变换密度窗口，重复计算变换直到收敛。 不受噪声敏感(除三维颜色，还引入位置坐标信息) 参数单一 维度越高，聚类越慢 重复计算(染色标记降低冗余)","tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://joshuaqyh.github.io/tags/机器学习/"},{"name":"数据挖掘","slug":"数据挖掘","permalink":"https://joshuaqyh.github.io/tags/数据挖掘/"},{"name":"图像分割","slug":"图像分割","permalink":"https://joshuaqyh.github.io/tags/图像分割/"}]},{"title":"信息安全 | 认证技术","date":"2018-11-28T08:24:19.198Z","path":"2018/11/28/零知识证明/","text":"零知识证明Fiat-Shamir 算法 $n = p * q。p, q$是大素数。 $n$为可信第三方机构公开，而$p, q$为私有或者销毁 $s: Alice$的密钥, $0 &lt; s &lt; n$。 Alice 必须证明其知晓密钥$s$,而不需要向任何人出示$s$。 $v:Alice$的公钥，满足$v \\equiv s^2 \\, mod \\, n$ 。 Alice 计算并得出v展示给Bob 无法从v推导出s。 $r: Alice$随机挑选的一个数字，满足$0 &lt; r &lt; n-1$。 $x : x = r^2 \\, mod \\, n$ 作为一个Alice计算后的证据x(evidence)，并发送给Bob。 $c: $ Bob随机挑选的一个数c(challenger)，范围是{1， 0}。 $y : y = rs^c \\, mod \\, n$ 由$Alice$计算得到结果y（response），并发送给Bob。 Bob通过计算$y^2\\, mod \\,n \\,\\,?= xv^c\\, mode \\, n$ ,如果相等，则认证完毕。 认证技术X.509数据协议，定义一个数据目录服务，维护一个用户信息数据库。 Kerberos认证协议，用于证明接收双方的合法性。基于C/S结构的单向认证，弱双向认证。 ##认证攻击类型 假冒攻击 重放攻击 强迫延时攻击 交错攻击 Oracle会话攻击 并行会话攻击 PKIPKI 公钥基础设施，通过公开密钥技术和数字证书，来确保系统信息安全，并负责验证数字证书持有者身份的体系。绝对安全，由国家信用作为背书。 应用：VPN，安全电子邮件，web服务安全。 KerberosKerberos 是一种计算机网络认证协议。基于票据（tickets） 的工作原理和$Neeedham-Schroeder \\, Symmetric \\, key \\, Protocol$，允许结点以一种安全的策略，在不安全的网络中，互相证明的身份。 防窃听，防重放攻击。 C/S 模型，提供双方认证。 该协议无竞争对手！ 开源，多平台可用。 该协议建立在对称加密体系之上，并且需要一个可信的第三方机构 。在特定的认证情景中使用不同的对称加密算法。 * $Neeedham-Schroeder \\, Symmetric \\, key \\, Protocol$情景： TA是一个第三方的可信机构，可分发密钥中心，能够提供双方会话共享密钥。 E（K，-）是一个对称加密算法（如DES） TA拥有一个密钥$K_{AT}$y与Alice一致，同样也有一个$K_{BT}$ 与Bob一致。 Alice使用一个随机数$r_A$ 来认证TA，并从TA获得一个会话密钥 $K_{AB}$ 。 Alice使用$K_{BT}$加密$(K_{AB}, r_B) $ 发给bob，bob使用$K_{BT}$解密。 Bob使用会话密钥$K_{AB}$ 加密$r_B $发送给Alice。 Alice使用$K_{AB}$解密得到$r_B$，并使用$K_AB$加密$r_B - 1$ 发送给Bob，Bob解密检查结果是否为$r_B -1$ 。 * 架构AS = 认证服务器（认证机构） SS = 提供服务的服务器（服务机构） TGS= 票据许可服务器 TGT = 许可的票据 ST = 服务票据 * 流程 用户客户端注册 客户端认证 客户服务认证 客户服务请求 客户登录步骤： 用户输入用户名和密码，构成【长期密钥】，用于加密网络传输的数据。 使用hash函数运行输入的密码，得到客户的主密钥【客户/客户 密钥】，并由客户端保管。 TGS，SS会话密钥属于短期密钥，利用主密钥实现交换和发布。 客户认证步骤： 客户机向AS发送一个明文消息，代表用户请求服务。 AS校验Bob是否在其数据库中，如果在，则AS返回一下两条信息给客户 消息A，用主密钥加密的【客户/TGS】会话密钥。 消息B， 用TGS加密的票据授权票据TGT，客户网络地址，票据有效期，【客户/TGS会话密钥】。 客户机收到A，B，使用主密钥解密A 得到【客户/TGS 会话密钥】,消息B无法解密，因为没有TGS密钥来解密。 客户服务认证步骤： 申请服务时，客户机向TGS发送两条消息： 消息C，由消息B和申请服务的ID组成。 消息D，用【客户/TGS会话密钥】加密的认证。（客户ID+时间戳组成） 基于收到的消息C，D，TGS将从消息C中重新获取消息B，用TGS密钥解密消息B，从而得到【客户/TGS会话密钥】，TGS使用这个密钥解密消息D，成功认证，然后返回两条消息给客户机 ： 消息E，用SS服务器加密的客户-SS服务票据ST（客户ID，客户网络地址，【客户/SS会话密钥】，票据有效期） 消息F：用【客户/TGS会话密钥】加密的【客户/SS会话密钥】。 客户服务申请步骤: 基于从TGS收到的消息E，F，客户机有足够的消息向SS认证自己。客户机发送消息给SS： 消息E，由先前步骤得到的E。 消息G：用【客户/SS会话密钥】加密的一个新的认证，包括客户ID和时间戳 SS用自己的密钥解密消息E（票据），重新得到 【客户/SS会话密钥】，用这个会话密钥，SS解密消息G得到认证，返回确认函H给客户机，确认该身份真实，并同一向该客户提供服务。 消息H：在客户认证中找到时间戳， +1，用【客户/SS会话密钥加密】 客户机使用【客户/SS会话密钥】解密确认函H，并检查时间戳是否被正确地更新，如果是，客户机可以信赖该服务器，并向该服务器发送服务请求。 服务器向客户机提供所请求地服务。 * 局限性 单点故障：中心化 时钟同步：未同步时间戳认证将会失效。 管理协议未标准化","tags":[{"name":"信息安全","slug":"信息安全","permalink":"https://joshuaqyh.github.io/tags/信息安全/"},{"name":"加密认证技术","slug":"加密认证技术","permalink":"https://joshuaqyh.github.io/tags/加密认证技术/"}]},{"title":"python实现DES加密算法","date":"2018-11-28T07:08:57.541Z","path":"2018/11/28/DES 算法/","text":"一、 DES算法原理概述预备知识 64位为一个分组，当成明文输入DES算法模型，输出同样长度64位的密文。 对称加密，加密密钥也是解密密钥，密钥定义了加密过程。 密钥构成：64位，每8位的最后一位用于奇偶校验，所以实际密钥长度为56位。 基本过程是换位和置换（根据置换矩阵） ​ 算法核心概要 总体结构 Feistel轮函数 子密钥生成 解密过程 ​ 信息空间处理： 原始明文消息的处理：最后的分组不足64位时，填充的字节为缺失的字节数目。 明文分组结构：$M = m_1m_2…m_{64} \\,, m_i ∈ {0， 1}，i= 1…64 $ 密文分组结构： $C = c_1c_2…c_{64} \\,, c_i ∈ {0， 1}，i= 1…64 $ 密钥结构:$K = k_1k_2…k_{64} \\,, k_i ∈ {0， 1}，i= 1…64 $ ​ 加密过程：64位原始密文M经IP初始置换得到$IP(M)$ $IP(M)$经过16次迭代$T_1, T_2… T_{16}$ 得到$T_16T_15…T_1IP(M)$ 然后在经过$IP^{-1}$ 逆变换得到密文。 解密过程：加密逆向进行分析。和加密不同的是，子密钥调度过程为逆序，其他一致。 初始置换：给定一个固定的初始置换IP矩阵来重排明文块M中的二进制位。得到二进制串$M_0 = IP (M) = L_0R_0$ 表： IP置换表（8 8）（row col 下同） 迭代T 迭代规则：交叉迭代。$L_i = R_{i-1} \\,\\, R_i = L_{i-1} \\bigoplus f(R_{i - 1}, K_i)$. $K_i$为子密钥，长度为$$K_i\\,, f$$为$$fiestel$$ 轮函数。 16次迭代后产生$L_{16}R_{16}$ 左右交换输出$R_{16}L_{16}$ ​ 逆置换$P^{-1}$ $C = IP^{-1}(R_{16}L_{16})$ 表： 逆置换表（8 * 8） 轮函数$f(R_{i-1}, K_i)$密码函数f(R, K)接受两个输入：32 位的数据和 48 位的子密钥。然后： 通过表 E 进行扩展置换 （表），将输入的 32 位数据扩展为 48 位； 将扩展后的 48 位数据与 48 位的子密钥进行异或运算； 将异或得到的 48 位数据分成 8 个 6 位的块，每一个块通过对应的一个 S 表产生一个 4 位的输出。其中，每个 S 表都是 4 行 16 列。具体的置换过程如下：把 6 位输入中的第 1 位和第 6 位取出来行成一个两位的二进制数 x ，作为 Si 表中的行数（0~3）；把 6 位输入的中间 4 位构成另外一个二进制数 y，作为 Si 表的列数（0~15）；查出 Si 盒表（8 4 16 的矩阵）中 x 行 y 列所对应的整数，将该整数转换为一个 4 位的二进制数。 把通过 S 表置换得到的 8 个 4 位连在一起，形成一个 32 位的数据。然后将该 32 位数据通过表 P 进行置换（称为P-置换），置换后得到一个仍然是 32 位的结果数据，这就是f(R, K)函数的输出。 三个表：E扩展置换表（8 6），S盒置换表（4 16），P-置换表（8 * 4） ​ 子密钥生成 对密钥K中的56个非校验位实现PC-1置换，得到$C_0D_0$,即置换后的前28位和后28位。 对$C_{i-1} D_{i-1}$ 分别进行循环左移操作，得到$C_{i}D_{i}$,当$i = 1，2，9，16$时二进制串左移一个位置，否则左移两个位置。 对56位的$C_iD_i$ 实行PC-2压缩置换，得到48位的$K_i$ 。 然后$i++$。 如果已经得到$K_{16}$，密码调度结束，否则转步骤2. 两个表：压缩置换表PC-1 PC-2 ​ 二、 代码模块核心函数展示和描述由于解密函数需要的模块基本与加密一致，所以不做呈现。 1234567891011#####加密总函数############################################################################# 1. 初始置换 2. 交叉迭代 3. 逆置换def Encryption(plainText, secretKey): if PRINT_FLAG == True: print(\"&gt; 开始加密64位明文\") M = list(plainText) L0, R0 = InitialPermutation(M) RL = CrossIterationInEncryption(L0, R0, secretKey) cipherText = \"\".join(InversePermutation(RL)) return cipherText############################################################################################## 1234567891011121314######表格置换函数###########################################################################\"\"\" function: transfrom the binaryStr with the giver permutation table condition: len(binaryStr) == len(PermutationTable) return: the permutated binary List.\"\"\"# 传入01字符串列表和置换表，返回置换结果def Permutation(binaryStr, PermutationTable): length = len(PermutationTable) PermutatedList = [] for i in range(0, length): PermutatedList.extend(binaryStr[PermutationTable[i] - 1]) return PermutatedList############################################################################################ 1234567891011121314151617181920212223#########加密过程的的交叉迭代####################################################################\"\"\" function: make cross iteration on L0, R0 for 16 times input: L0--the front 32 bits of 64-bits plain text , R0--the back 32 bits of plain text return: R16--the back iterated 32-bits result, L16--the front iterated 32-bits result \"\"\"# 16次交叉迭代，返回RL列表用于逆置换。def CrossIterationInEncryption(L_0, R_0, SecretKey): if PRINT_FLAG == True: print(\"&gt; 正在进行加密过程的交叉迭代\") R = \"\" L = \"\" tmp_R = R_0 tmp_L = L_0 sonKeyList = createSonKey(SecretKey) for i in range(1,17): L = tmp_R R = XOROperation(tmp_L,Feistel(tmp_R,sonKeyList[i - 1])) tmp_R = R tmp_L = L RL = R + L return RL ############################################################################################## 1234567891011121314151617181920212223242526272829303132333435####创建子密钥##################################################################################\"\"\" function: create the 16 son keys with the given key return: sonKeysList: 16 son keys list\"\"\"def createSonKey(SecretKey): # 提取密钥中的非校验位 if PRINT_FLAG == True: print(\"&gt; 正在生成16个子密钥\") str_56_bits_List = list(SecretKey) sonKeyList = [] # 进行PC-1置换 Temp_PC_1_PermutationResult_C_i_1, Temp_PC_1_PermutationResult_D_i_1 = PC_1_Permutation(str_56_bits_List) C_i = [] D_i = [] for i in range(1, 17): # C_i-1 D_i-1 # 计算C_i D_i # 循环左移 if i == 1 or i == 2 or i == 9 or i == 16: C_i = shiftLeft(Temp_PC_1_PermutationResult_C_i_1, 1) D_i = shiftLeft(Temp_PC_1_PermutationResult_D_i_1, 1) else: C_i = shiftLeft(Temp_PC_1_PermutationResult_C_i_1, 2) D_i = shiftLeft(Temp_PC_1_PermutationResult_D_i_1, 2) CD = C_i + D_i # PC2压缩置换 sonKey_i = PC_2_Permutation(CD) sonKeyList.append(sonKey_i) Temp_PC_1_PermutationResult_C_i_1 = C_i Temp_PC_1_PermutationResult_D_i_1 = D_i if i == 16: break return sonKeyList############################################################################################## 12345678910111213141516171819#####Feistel 函数#############################################################################\"\"\" function: Feistel function to create bit-stR_ing to permute with R_i -- a 32-bit stR_ing input: R_i_1--the (i-1)th back 32 bits string, K_i--the son secret key return: Feistel result (string type)\"\"\"# 轮函数：1. E扩展置换； 2. 扩展结果和子密钥进行异或运算 3. 进行S盒6-4转换def Feistel(R_i_1, K_i): if PRINT_FLAG == True: print(\"&gt; 正在执行feistel轮函数\") E_ExpandResult = E_Expand(R_i_1) xorResult = XOROperation(E_ExpandResult, K_i) str_32_bits = [] for i in range(8): str_6_bits = xorResult[i * 6: i * 6 + 6] str_32_bits += S_Box_Transformation(str_6_bits, i + 1) return \"\".join(P_Permutation(str_32_bits))############################################################################################## 123456789101112####随机生成64位key，8个字符#####################################################################\"\"\" return: a 64-bits (8 bytes) string as a secret key\"\"\"def createSecrteKey(): seed = \"1234567890abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!@#$%^&amp;*()_+=-\" key = [] for i in range(8): key.append(random.choice(seed)) randomSecretKey = ''.join(key) return randomSecretKey################################################################################################ 1234567##########8个字符的字符串转为ascii，然后转 0 1串####################################def ToBitString(string_8_char): strList = [] for i in range(8): strList.append(str(int2bin(ord(string_8_char[i]), 8))) return \"\".join(strList)################################################################################## 1234567891011########64位bits转为8个ascci字符###################################################def ToAsciiChar(string_64_bits): strList = [] bitList = list(string_64_bits) for i in range(8): if int(\"\".join(bitList[i * 8: i * 8 + 8]), 2) &lt; 8: continue # 八个bit一个处理单元，先转为10进制，然后转ascii，存入列表 strList.append(chr(int(\"\".join(bitList[i * 8: i * 8 + 8]), 2))) return \"\".join(strList)################################################################################## 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253############ 加密过程和解密过程while True: text_8_bytes = PlainTextFile.read(8) # 读取8个ascii字符 if not text_8_bytes: print(\"读取明文文件到结尾啦\") break if len(text_8_bytes) != 8: full_flag = False else: bitString = ToBitString(text_8_bytes) # 8个ascii字符转十进制int，然后再转为64位01 # 加密 encryptStr = Encryption(bitString, secretKeyBitString) # 加密结果写入文件 CipherTextFile.write(str(ToAsciiChar(encryptStr))) # 解密 decryptStr = Decryption(encryptStr, secretKeyBitString) # 解密结果写入文件 DecryptTextFile.write(str(ToAsciiChar(decryptStr))) if full_flag == False: # 如果尾部字节不足8个，那么每个字节都填入缺失的字节数量 NumOfLostBytes = 8 - len(text_8_bytes) bitStringList = [] for i in range(len(text_8_bytes)): bitStringList.append(int2bin(ord(text_8_bytes[i]), 8)) full_8_bits = int2bin(NumOfLostBytes, 8) # 填充的比特串 # 填充的字节数 转为bitstring for i in range(NumOfLostBytes): bitStringList.append(full_8_bits) bitString = \"\".join(bitStringList) #补全64位分组 # 加密 encryptStr = Encryption(bitString, secretKeyBitString) # 加密结果写入文件 CipherTextFile.write(str(ToAsciiChar(encryptStr))) # 解密 decryptStr = Decryption(encryptStr, secretKeyBitString) # 解密结果写入文件 DecryptTextFile.write(str(ToAsciiChar(decryptStr))) # 读取完整的8个字节分组字节，尾部填充8个字节，取值都为08 if full_flag == True: zero_eight = \"00001000\" tmpList = [] for i in range(8): tmpList.append(zero_eight) bitString = \"\".join(tmpList) # 加密 encryptStr = Encryption(bitString, secretKeyBitString) # 加密结果写入文件 CipherTextFile.write(str(ToAsciiChar(encryptStr))) # 解密 decryptStr = Decryption(encryptStr, secretKeyBitString) # 解密结果写入文件 DecryptTextFile.write(str(ToAsciiChar(decryptStr))) 数据结构说明 明文，密文，解密后的数据 从明文文件中读取8个ascii字符，存放在string结构中，然后再转换为64个ascii字符的0 1 字符串作为加密的明文。加密结果和解密结果也是转换为ascii字符串，存放在文件中。 加密解密过程的0 1 字符串数据 在实际操作中，由于python中的string不支持赋值以及增删操作，所以通过python里的list即列表来存放字符串，通过list 方便的操作接口来执行加密解密。而string和list之间的转换方式也很简单，如下。 12List = list(str) # string 转 liststr = \"\".join(List) # list 转string 三、 完整代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606\"\"\" Autor: qiuyh contact: 576261090@qq.com Date: 18/11/1 Description: achieve an encryption algoriithm -- DES(Data Encryption Standard) Note: To code a nice code !\"\"\"import numpy import random#########文件变量CIPHER_TEXT_FILE = \"cipherText.txt\" #密文文件PLAIN_TEXT_FILE = \"plainText.txt\" #明文文件SECRET_KEY_FILE = \"secretKey.txt\" #密钥文件DECRYPT_TEXT_FILE = \"decryptText.txt\" #解密文件######## 显示过程变量,为真显示加密步骤PRINT_FLAG = True########异或运算###################################################################################\"\"\" function:do XOR operation on bits string s1, s2 异或运算 condition: len (s1) == len(s2) return: xorResult -- the xor result and itstype is list\"\"\"def XOROperation(s1,s2): length = len(s1) xorResult = [] for i in range(0, length): # 转为int类型0，1比特，进行异或操作后，转为string类型 xorResult.extend(str(int(s1[i]) ^ int(s2[i]))) return xorResult############################################################################################################## int 转 二进制 指定位数#####################################################################def int2bin(n, count=24): \"\"\"returns the binary of integer n, using count number of digits\"\"\" return \"\".join([str((n &gt;&gt; y) &amp; 1) for y in range(count-1, -1, -1)])############################################################################################################表格置换函数###################################################################################\"\"\" function: transfrom the binaryStr with the giver permutation table condition: len(binaryStr) == len(PermutationTable) return: the permutated binary List.\"\"\"def Permutation(binaryStr, PermutationTable): length = len(PermutationTable) PermutatedList = [] for i in range(0, length): PermutatedList.extend(binaryStr[PermutationTable[i] - 1]) return PermutatedList######################################################################################################循环左移############################################################################################\"\"\" function: to achieve cycle shift n bits. return: the shifted result.\"\"\"def shiftLeft(binaryStr, nBits): length = len(binaryStr) nBits = nBits % nBits shiftedList = list(binaryStr) for i in range(0, length): if i &lt; nBits: shiftedList.extend(shiftedList[0]) del shiftedList[0] else: break return shiftedList######################################################################################################字节转比特#########################################################################################def ByteToBit(ByteString): bitList = [] for i in range(0,4): bitList.insert(0, str(ByteString%2)) ByteString = int(ByteString / 2) bitResult = \"\".join(bitList) return bitResult#############################################################################################################初始P置换####################################################################################InitialPermutationTable=[58,50,42,34,26,18,10,2, 60,52,44,36,28,20,12,4, 62,54,46,38,30,22,14,6, 64,56,48,40,32,24,16,8, 57,49,41,33,25,17,9,1, 59,51,43,35,27,19,11,3, 61,53,45,37,29,21,13,5, 63,55,47,39,31,23,15,7]\"\"\" function: Initial permutation function input: M_0--64bit plain text block return: L_0--the front 32 bits of M_0 , R0--the back 32 bits of M_0\"\"\"def InitialPermutation(M_0): if PRINT_FLAG == True: print(\"&gt; 进行初始IP置换\") InitialPermutationResult = Permutation(M_0, InitialPermutationTable) L_0 = InitialPermutationResult[0:int((len(InitialPermutationResult)/2))] R_0 = InitialPermutationResult[int((len(InitialPermutationResult)/2)):int(len(InitialPermutationResult))] return L_0, R_0 # List type###################################################################################################PC-1置换#########################################################################################PC_1Table = [57,49,41,33,25,17,9, 1,58,50,42,34,26,18, 10,2,59,51,43,35,27, 19,11,3,60,52,44,36, 63,55,47,39,31,23,15, 7,62,54,46,38,30,22, 14,6,61,53,45,37,29, 21,13,5,28,20,12,4]\"\"\" function: PC-1 permutation input: 56 not checked bits of secret ley return: C_0, D_0 \"\"\"def PC_1_Permutation(SecretKey): if PRINT_FLAG == True: print(\"&gt; 进行PC-1 置换\") PC_1_PermutationResult = Permutation(SecretKey, PC_1Table) C_0 = PC_1_PermutationResult[0: int(len(PC_1_PermutationResult)/2)] D_0 = PC_1_PermutationResult[int(len(PC_1_PermutationResult)/2): int(len(PC_1_PermutationResult))] return C_0, D_0######################################################################################################循环左移函数######################################################################################\"\"\" function: do ring shift left on a str_28_bits input: str_28_bits -- a 28 bits string; ShiftFlag -- when it is 1,2,9,16, shift 2 bits return: shift_result\"\"\"def RingShiftLeft(str_28_bits, ShiftFlag): shiftResult = \"\" if ShiftFlag == 1 or ShiftFlag == 2 or ShiftFlag == 9 or ShiftFlag == 16: shiftResult = shiftLeft(str_28_bits, 2) else: shiftResult = shiftLeft(str_28_bits, 1) return shiftResult########################################################################################################PC-2置换####################################################################################PC_2Table = [14,17,11,24,1,5, 3,28,15,6,21,10, 23,19,12,4,26,8, 16,7,27,20,13,2, 41,52,31,37,47,55, 30,40,51,45,33,48, 44,49,39,56,34,53, 46,42,50,36,29,32]\"\"\" function: PC-2 compressed permutation input: str_56_bits return: str_48_bits\"\"\"def PC_2_Permutation(str_56_bits): if PRINT_FLAG == True: print(\"&gt; 进行PC-2置换\") # 去掉9， 18， 22， 25， 35， 38，43， 54 位 str_48_bits = Permutation(str_56_bits, PC_2Table) return str_48_bits##################################################################################################创建子密钥##################################################################################\"\"\" function: create the 16 son keys with the given key return: sonKeysList: 16 son keys list\"\"\"def createSonKey(SecretKey): # 提取密钥中的非校验位 if PRINT_FLAG == True: print(\"&gt; 正在生成16个子密钥\") str_56_bits_List = list(SecretKey) sonKeyList = [] # 获取子密钥 Temp_PC_1_PermutationResult_C_i_1, Temp_PC_1_PermutationResult_D_i_1 = PC_1_Permutation(str_56_bits_List) C_i = [] D_i = [] for i in range(1, 17): # C_i-1 D_i-1 # 计算C_i D_i if i == 1 or i == 2 or i == 9 or i == 16: C_i = shiftLeft(Temp_PC_1_PermutationResult_C_i_1, 1) D_i = shiftLeft(Temp_PC_1_PermutationResult_D_i_1, 1) else: C_i = shiftLeft(Temp_PC_1_PermutationResult_C_i_1, 2) D_i = shiftLeft(Temp_PC_1_PermutationResult_D_i_1, 2) CD = C_i + D_i sonKey_i = PC_2_Permutation(CD) sonKeyList.append(sonKey_i) Temp_PC_1_PermutationResult_C_i_1 = C_i Temp_PC_1_PermutationResult_D_i_1 = D_i if i == 16: break return sonKeyList####################################################################################################E扩展置换#################################################################################E_ExpandTable = [32,1,2,3,4,5, 4,5,6,7,8,9, 8,9,10,11,12,13, 12,13,14,15,16,17, 16,17,18,19,20,21, 20,21,22,23,24,25, 24,25,26,27,28,29, 28,29,30,31,32,1]\"\"\" function: E_Expand on the 32 bits R(i-1) string input: R_i_1 -- the (i-1)th back 32 bits string return: E_R_i_1 -- the 48 bits expanded string\"\"\"def E_Expand(R_i_1): if PRINT_FLAG == True: print(\"&gt; 正在进行E扩展置换\") E_R_i_1 = Permutation(R_i_1, E_ExpandTable) return E_R_i_1#####################################################################################################S盒置换################################################################################eight_S_Boxes=[[14,4,13,1,2,15,11,8,3,10,6,12,5,9,0,7, 0,15,7,4,14,2,13,1,10,6,12,11,9,5,3,8, 4,1,14,8,13,6,2,11,15,12,9,7,3,10,5,0, 15,12,8,2,4,9,1,7,5,11,3,14,10,0,6,13,], [15,1,8,14,6,11,3,4,9,7,2,13,12,0,5,10, 3,13,4,7,15,2,8,14,12,0,1,10,6,9,11,5, 0,14,7,11,10,4,13,1,5,8,12,6,9,3,2,15, 13,8,10,1,3,15,4,2,11,6,7,12,10,5,14,9,], [10,0,9,14,6,3,15,5,1,13,12,7,11,4,2,8, 13,7,0,9,3,4,6,10,2,8,5,14,12,11,15,1, 13,6,4,9,8,15,3,0,11,1,2,12,5,10,14,7, 1,10,13,0,6,9,8,7,4,15,14,3,11,5,2,12], [7,13,14,3,0,6,9,10,1,2,8,5,11,12,4,15, 13,8,11,5,6,15,0,3,4,7,2,12,1,10,14,9, 10,6,9,0,12,11,7,13,15,1,3,14,5,2,8,4, 3,15,0,6,10,1,13,8,9,4,5,11,12,7,2,14,], [2,12,4,1,7,10,11,6,8,5,3,15,13,0,14,9, 14,11,2,12,4,7,13,1,5,0,15,10,3,9,8,6, 4,2,1,11,10,13,7,8,15,9,12,5,6,3,0,14, 11,8,12,7,1,14,2,13,6,15,0,9,10,4,5,3], [12,1,10,15,9,2,6,8,0,13,3,4,14,7,5,11, 10,15,4,2,7,12,9,5,6,1,13,14,0,11,3,8, 9,14,15,5,2,8,12,3,7,0,4,10,1,13,11,6, 4,3,2,12,9,5,15,10,11,14,1,7,6,0,8,13,], [4,11,2,14,15,0,8,13,3,12,9,7,5,10,6,1, 13,0,11,7,4,9,1,10,14,3,5,12,2,15,8,6, 1,4,11,13,12,3,7,14,10,15,6,8,0,5,9,2, 6,11,13,8,1,4,10,7,9,5,0,15,14,2,3,12], [13,2,8,4,6,15,11,1,10,9,3,14,5,0,12,7, 1,15,13,8,10,3,7,4,12,5,6,11,0,14,9,2, 7,11,4,1,9,12,14,2,0,6,10,13,15,3,5,8, 2,1,14,7,4,10,8,13,15,12,9,0,3,5,6,11]]\"\"\" function: to transfrom a 6-bits string to a 4-bits string with 8 S-Boxes input: six_bits_str -- 6-bits string; S_Box_Num -- indicate the number of the S-Box [1, 8] return: four_bits_str -- 4 bits string group\"\"\"def S_Box_Transformation(six_bits_str, S_Box_Num): if PRINT_FLAG == True: print(\"&gt; 正在通过S盒进行6-4转换\") row = int(six_bits_str[0]) * 2 + int(six_bits_str[5]) col = int(six_bits_str[1]) * 8 + int(six_bits_str[2]) * 4 + int(six_bits_str[3]) * 2 + int(six_bits_str[4]) value = eight_S_Boxes[int(S_Box_Num - 1)][int(row * 15 + col)] four_bits_str = list(int2bin(value,4)) return four_bits_str######################################################################################################P扩展置换##############################################################################P_Table=[16,7,20,21, 29,12,28,17, 1,15,23,26, 5,18,31,10, 2,8,24,14, 32,27,3,9, 19,13,30,6, 22,11,4,25]\"\"\" function: P_Permutation on the 32 bits string input: str_32bits -- the 32 bits string List return: FeistelResult -- the output of the feistel function\"\"\"def P_Permutation(str_32bits): if PRINT_FLAG == True: print(\"&gt; 正在进行P置换\") FeistelResult = Permutation(str_32bits, P_Table) return FeistelResult###################################################################################################Feistel 函数#########################################################################################\"\"\" function: Feistel function to create bit-stR_ing to permute with R_i -- a 32-bit stR_ing input: R_i_1--the (i-1)th back 32 bits string, K_i--the son secret key return: Feistel result (string type)\"\"\"def Feistel(R_i_1, K_i): if PRINT_FLAG == True: print(\"&gt; 正在执行feistel轮函数\") E_ExpandResult = E_Expand(R_i_1) xorResult = XOROperation(E_ExpandResult, K_i) str_32_bits = [] for i in range(8): str_6_bits = xorResult[i * 6: i * 6 + 6] str_32_bits += S_Box_Transformation(str_6_bits, i + 1) return \"\".join(P_Permutation(str_32_bits))#######################################################################################################加密过程的的交叉迭代过程#####################################################################################\"\"\" function: make cross iteration on L0, R0 for 16 times input: L0--the front 32 bits of 64-bits plain text , R0--the back 32 bits of plain text return: R16--the back iterated 32-bits result, L16--the front iterated 32-bits result \"\"\"def CrossIterationInEncryption(L_0, R_0, SecretKey): if PRINT_FLAG == True: print(\"&gt; 正在进行加密过程的交叉迭代\") R = \"\" L = \"\" tmp_R = R_0 tmp_L = L_0 sonKeyList = createSonKey(SecretKey) for i in range(1,17): L = tmp_R R = XOROperation(tmp_L,Feistel(tmp_R,sonKeyList[i - 1])) tmp_R = R tmp_L = L RL = R + L return RL #######################################################################################################解密过程的的交叉迭代过程#####################################################################################\"\"\" function: make cross iteration on L0, R0 for 16 times input: L0--the front 32 bits of 64-bits cipher text , R0--the back 32 bits of cipher text return: R16--the back iterated 32-bits result, L16--the front iterated 32-bits result \"\"\"def CrossIterationInDecryption(L_0, R_0, SecretKey): if PRINT_FLAG == True: print(\"&gt; 正在进行解密过程的交叉迭代\") R = [] L = [] tmp_R = R_0 tmp_L = L_0 sonKeyList = createSonKey(SecretKey) for i in range(1,17): L = tmp_R R = XOROperation(tmp_L,Feistel(tmp_R,sonKeyList[16 - i])) tmp_R = R tmp_L = L RL = R + L return RL ####################################################################################################P 逆置换########################################################################################InversePermutationTable=[40,8,48,16,56,24,64,32, 39,7,47,15,55,23,63,31, 38,6,46,14,54,22,62,30, 37,5,45,13,53,21,61,29, 36,4,44,12,52,20,60,28, 35,3,43,11,51,19,59,27, 34,2,42,10,50,18,58,26, 33,1,41,9,49,17,57,25]\"\"\" function: inverse permutation on the R16L16 bit-stR_ing input: R16--the back iterated 32-bits result, L16--the front iterated 32-bits result return: ciphterText--64bits\"\"\"def InversePermutation(R_16_L_16): if PRINT_FLAG == True: print(\"&gt; 正在进行逆置换\") cipherText = \"\" cipherText = Permutation(R_16_L_16, InversePermutationTable) return cipherText ###################################################################################################加密总函数#########################################################################################def Encryption(plainText, secretKey): if PRINT_FLAG == True: print(\"&gt; 开始加密64位明文\") M = list(plainText) L0, R0 = InitialPermutation(M) RL = CrossIterationInEncryption(L0, R0, secretKey) cipherText = \"\".join(InversePermutation(RL)) return cipherText####################################################################################################解密总函数###############################################################################def Decryption(cipherText, secretKey): if PRINT_FLAG == True: print(\"&gt; 开始解密64位密文\") M = list(cipherText) L0, R0 = InitialPermutation(M) RL = CrossIterationInDecryption(L0, R0, secretKey) decryptedText = \"\".join(InversePermutation(RL)) return decryptedText##################################################################################################随机生成64位key，8个字符#####################################################################\"\"\" return: a 64-bits (8 bytes) string as a secret key\"\"\"def createSecrteKey(): seed = \"1234567890abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!@#$%^&amp;*()_+=-\" key = [] for i in range(8): key.append(random.choice(seed)) randomSecretKey = ''.join(key) return randomSecretKey##########################################################################################################8个字符的字符串转为ascii，然后转 0 1串####################################def ToBitString(string_8_char): strList = [] for i in range(8): strList.append(str(int2bin(ord(string_8_char[i]), 8))) return \"\".join(strList)##########################################################################################64位bits转为8个ascci字符###################################################def ToAsciiChar(string_64_bits): strList = [] bitList = list(string_64_bits) for i in range(8): if int(\"\".join(bitList[i * 8: i * 8 + 8]), 2) &lt; 8: continue # 八个bit一个处理单元，先转为10进制，然后转ascii，存入列表 strList.append(chr(int(\"\".join(bitList[i * 8: i * 8 + 8]), 2))) #print(\"ASCII:\" + str(strList)) return \"\".join(strList)##################################################################################if __name__ == \"__main__\": \"\"\" print(\"执行DES加密算法\") M=\"0000000100100011010001010110011110001001101010111100110111101111\"#测试的明文 K=\"0001001100110100010101110111100110011011101111001101111111110001\"#密钥 print(\"明文是\" + M) print(\"加密后:\" + Encryption(M, K)) print(\"解密后\" + Decryption(Encryption(M,K), K)) \"\"\" print(\"【DES程序说明】\") print(\"1. 明文文件默认为同目录下的plainText.txt，如需加密其他文件，请修改16到20行代码的文件变量。\" ) print(\"2. 密钥是随机生成的，保存在同目录的secretKey.txt文件中\") print(\"3. 如果要显示加密和解密过程，可修改23行代码的打印变量，置为True\") print(\"---------------------------------------------------------------------\") continueSign = input(\"请按任意键执行加密和解密过程。。。\") print(\"随机生成密钥中...\") secretKey = createSecrteKey() with open(SECRET_KEY_FILE, 'w') as sf: sf.write(secretKey) print(\"密钥已写入文件\" + SECRET_KEY_FILE + \"!\") secretKeyBitString = ToBitString(secretKey) print(\"得到密钥的 0 1字符串！\") full_flag = True # 分组为8的倍数的标志，为8则真 PlainTextFile = open(PLAIN_TEXT_FILE, 'r') CipherTextFile = open(CIPHER_TEXT_FILE, 'w') DecryptTextFile = open(DECRYPT_TEXT_FILE, 'w') while True: text_8_bytes = PlainTextFile.read(8) if not text_8_bytes: print(\"读取明文文件到结尾啦\") break if len(text_8_bytes) != 8: full_flag = False else: bitString = ToBitString(text_8_bytes) # 加密 encryptStr = Encryption(bitString, secretKeyBitString) # 加密结果写入文件 CipherTextFile.write(str(ToAsciiChar(encryptStr))) # 解密 decryptStr = Decryption(encryptStr, secretKeyBitString) # 解密结果写入文件 DecryptTextFile.write(str(ToAsciiChar(decryptStr))) if full_flag == False: NumOfLostBytes = 8 - len(text_8_bytes) bitStringList = [] for i in range(len(text_8_bytes)): bitStringList.append(int2bin(ord(text_8_bytes[i]), 8)) full_8_bits = int2bin(NumOfLostBytes, 8) # 填充的比特串 # 填充的字节数 转为bitstring for i in range(NumOfLostBytes): bitStringList.append(full_8_bits) bitString = \"\".join(bitStringList) #补全64位分组 # 加密 encryptStr = Encryption(bitString, secretKeyBitString) # 加密结果写入文件 CipherTextFile.write(str(ToAsciiChar(encryptStr))) # 解密 decryptStr = Decryption(encryptStr, secretKeyBitString) # 解密结果写入文件 DecryptTextFile.write(str(ToAsciiChar(decryptStr))) # 读取完整的8个字节分组字节，尾部填充8个字节，取值都为08 if full_flag == True: zero_eight = \"00001000\" tmpList = [] for i in range(8): tmpList.append(zero_eight) bitString = \"\".join(tmpList) # 加密 encryptStr = Encryption(bitString, secretKeyBitString) # 加密结果写入文件 CipherTextFile.write(str(ToAsciiChar(encryptStr))) # 解密 decryptStr = Decryption(encryptStr, secretKeyBitString) # 解密结果写入文件 DecryptTextFile.write(str(ToAsciiChar(decryptStr))) print(\"加密成功！\") print(\"解密成功！\") PlainTextFile.close() CipherTextFile.close() DecryptTextFile.close() with open(PLAIN_TEXT_FILE, 'r') as pf: data = pf.read() print(\"明文为：\") print(data) with open(CIPHER_TEXT_FILE, 'r') as cf: data = cf.read() print(\"加密结果为：\") print(data) with open(DECRYPT_TEXT_FILE, 'r') as df: data = df.read() print(\"解密结果为：\") print(data) 四、总结本次DES算法实践有点崎岖，主要问题在于对整个算法的熟悉以及一些细节的问题处理如ascii字符和01互换，以及在置换过程中出现的溢出问题。debug相对比较困难，因为函数的输出结果经过各种置换后，已经很难分辨是真是假，哪一步出错，只有对算法流程足够熟悉才可以顺利的完成这个实验！","tags":[{"name":"信息安全","slug":"信息安全","permalink":"https://joshuaqyh.github.io/tags/信息安全/"},{"name":"加密技术","slug":"加密技术","permalink":"https://joshuaqyh.github.io/tags/加密技术/"},{"name":"Java","slug":"Java","permalink":"https://joshuaqyh.github.io/tags/Java/"}]},{"title":"基于时间的概率推理","date":"2018-11-26T14:44:12.876Z","path":"2018/11/26/ch15 时间上的概率推理/","text":"马尔可夫过程当前状态依赖于前一个状态，单阶的马尔可夫链； 当前状态依赖于前n个状态，n阶的马尔可夫链； 传感器模型 传感器马尔可夫假设： $$P(E_t | X_{0:t}, E_{0:t-1}) = P(E_t | X_t)$$ 等式右边就是我们的传感器模型。 有$X_t$ 就可感应得到$E_t$。 物理含义就是当前的证据只与当前状态有关，即便给定了过去所有状态和证据。 状态转移模型 $$P(X_i | X_{i-1}) = P(X_t | X_{0:t-1})$$ 物理含义就是给定前一个状态，计算当前状态的概率相当于给定所有状态时计算当前状态的概率 。给定前一个状态和给定过去所有状态的结果是一样的。 有了上述两个模型之后，加上初始状态模型$P(X_0)$, 我们就可以确定所有变量上完整的联合概率分布，从而确定其他类型的概率分布。 公式如下： $$P(X_{0:t}, E_{1:t}) = P(X_0) \\prod_{i=1}^tP(X_i | X_{i-1})P(E_i | X_i)$$ 形式化基本推理任务 滤波。计算信念状态。给定当前所有证据，计算当前状态的后验概率分布。 预测。给定当前所有证据，计算未来状态的后验分布。 平滑。给定当前所有证据，计算过去某一状态的后验概率。 最可能的解释。给定观察序列，找到最可能生成这些观察结果的状态序列。 学习。从观察中学习，推理哪些确实会发生转移，估计。期望最大化算法。EM算法。 ​ 滤波过程根据当前时刻已知的所有证据变量，计算当前状态的后验概率分布。 假设存在函数f使得 $P(X_{t+1} | e_{1:t+1}) = f(e_{t+1}, P(X_t | e_{1:t}))$,其物理含义就是已知t时刻的滤波结果$P(X_t | e_{1:t}) $和t+1时刻的证据$e_{t+1}$ ，可以计算下一个时刻t+1的滤波结果$P(X_t | e_{1:t}) $。该过程称为递归估计。 公式计算过程为： $P(X_{t+1} | e_{1: t+1}) = P(X_{t + 1} | e_{1: t}, e_{t+1})$ // 分解证据 ​ $= \\alpha P(e_{t+1} | X_{t+1}, e_{1:t})P(X_{t+1} | e_{1:t})$ // 使用贝叶斯规则 ​ $= \\alpha P(e_{t+1} | X_{t+1}) P(X_{t+1} | e_{1:t})$ // 根据传感器马尔科夫假设 ​ $=\\alpha P(e_{t+1} | X_{t+1}) \\sum_{x_t} P(X_{t+1}| x_t, e_{1:t})P(x_t | e_{1:t})$ // 分解为求和式 ​ $= \\alpha P(e_{t+1} | X_{t+1}) \\sum_{x_t} P(X_{t+1} | x_t)P(x_t | e_{1:t})$ // 马尔可夫假设 上述的求和表达式中，第一个因子来自转移模型，第二个因子来自当前状态分布。由此得到了递归公式 。我们可以认为滤波估计$P(e_t | X_t)$ 是沿着序列从1到t的前向”消息”：$f_{1:t}$ ，在每一时刻发生转移时得到修正，并根据每一新的观察进行更新，该过程表达为 $f_{1:t+1} = \\alpha Forward(f_{1:t}, e_{t+1})$ $Forward$函数实现了马尔可夫假设中的递归过程。 平滑过程给定现在已知的证据，计算过去某一状态的后验分布。 $$ 对于 0 \\le k &lt; t\\, 计算P(X_k | e_{1:t})$$ ，计算过程是: $P(X_k | e_{1:t}) = P (X_k | e_{1: k}, e_{k+1:t})$ // 分解证据 ​ $= \\alpha P(X_k | e_{1:k})P(e_{k+1:t}| X_k, e_{1:k}) $ // 使用贝叶斯规则 ​ $ = \\alpha P(X_k | e_{1:k}) P (e_{k+1:t} | X_k)$ // 使用条件独立性 ​ $ = \\alpha f_{1:k} × b_{k+1:t}$ 结果代表 $\\alpha *$ 前向消息 点乘 后向消息。 前向消息计算方法是通过从1到k的前向滤波过程，而后向消息的计算需要从时刻t到k+1进行反向递归。 $P(e_{k+1:t} | X_k) = \\sum_{x_{k+1}} P(e_{k+1:t} | X_k, x_{k+1})P(X_{k+1} | X_k)$ ​ $ = \\sum_{x_{k+1}} P (e_{k+1:t} | x_{k+1}) P (x_{k+1} | X_k)$ ​ $ = \\sum_{x_{k+1}}P(e_{k+1} | x_{k+1})P(e_{k+2:t} | x_{k+1})P(x_{k+1} | X_k)$ 隐马尔可夫模型HMM卡尔曼滤波器使用观测到的离散量来估计连续变量的规律，使用隐马尔可夫模型来建模。 使用合适的条件概率密度来表示转移模型和传感器模型； 使用线性高斯分布，意味着下一状态$X_{t+1}$必须是当前状态$X_t$ 的线性函数，并加上一个高斯噪声$\\sigma$。 $$X_{t+1} = \\alpha X_t + \\sigma$$ 提炼为线性高斯转移模型为： $$P(X_{t+ \\gamma} = x_{t+\\gamma}|X_t = x_t, X’_t = x’_t) = N (x_t + x’t \\gamma, \\sigma^2)(x{t+\\gamma})$$ 动态贝叶斯网络DBN每一个隐马尔可夫模型都可以表示为只有一个状态变量和一个证据变量的动态贝叶斯网络。","tags":[{"name":"人工智能","slug":"人工智能","permalink":"https://joshuaqyh.github.io/tags/人工智能/"},{"name":"马尔可夫场","slug":"马尔可夫场","permalink":"https://joshuaqyh.github.io/tags/马尔可夫场/"}]},{"title":"人工智能 |贝叶斯网络基础知识","date":"2018-11-26T12:01:22.786Z","path":"2018/11/26/ch 13不确定性的量化/","text":"1. 概率分布 先验概率等于无条件概率 $P(A)$ 后验概率等于条件概率 $P(A|B)​$ 联合概率分布是由$A ,B$不同取值得到的一个$P(A,B )$概率分布。 完全联合分布中的边缘概率，是指某一随机变量成立的无条件概率，根据联合分布概率表累加计算可以得到。求得边缘概率的过程称为边缘化或者是求和消元化。 $P(A) = \\sum_{z∈Z}P(A, z)$ 求和消元化的联合分布表示 $P(A) = \\sum_zP(A|z)P(z)$ 根据乘法法则$P(A,z) = P(A | z) P(z)$ 可以求得求和消元化的条件概率分布。该规则也称条件化。 归一化常数 $\\alpha$: $P(A |B) = \\alpha P(AB)$。将$\\alpha$替代$1 / P(B)$ 。 $P(X|e) = \\alpha P(X ,e) = \\alpha \\sum_yP(X,e,y)$ 。 2. 独立性存在独立性，可进行概率分解降低模型的复杂度。 ！条件独立的含义：事件A，B，C, 若在A概率未知的情况下，AB不独立，如果A概率已知，那么AB就存在条件独立的关系。 独立性的一个表现就是 $P(A | B) = P (A)$ ，当B与A无互相独立互不影响的时候。 其他表示: $ P(AB ) = P(A)P(B)$ 3. 贝叶斯$P(Y|X)P(X) = P(X|Y)P(Y) = P(XY)$ 从概率来看到原因的概率分布。 $ P(Y | X) = \\frac{P(X | Y)P(Y)}{P(X)}$ 如果某人是好人(概率为$P(Y)$), 某人偷东西的事件概率为($X$) ，如果发生了A偷东西$P(Y|X)$，那么A是好人的概率$P(Y | X)$。 放在实例中来观察贝叶斯公式的简单应用。在医疗诊断中，如果医生知道某一疾病发生某些症状的概率，那么可以利用贝叶斯公式估计得知当病人发生某症状时，推测病人发生某病的概率。 贝叶斯公式其实是反映了原因和结果之间的概率关系。 $ P(Cause | Effect) = \\frac{P(Effect | Cause)P(Cause)}{P(Effect)}= \\alpha P(Effect | Cause)P(Cause)$ 其中的 $P(Cause) P (Effect)$ 二者都属于先验概率, $\\alpha$ 是让 $P(Effect | Cause)$归一化的常数。 朴素贝叶斯 $P(Cause, Effect_1, Effect_2, Effect_3….Effect_n) = P(Cause) \\prod_n P(Effect_i | Cause)$","tags":[{"name":"人工智能","slug":"人工智能","permalink":"https://joshuaqyh.github.io/tags/人工智能/"},{"name":"贝叶斯网络","slug":"贝叶斯网络","permalink":"https://joshuaqyh.github.io/tags/贝叶斯网络/"}]},{"title":"markdown 数学公式表示大集合","date":"2018-10-22T05:47:02.506Z","path":"2018/10/22/markdown-数学公式表示大集合/","text":"MarkDown 插入数学公式实验大集合0. 前言 最近在学习一些机器学习相关的知识，想把自己学习的东西通过 MD 的形式在线记录下来，但是之前一直没有开始行动，因为里面的公式什么的感觉实在是麻烦。于是今天打算花点时间了解一下如何在 markdown 中插入数学公式，发现其实很简单，大概花一个小时左右就能知道如何编写了。 1. 基础认识 笔者认为所谓插入数学公式其实就是引入一种规则，然后通过模板？渲染成公式，不知道这个理解对不对，不对望指正。其实你以前可能就看到过有的博客本该出现公式的时候不显示，点击后会链接到一个 new tab 然后显示一张公式的图片，有时却出现一大堆的代码。这里就是通过这段代码解析成公式然后显示的。 这里我们选取 MathJax 引擎。 引入脚本，把下面代码插入 MD 文件里面，如果你怕这份在线文件源别人访问不到的话，可以把这个下下来自己做一个源，这样比较稳定缺点是要自己手动更新源。 12&lt;script type=&quot;text/javascript&quot; src=&quot;http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default&quot;&gt;&lt;/script&gt;复制代码 好了到这里就可以插入公式了，如果你懂 LaTeX 的话那看一两个例子就知道了，不懂也没关系，自己写一写代码就知道了，可以找一个可以预览 MD 的工具一直尝试。 1.1 插入方式 这里分两种，一种是行间插入，另一种是另取一行 1.1.1 行间插入12\\\\(a + b\\\\)复制代码 这里是行间插入公式 a + b : (a + b)，特点就是通过( 和 ) 包含公式，然后为了模板引擎能够区分该 ( 不是普通文本的 ( 而是公式的 (，通过 \\\\ 转义一下。这样应该就很好理解这个语法构成了。注意这里方式不唯一，这是笔者喜欢的方式，其他的使用方式自行搜索。下面的介绍同样是这样。 PS: 这里掘金使用的是 $a + b$ : a + b ，如果对您的阅读产生印象，请看最后说明，这里就不做一一更改了。谢谢。 1.1.2 另取一行12$$a + b$$复制代码 这里是另取一行 a + b 特点就是通过$$包含公式。 笔者认为第二种方式更好，以下没看 JS 源码纯属猜测：行间的需要考虑到当前行的行高并对公式进行处理，而另取一行就更简单一些，可能解析起来更快。最最最最最最主要是看起来漂亮 ^_^ 不太要考虑空间不够换行。 1.2 基本类型的插入 这里对 @houkai ：LATEX数学公式基本语法 的思路稍加修改，然后进行介绍。 1.2.1 上、下标先看结果再总结语法吧。 123456789101112$$x_1$$$$x_1^2$$$$x^2_1$$$$x_&#123;22&#125;^&#123;(n)&#125;$$$$&#123;&#125;^*x^*$$$$x_&#123;balabala&#125;^&#123;bala&#125;$$复制代码 x_1 x_1^2 x^2_1 x_{22}^{(n)} {}^*x^* x_{balabala}^{bala} 可以看到 x 元素的上标通过 ^ 符号后接的内容体现，下表通过 _ 符号后接的内容体现，多于一位是要加 {} 包裹的。 笔者习惯先下标后上标的写法，和我的书写习惯一致：x_{balabala}^{bala}，不管你使用哪一种风格，最好自己注意统一，不要混用。 1.2.2 分式1234$$\\frac&#123;x+y&#125;&#123;2&#125;$$$$\\frac&#123;1&#125;&#123;1+\\frac&#123;1&#125;&#123;2&#125;&#125;$$复制代码 frac{x+y}{2} frac{1}{1+frac{1}{2}} 这里就出现了一个 frac{}{} 函数的东西，同样，为了区分这是函数不是几个字母，通过 \\frac转义，于是 frac 被解析成函数，然后第一个 {} 里面的被解析成分子，第二个 {} 被解析成分母。这里可以试试分数的行间解析 frac{1}{1+frac{1}{2}} 。我要看行间填充效果我要看行间填充效果我要看行间填充效果我要看行间填充效果我要看行间填充效果我要看行间填充效果我要看行间填充效果我要看行间填充效果我要看行间填充效果我要看行间填充效果我要看行间填充效果我要看行间填充效果。 1.2.3 根式123456$$\\sqrt&#123;2&#125;&lt;\\sqrt[3]&#123;3&#125;$$$$\\sqrt&#123;1+\\sqrt[p]&#123;1+a^2&#125;&#125;$$$$\\sqrt&#123;1+\\sqrt[^p\\!]&#123;1+a^2&#125;&#125;$$复制代码 sqrt{2} y=begin{cases}-x,quad xleq 0 \\\\x,quad x>0end{cases} 里面用到了 (\\leq) 符号，下一章会介绍常用数学符号。 2.2 数组的其他使用2.2.1 划线12345678$$\\left(\\begin&#123;array&#125;&#123;|c|c|&#125;1 &amp; 2 \\\\\\\\\\\\hline3 &amp; 4\\end&#123;array&#125;\\right)$$复制代码 left( begin{array}{|c|c|}1 & ldots \\\\hlinevdots & ddots end{array} ight) 2.2.2 制表12345678910$$\\begin&#123;array&#125;&#123;|c|c|&#125;\\hline&#123;1111111111&#125; &amp; 2 \\\\\\\\\\hline3 &amp; 4 \\\\\\\\\\hline\\end&#123;array&#125;$$复制代码 begin{array}{|c|c|}hline{1111111111} & 2 \\\\hline{balabala} & 你好啊 \\\\hlineend{array} 可以看到，其实其他很多东西都可以很灵活的表达出来。碰到其他有趣的我会继续写出来的。 3. 常用数学符号 这里提供一个文档下载，如果上面的链接失效，也可以到我的 GitHub 下载 pdf 版。下面举几个例子。 3.1 希腊字母12345678910111213141516171819202122232425262728$$\\begin&#123;array&#125;&#123;|c|c|c|c|c|c|c|c|&#125;\\hline&#123;\\alpha&#125; &amp; &#123;\\backslash alpha&#125; &amp; &#123;\\theta&#125; &amp; &#123;\\backslash theta&#125; &amp; &#123;o&#125; &amp; &#123;o&#125; &amp; &#123;\\upsilon&#125; &amp; &#123;\\backslash upsilon&#125; \\\\\\\\\\hline&#123;\\beta&#125; &amp; &#123;\\backslash beta&#125; &amp; &#123;\\vartheta&#125; &amp; &#123;\\backslash vartheta&#125; &amp; &#123;\\pi&#125; &amp; &#123;\\backslash pi&#125; &amp; &#123;\\phi&#125; &amp; &#123;\\backslash phi&#125; \\\\\\\\\\hline&#123;\\gamma&#125; &amp; &#123;\\backslash gamma&#125; &amp; &#123;\\iota&#125; &amp; &#123;\\backslash iota&#125; &amp; &#123;\\varpi&#125; &amp; &#123;\\backslash varpi&#125; &amp; &#123;\\varphi&#125; &amp; &#123;\\backslash varphi&#125; \\\\\\\\\\hline&#123;\\delta&#125; &amp; &#123;\\backslash delta&#125; &amp; &#123;\\kappa&#125; &amp; &#123;\\backslash kappa&#125; &amp; &#123;\\rho&#125; &amp; &#123;\\backslash rho&#125; &amp; &#123;\\chi&#125; &amp; &#123;\\backslash chi&#125; \\\\\\\\\\hline&#123;\\epsilon&#125; &amp; &#123;\\backslash epsilon&#125; &amp; &#123;\\lambda&#125; &amp; &#123;\\backslash lambda&#125; &amp; &#123;\\varrho&#125; &amp; &#123;\\backslash varrho&#125; &amp; &#123;\\psi&#125; &amp; &#123;\\backslash psi&#125; \\\\\\\\\\hline&#123;\\varepsilon&#125; &amp; &#123;\\backslash varepsilon&#125; &amp; &#123;\\mu&#125; &amp; &#123;\\backslash mu&#125; &amp; &#123;\\sigma&#125; &amp; &#123;\\backslash sigma&#125; &amp; &#123;\\omega&#125; &amp; &#123;\\backslash omega&#125; \\\\\\\\\\hline&#123;\\zeta&#125; &amp; &#123;\\backslash zeta&#125; &amp; &#123;\\nu&#125; &amp; &#123;\\backslash nu&#125; &amp; &#123;\\varsigma&#125; &amp; &#123;\\backslash varsigma&#125; &amp; &#123;&#125; &amp; &#123;&#125; \\\\\\\\\\hline&#123;\\eta&#125; &amp; &#123;\\backslash eta&#125; &amp; &#123;\\xi&#125; &amp; &#123;\\backslash xi&#125; &amp; &#123;\\tau&#125; &amp; &#123;\\backslash tau&#125; &amp; &#123;&#125; &amp; &#123;&#125; \\\\\\\\\\hline&#123;\\Gamma&#125; &amp; &#123;\\backslash Gamma&#125; &amp; &#123;\\Lambda&#125; &amp; &#123;\\backslash Lambda&#125; &amp; &#123;\\Sigma&#125; &amp; &#123;\\backslash Sigma&#125; &amp; &#123;\\Psi&#125; &amp; &#123;\\backslash Psi&#125; \\\\\\\\\\hline&#123;\\Delta&#125; &amp; &#123;\\backslash Delta&#125; &amp; &#123;\\Xi&#125; &amp; &#123;\\backslash Xi&#125; &amp; &#123;\\Upsilon&#125; &amp; &#123;\\backslash Upsilon&#125; &amp; &#123;\\Omega&#125; &amp; &#123;\\backslash Omega&#125; \\\\\\\\\\hline&#123;\\Omega&#125; &amp; &#123;\\backslash Omega&#125; &amp; &#123;\\Pi&#125; &amp; &#123;\\backslash Pi&#125; &amp; &#123;\\Phi&#125; &amp; &#123;\\backslash Phi&#125; &amp; &#123;&#125; &amp; &#123;&#125; \\\\\\\\\\hline\\end&#123;array&#125;$$复制代码 begin{array}{|c|c|c|c|c|c|c|c|}hline{alpha} & {backslash alpha} & { heta} & {backslash theta} & {o} & {o} & {upsilon} & {backslash upsilon} \\\\hline{beta} & {backslash beta} & {vartheta} & {backslash vartheta} & {pi} & {backslash pi} & {phi} & {backslash phi} \\\\hline{gamma} & {backslash gamma} & {iota} & {backslash iota} & {varpi} & {backslash varpi} & {varphi} & {backslash varphi} \\\\hline{delta} & {backslash delta} & {kappa} & {backslash kappa} & { ho} & {backslash rho} & {chi} & {backslash chi} \\\\hline{epsilon} & {backslash epsilon} & {lambda} & {backslash lambda} & {varrho} & {backslash varrho} & {psi} & {backslash psi} \\\\hline{varepsilon} & {backslash varepsilon} & {mu} & {backslash mu} & {sigma} & {backslash sigma} & {omega} & {backslash omega} \\\\hline{zeta} & {backslash zeta} & { u} & {backslash nu} & {varsigma} & {backslash varsigma} & {} & {} \\\\hline{eta} & {backslash eta} & {xi} & {backslash xi} & { au} & {backslash tau} & {} & {} \\\\hline{Gamma} & {backslash Gamma} & {Lambda} & {backslash Lambda} & {Sigma} & {backslash Sigma} & {Psi} & {backslash Psi} \\\\hline{Delta} & {backslash Delta} & {Xi} & {backslash Xi} & {Upsilon} & {backslash Upsilon} & {Omega} & {backslash Omega} \\\\hline{Omega} & {backslash Omega} & {Pi} & {backslash Pi} & {Phi} & {backslash Phi} & {} & {} \\\\hlineend{array} 写太累了😂😂😂。。。其他的详见 PDF。 4. 总结 通过这样梳理一下基本的公式都能插入了，而且也会如何查资料。对于自己日后学习 LaTeX 写论文有很大帮助。以下建议带有很强的主观性，仅供参考。 公式一律使用另取一行，并且上下都空一行 一个公式一个语句，不要写在一个 $$***$$ 里，保证独立性，一个公式错误不影响另一个公式。 风格统一，不要混用。比如上下标的写法：x_{balabala}^{bala} 行间字母可以使用 \\\\(a\\\\) 代替 a ，养成自己的写作风格。 最后：我的 Blog 和 GitHub，感谢阅读。 5. 参考资料 十分感谢以下作者的无私分享。 Markdown中插入数学公式的方法 LATEX数学公式基本语法 一份其实很短的 LaTeX 入门文档 说明：掘金好像有些转义不出来，如果想看效果可以参考这篇自己多试试。","tags":[{"name":"markdown","slug":"markdown","permalink":"https://joshuaqyh.github.io/tags/markdown/"}]},{"title":"区块链挑战，应用和发展","date":"2018-10-21T01:57:20.688Z","path":"2018/10/21/初探区块链的挑战，应用和发展/","text":"一、 引言​ 区块链技术被认为是继互联网、人工智能以后又一大颠覆式的技术创新，其内在的发展潜力被无数人所追求。以区块链技术为原理的比特币等加密数字货币的兴起，让区块链技术得以走向公众的视线。提及区块链，我们往往会联想到其特性，分布式，可溯源，去中心化，不可篡改，安全匿名，公开透明等等。区块链凭借这些前所未有的技术优势获得了政府，学术界，企业们的青睐和高度的重视。近年来，无论是科技巨头还是中小的初创公司，都在积极的布局着区块链，关于区块链的的技术创新和模式创新不断涌现。但对于区块链这一新型事物，各行各业都处在摸石头过河的阶段，探索着区块链有效的应用场景。 ​ 关于如何看待区块链，公众的看法不一。有人一直唱衰，称其为泡沫；有人坚持信念，在区块链的浪潮中砥砺前行，期待区块链价值的焕发，试图成为社会变革的先驱者。区块链发展的主流观点是：区块链将是一种实现信息互联网到价值互联网转变的跨越式技术，一定程度上能够节约生产成本，提高生产效率，并有望成为未来的核心基础设施，推动社会方方面面的变革和进步，包括金融，经济贸易，社会管理，公共服务等等。区块链创造性地去除了许多系统应用的约束，为很多想法的实现提供了新的可能。以比特币为代表的加密数字货币，改变了传统的金融业交易模式；火热的以太坊智能合约，结合日渐发达的物联网，让我们看到了智能合约型社会在未来的可能。 ​ 从技术的角度来看，区块链就是一个结合P2P协议和加密技术分布式的公共账本，网络上的每一个节点都有可能在账本上添加记录，但决定记账权的方法是通过多种的共识算法如PoW, PoS来实现的。记账就是把数据打包成一个区块添加到一条最长的区块链上，该区块上的数据可追溯可验证。区块链的分布式存储决定了其去中心化，公开透明，信息共享；基于安全的哈希算法和共识算法，使其具备了不可篡改的特性；非对称加密技术让参与主体安全匿名，隐私得到保护；而时间戳技术让区块链上的数据可追溯可审核。 ​ 从社会科学的角度来看，区块链就是一个通过算法来制造信任和定义信用的机器，在任何需要信任的领域，都有区块链的用武之地。我们知道，在中心化的结构体系中，各方参与者只需要服从中心确立好的共识即可，共识的达成将是十分高效的，而对于分布式，各自取其益的情况下，达成共识则非常难。共识机制的建立，使去中心化的区块链记账系统成为了现实。总的来说，区块链创造了一个数字化的，有效地传输价值的信用系统。 ​ 区块链技术将有助于实现软件定义的社会系统，是下一代云计算的雏形，有望像互联网一般彻底重塑人类活动形态，并实现从目前的信息互联网向价值互联网的转变。目前整体发展态势虽没有17年比特币大火时那样的激进，围绕币市的各种业务正感受着区块链“泡沫”破灭的寒冬，以往那种投机主义者的空气币，割韭菜的喧嚣正逐渐退去，区块链的真正发展和价值落地才刚刚开始，泡沫破灭的过程恰似一个适者生存，劣者淘汰的过程，只有经过时间和现实情况检验过的优秀项目才能存活下来。 ​ 依托成熟的云计算技术体系，业界也出现了“区块链即服务（BaaS）”的平台，主要提供了联盟链及公有链这2种服务，包括IBM的Bluemix，微软的Bletchley，腾讯的TBaaS；与此同时，我国在《“十三五”国家信息化规划》中把区块链作为一项重点前沿的技术，明确提出需加强区块链等新技术的创新，试验和应用，以实现抢占新一代信息技术主导权。目前，我国区块链技术持续创新，区块链产业初步形成，开始在供应链金融、征信、产品溯源、版权交易、数字身份、电子证据等领域快速应用，有望推动我国经济体系实现技术变革，组织变革和效率变革，为构建现代化经济体系作出重要贡献。 二、区块链面临的挑战​ 开放，共享，去中心化是互联网的重要精神，而区块链则高度契合了这一精神。从时间跨度上看，区块链的诞生时间比较晚，具有极大的发展潜力和空间，而相关的行业发展经验和学术研究仍是不足的，更是决定了区块链技术在今后的发展中仍然还会面临极大的挑战。本文主要总结了以下几个较为明显和迫切的挑战： 技术层面仍有不足之处1.1安全性问题 ​ 我们知道在比特币的共识过程中，如果汇聚了超过51%的算力时，就有可能达成篡改区块链的数据。我们通常所说的区块链的数据不可篡改其实是相对而言的，因为共识过程需要消耗大量的算力，当篡改成本远远大于实际成本时，可以近似看作不可篡改，但这一威胁的存在并不能忽视，更为安全有效的共识机制有待更深入的研究和设计。 ​ 随着量子计算等新型计算技术的发展，区块链的密码学保护可能会变得越来越脆弱，非对称的加密技术有可能在今后得到破解，所以对加密技术的研究的进程仍要跟上，不能止步于前。 ​ 而区块链中的隐私匿名保护特性其实也存在着被追踪的可能性，有学者也提供了一种根据比特币交易事务进行时追踪用户IP地址的情况。随着各类反匿名身份甄别技术的发展, 加上区块链上的数据公开透明，实现部分重点目标的定位和标识也存在可能。如何加强匿名保护的技术，也是当前区块链研究的热点方向。 1.2效率问题 ​ 区块链的效率问题一直为人诟病，甚至有人宣称区块链技术存在天然瓶颈。交易效率慢，如比特币区块链每秒仅能处理7笔交易，这极大限制了区块链在商业世界的应用。还有有一种说法就是区块链实际就是一个造价昂贵的缓慢数据库，与其花大价钱来打造分布式的区块链数据库不如精心去维护好集中式的数据库。而且当数据区块越来越大的时候，因为分布式存储的原因，区块链数据将会变的臃肿庞大。 ​ 不过短时间内效率低并不是阻碍区块链的重要原因，对于共识机制效率如何改善相信会有好的进展。从另一个角度来讲，效率低也是安全的一种保证。可能我们在安全和效率之间需要一个良好的折衷方案吧。 监管问题 ​ 提及到监管问题，首先想到区块链的去中心化，接着是匿名性。去中心化意味着不受中心的掌控，匿名性意味着难以追踪参与者。从负面效果来看，去中心化是不受控制，放任自由，为所欲为；匿名则意味着包庇，躲避正义的追踪。 ​ 举个例子，一开始比特币流通的环境是在暗网，交易双方信息保密，只关注交易事务本身不关注交易双方。比特币的匿名性跟暗网的隐匿性有天然的契合度，利用比特币在暗网交易，走私，贩毒，洗钱等等难以追查，成了犯罪分子的天堂。 ​ 利用区块链来进行洗钱的途径也是存在的，尤其不能忽视发行代币的风险，要时刻警惕空气币，ICO的陷阱，防止其破坏金融市场的稳定，减少无良资本家割韭菜的局面。在监管层面必须做到对虚拟货币的发行，控制，管理，甚至禁止。在区块链发展的同时，相应的法律法规和政策也要跟上脚步。国家在发展布局区块链的时候，干预力度和引导的力度要如何拿捏才能更好地发挥区块链的社会价值呢，这是个值得挖掘的问题。 趋中心化问题 ​ 区块链自从走入公众视野就以去中心化的特点引起无数人的兴趣和追捧，这得益于分布式的共识机制，所谓人人都有记账权，人人都享有一份公共一致的账本，人人都有对账本上写入的记录的监督权。但是现有的共识机制，依旧有中心化的趋势，真正的去中心化可能渐渐消失。 ​ 以比特币的PoW共识机制为例，挖矿的矿工如果集中到一起，形成一个足够大的矿池，获得记账权的概率就更大，去中心化可能会演变成中心化，记账权掌握在少数人手里。PoW就是比拼谁的算力大，谁的算力越大获得的比特币奖励就越多，这个过程跟买彩票一样，越有钱的人买的彩票越多，中奖几率越大，而事实是越有钱的人会购买算力更大性能更优的矿机，挖到比特币的可能性更多发生在这些挖矿专业户手中。比特币的奖励集中到某些一小部分人的手上，比特币价格居高不下，财富就越是汇聚到这些人的手上。相似地，基于PoS的共识机制也会出现相同的问题，那些持有币数量越大，币龄越高的人越有可能获得记账权。这近乎是一种马太效应！弱中心化和重回中心化的威胁不容小觑！ ​ 或许完全去中心化的共识机制只是一个乌托邦式的幻想，就像人们曾经热衷于追求永动机一般，但这并不意味着人们要停止对区块链的探索，更为安全有效的共识机制仍要很长的一段时间去检验其有效性和正确性，去中心化未必能完美准确地达成，但近似地有效地达成去中心化的特性，将无疑带给社会一次前所未有的变革。 三、 区块链的多元化应用​ 区块链行业的应用非常多元，但实际落地条件可能还需要多次实践和配套基础设施的建立和完善。各国政府对待区块链的态度和政策也从很大程度上左右着区块链的发展方向和未来，区块链未来会是在哪些行业发光发彩。而在当前，各类与行业特点相结合的区块链项目如雨后春笋般涌现，预示着整个区块链产业的潜力。与“互联网+”类似，本文主要讨论几个当前较为大众所热议以及具有较为清晰发展前景的应用，以供了解。 金融 ​ 金融领域是与科技界联系较为紧密的领域，许多技术的创新都能很快被金融领域所嗅探到，并且得到很好的应用，所以在金融业也出现了“金融科技（FinTech）”等理念。诚然，金融领域几乎是天然与区块链系统契合的，金融领域的许多痛点仿佛在区块链的技术支撑下找到了良好的解决方案。传统金融的中心化，交易繁琐复杂，安全性有限都是亟需解决的痛点，“区块链+” 1.1 数字货币 ​ 最具代表性的数字货币当属比特币，同时也是目前世界影响最为广泛的一个应用。比特币可以安全方便地将数字资产转移给另外一个人，得以于这些特性，比特币很快就在交易相关的行业发展。比特币是一个工具，系统无法限制人们使用它的方式，比如一个较为灰色的例子，暗网上的“丝绸之路”网站就通过比特币定价并且进行交易，随后被美国FBI查封并且收缴了26000比特币，虽然数字货币存在被不法分子不正当利用的情形，但我们依旧能看到数字货币在市场上流通实验的成功实践。 ​ 不过数字货币去中心化的特点依旧对许多国家的货币机制产生了威胁，常常被认为是金融不稳定的因素。如何看待ICO，如何加强数字货币的监督管控，是每个国家都要面对和思考的问题。目前数字货币还没有在全世界的国家之间达成共识，如何制定有效的法律法规来引导数字货币的发展，数字币作为一个新生儿，仍然不断接收着世人的拷问。 1.2 供应链金融 ​ 供应链金融是银行将核心企业和上下游企业联系在一起提供灵活运用的金融产品和服务的一种融资模式。供应链金融参与方主要包括：核心企业，中小企业，金融机构和第三方支持服务。核心企业通常对上下游的供应商、经销商在定价、账期等方面要求苛刻，供应链中的中小企业常出现资金紧张、周转困难等情况，导致供应链效率大幅降低甚至停止运转。因此，供应链金融产业面临的核心问题是中小企业融资难，融资贵，成本高，周转效率低。供应链金融平台、核心企业系统交易本身的真实性难以验证，导致资金端风控成本居高不下。 ​ 区块链分布式记账以及共识机制，恰好建立了一套可信的信用体系，在数据验证和追溯上提供了有力的技术支撑，贯穿了金融供应链上下游的各方的信用。运用区块链技术，可以将核心企业的信用数字化，写入智能合约，依托智能合约来防范金融风险，使信用在供应链上有效传导，降低合作成本，提高生产效率。还可以使用智能合约来实现对供应链资金的拆分和流转，提高资金的周转效率，为中小企业解决融资难，融资贵的问题。 1.3 贸易金融 ​ 区块链就是一个用共识算法建立起来的具备信用的公共账本，开放共享的特性在贸易金融领域也有一番用武之地。传统银行之间存在着信息不对称以及交流不畅，信用鉴定繁琐的痛点，银行之间的业务报文的传递还大多依靠着国际组织Swift，EDI等等。利用区块链来建立银行之间的业务报文收发联盟的问题，简化业务流程，着手打造自己基于区块链系统的贸易金融平台，也就是通常讲的联盟链，已经成为一种新的发展思路。 ​ 往更开阔的角度来思考其应用，区块链多方可参与的特点有利于连接一切利益相关者，如区块链相关企业，政府部门一起来构建一个更完善，更自动化，更具信用价值的贸易金融生态。 1.4财务管理 ​ 区块链可审查，可追溯，不可篡改的特性也在财务管理方面有着出色的表现。在交易清算方面，区块链让多方共享一套可信互相认可的公共账本体系，所有的交易清算可实时的记录在区块链账本上，不可篡改，可追溯，大大提高了对账的准确率和效率。搭载智能合约之后，还能实现自动化的交易清结算，减少对账人员的成本和差错率。在审计方面，区块链能提高对企业财务信息的监督水平，虚假交易和账目造假难度大大提升。另外，通过区块链网络的实时性以及可审核性，审计效率也能大大提升，节约人力成本。而且区块链还能显著降低审计数据被攻击的风险，分布式的存储让审计数据的保护变得稳定可靠。 除了上述四点，区块链和金融场景的结合还有诸多的可能，电子信用凭证，跨境汇款查询应用，风险管理，企业改革等等，在未来将会有炫目的表现。 物联网 ​ 如今的物联网实现物物通信的方式是经由中心化的云服务器，该模式存在的弊端是当接入设备大幅增加时，服务器面临的负载将会越重，而在未来，上亿级的设备互联是必然的。到了那时云服务将会带来巨额成本，这是物联网发展的一个绊脚石。而且传统物联网数据容易受到攻击，具有诸多信息安全风险问题。区块链+物联网则通过多个节点参与验证，将全网达成交易的数据记录在分布式账本之中，取代中央服务器的作用，同时也能依赖区块链的非对称加密技术，共识机制，分布式存储降低数据丢失的风险。 ​ 在物联网中的电子商务行业，通过智能合约的方式实现交易的自动化，提供可靠性。去中心化的机制也能去除第三方的接入，让交易更为直接，有效率。 ​ 此外，物联网时代中的个人隐私安全更需要高度重视，人机交互，物物互联极大提高了暴露个人隐私数据的危险。利用非对称加密技术来对用户信息进行加密是一种有效的办法。 ​ 物流方面，结合智能硬件，区块链的可追溯性，实时性安全性也能得到充分发挥。在未来进一步发展的物联网社会，区块链将能不一样的智能体验。 医疗健康 ​ 区块链+医疗也是一个热门的场景。电子医疗数据的处理是当今区块链研究的一大热点，人们致力于如何将医疗数据安全共享。区块链作为一种多方维护，分布式存储，安全加密的记账技术，在解决医疗行业患者敏感信息共享与保护方面将会是一个很好的创新。借助区块链，我们可以搭建一个医疗信息区块链平台，实现多方数据共享，满足获取患者电子病历等历史数据，并将共享数据用于AI建模，图像检索，健康咨询等等。 社会公共服务和基础设施 ​ 新一代的社会公共服务，以及新型的基础设施建设，将会是当前区块链行业极为重要的机会，但这一发展道路还很漫长，公共服务和基础设施都需要发展到一定规模才能提供良好的服务。当前区块链发展仍在早期阶段，价值互联网的时代虽然呼之欲出，但实际普及的时间点还很难说。而加大基础设施的建设，提供更多的社会公共服务将会加大这一进程的步伐。 ​ 例如在产权登记版权注册方面，利用区块链技术来保障个体或集体的权益不受侵犯。在教育行业，将区块链和学生征信管理，升学就业，学术，资质证明等方面相结合，对教育就业的健康发展具有重要价值。在节约能源方面，区块链也有独特的创新之处，现有专家学者也建议通过发行能源币的方式来鼓励可再生资源的使用。 总体来说，区块链在很多行业和领域都能有独特的创造性应用，只要是和价值挂钩的信息以及需要建立可靠信用流通性强的场景，都和区块链有天然的亲和性，可以结合在一起发展除新的方式来满足不同行业的需求。我们必须明确，在多元的场景下，多元的区块链实现是有必要的，价值互联网的构建离不开多元场景需求的驱动。 四、 区块链的未来发展方向和趋势​ 区块链领域已经成为行业创新创业的热土，技术的不断攻坚和创新，将在社会层面上带来一场变革。本文将从技术层面和社会应用层面来简述对区块链未来的理解和看法。技术和社会层面是相互作用的两条发展主线，技术的创新开拓了社会应用的场景和空间，社会应用遇到的痛点和发展需求又是技术创新的一大动力。 技术层面 1.1 自身技术的迭代更新 区块链自身的机制仍有不足之处，如共识机制，效率问题，加密技术等等，都等待着专家学者，各行各业的技术人员进行优化改进。结合未来多样化的场景，区块链自身也存在着变革和重构的可能。在未来，单一的公有链，或者联盟链，私有链可能不能满足价值更为多元的传递。为方面数字资产在不同区块链之间的转移，开发安全有效的侧链技术，也是一个研究的热点。而且在加大区块链系统的吞吐量，提高效率方面，高性能的系统方案如分片技术，多通道技术仍在不断探索中。此外，随着区块链技术的发展，谋求一个统一的技术标准对整体发展局面和速度有着极大的作用，如同互联网发展初期基于TCP/IP等传输协议带给互联网信息通信的影响一样。当拟定一个权威标准之后，区块链产业才能有条不紊地前进。 1.2 与其他技术的融合创新 跳开自身技术的”瓶颈“，区块链技术和其他高新技术仍存在这融合创新的可能。在大数据方面，可以结合区块链来提升大数据管理和大数据分析的可靠性，分布式存储非对称加密技术提供数据安全和保障，而时间戳技术和不可篡改可以帮助准确的大数据分析，实现精准营销。在人工智能方面，智能硬件搭配智能合约将重塑契约模式，让智能合约更智能，加速价值互联网的到来，实现虚拟价值和实体价值的进一步转化。 社会经济层面 2.1 经济上实现”弯道超车“，打造”可信数字化“实体经济 区块链作为价值互联网的基础，引领着世界新一轮的技术创新和产业变革。由区块链引发的技术创新和模式创新与实体经济紧密深度的融合在一起，推动社会实体经济的发展，改变产业运作方式，简化业务流程，减少人力物力的同时提高生产效率。从底层架构的区块链到细分场景的应用，从国家战略到企业实践，区块链的应用逐渐从金融领域辐射出去，带动着其他行业的发展和改革。区块链对生产关系的改造力，降低了传统过程中因为信息不对称，信用不可靠而早就的资源浪费。在实体经济中，基于算法搭建的无第三方介入的信用机制更是将数字化提升到一个新的层面，即”可信数字化“，极大地加速了实体经济中资金的流通，为经济上实现”弯道超车“提供了新的动力。 2.2 完善去中心化基础设施，奠定社会信任基石 去中心化的技术优势使得未来基于区块链理念的各类去中心化应用，去中心化自治组织，去中心化自治公司，甚至去中心化社会成为可能。不断完善的去中心化基础设施，逐步构建起来的社会信用体系，将为智能社会进一步赋能。就现状而言，智能合约会是未来一个重要的去中心化基础设施，预计之恶能合约会从自动化向智能化方向演变。而现阶段的智能合约本质逻辑是”IF-THEN“类型的条件响应规则，迈向更为智能的”WHAT-IF“推演过程。社会信任体系将从第三方中心的监督机制，转向由共识算法定义的信用体系。避开人性的贪婪，将数据资产交付给理性的机器合约，或许是行之有效的一种方向。 2.3 区块链驱动的平行社会 有关学者认为，区块链将引领世界从物理+网络的CPS实际世界走向精神层面的人工世界，形成物理+网络+人工的人-机-物一体化的三元耦合系统，称为社会物理信息系统CPSS。基于CPSS的平行社会已有了雏形，其核心本质特征是虚实互动与平行演化。而区块链就是实现CPSS平行社会的基础架构之一，为分布式社会系统和人工智能系统，物联网系统，提供了行之有效的去中心化数据结构，交互机制和计算范式，为实现平行社会奠定了坚实的数据基础和信用基础。智能合约的可编程性驱动着平行社会的进展，搭载物联网中的智能硬件，将虚拟空间和现实物理世界联通在一起，通过可靠有效的人物交互和智能识别，实现社会管理和社会模式的优化。 ​ 区块链的浪潮已经到来，由虚向实，更多区块链项目正在落地，进一步的数字化生活逐渐有了雏形。积极拥抱区块链，把握区块链发展态势，于个人，于企业，于国家，目前看，都是一个正确但要付出很大的努力去摸索的选择。 参考文献[1] 袁勇, 王飞跃. 区块链技术发展现状与展望. 自动化学报, 2016, 42(4): 481-494 [2] Zibin Zheng, Shaoan Xie, Hong-Ning Dai,Xiangping Chen,Huaimin Wang.Blockchain Challenges and Opportunities: A Survey. Int. J. Web and Grid Services [3]袁勇,周涛, 周傲英,段永朝, 王飞跃.区块链技术: 从数据智能到知识自动化.自动化学报,2017,43(9):1485-1490 [4] 2018 年中国区块链产业白皮书 [Online], available:http://www.miit.gov.cn/n1146290/n1146402/n1146445/c6180238/part/6180297.pdf, 2018-05-20. [5]黄俊飞,刘杰. 区块链技术研究综述. 北京邮电大学学报,2018,41(2):1-8","tags":[{"name":"区块链","slug":"区块链","permalink":"https://joshuaqyh.github.io/tags/区块链/"}]},{"title":"机器学习 | 基本概念理解","date":"2018-08-14T16:07:06.722Z","path":"2018/08/15/机器学习（一）--概念理解/","text":"笔记基于《机器学习》周志华一书所作的整理。 机器学习是什么，如何理解机器学习？ 人在认知事物的时候，必须经过一定的经验积累和认识，然后做出相应合理的决策。也就是说人在某一领域上经验的积累会提高人对事物的处理和反应能力。类比到机器学习中，机器学习正是这样一门学科，致力于如何通过计算的手段，利用所谓的经验来让系统具有一定的功能或者改善自己的性能，比如计算机视觉让计算机有“看物体”的能力，并使视觉能力不断增强，自然语言处理让计算机有“翻译，对话”能力，大量的模拟和计算使机器更“懂人话”。 在计算机系统中，“经验” 通常以“数据”的方式存在。机器学习所要研究的主要内容就是，关于在计算机上从数据中产生一个模型的算法，即“学习算法”。基于提供的经验和数据我们对系统进行提炼和优化模型，当系统接收到相应输入时，根据已有的经验去进行响应，做出符合“智能”定义的行为。机器学习，主要是数据+算法。通常情况下，数据的采集和处理显得更为重要，一般来说数据集越大，学习能力越强，但也意味着更长的训练时间和修正优化时间。 机器学习需要的数据基础 要进行机器学习，先要有数据。比如判定西瓜的好坏，需要先给出许多西瓜的数据例子：（色泽=青绿，根蒂=硬挺 … )[]，（色泽=白色，根蒂=蜷缩）[ ]等等，这些数据记录的集合称为数据集，每一条记录都是样本或者示例，每一条记录里有对象的属性或特征。 属性张开的空间称为属性空间，样本张开的空间称为样本空间 。在数学上，我们使用线性代数中的向量来表示物体的空间，空间的维度由我们数据记录中的属性个数决定，比如西瓜有色泽，根蒂，响声三个属性，那么我们以这三个属性张开的空间就可以表示所有的西瓜，每一个西瓜都能在这个空间中找到自己的坐标位置。由于空间中的每一个点对应一个坐标向量，因此我们也把一个示例称为一个特征向量。 一般地，令D = {x1， x2..， Xm } 表示包含m 个示例的数据集，每个示例由d 个属性描述(例如上面的西瓜数据使用了3 个属性)，则每个示例Xi = (Xi1; Xi2; . . . ; Xid) 是d 维样本空间X 中的一个向量， Xi ε X ， 其中Xij 是xi在第j 个属性上的取值(例如上述第3 个西瓜在第2 个属性上的值是”硬挺” ), d 称为样本xi的”维数” (dimensionality)。 机器学习的过程 从数据中学的模型的过程称为“学习”或者“训练”。整个过程通过执行某些算法来完成（我们将了解到十大算法CNN，RNN），训练过程 中使用的数据称为“训练数据”， 每一个样本称为“训练样本”，训练样本的集合称为“训练集”。 学得模型对应了关于数据的某种潜在规律，亦称假设（后续会根据数据的训练做不断地修正）, 机器学习本身就是一个不断逼近事实真相的过程。 模型有时被称为“学习器”，可看作学习算法在给定数据和参数空间上的实例化 机器学习所能完成的事和划分 预测 要建立一个可预测的模型，我们需要获得训练样本的结果信息，通常称为标记。一个样本具有标记时可成为样例。 标记集合也成为标记空间或者输出空间。比如要判断西瓜的好坏时，我们除了给出西瓜色泽，敲声等属性时，还要给出在这些属性下瓜的好坏，即赋予每一个样本标记 。根据预测对象的不同时，我们定义了不同的学习任务。 分类：当预测的对象是离散值（例如好瓜，坏瓜），此类学习任务称为分类。 回归：当预测的对象是连续值（例如西瓜的成熟度），此类学习任务称为回归。 当预测的类别只有两个时，称为“二分类”任务，涉及多个时，称为“多分类”任务。 一般地，预测任务是希望通过对训练集{(X1’ Y1) , (X2 , Y2) ,…, (Xm, Ym)} 进行学习，建立一个从输入空间X 到输出空间y 的映射f: X 叶y. 对二分类任务，通常令Y = {-1 ，+1} 或{0 ， l}; 对多分类任务， IYI &gt;2; 对回归任务， Y= R，R为实数集. 学得模型之后，使用其进行预测的过程称为“测试”。被预测的样本称为测试样本“。也就是说学习的过程是建立一个准确率更高的关于输入到输入的映射关系。 训练数据处理：聚类clustering 将训练集中的西瓜分成若干组，每一组称为一个簇，这些自动形成的簇可以对应一些潜在的概念划分，比如西瓜中按照色泽划分为”深色瓜“和”浅色瓜“。 这样有助于我们了解数据内在的规律，更为深入地分析数据建立基础。但是在聚类学习中，我们事先并不知道西瓜是根据哪些属性特征来划分为簇的，在学习过程中使用的训练样本通常不拥有标记信息。 ​ 根据训练样本是否拥有标记信息，学习任务大致可以划分为两类：监督学习和无监督学习。没有标记的当然是无监督学习，这意味着在无监督学习中没有标准答案给机器，只能依靠机器分析内部的数据特征来做响应的判断，而有标记的学习，则可以理解为在得到标准答案后，机器的一次次自我修正，以期下次遇到相似的问题时，能得到和标准答案更为接近的答案。显然，分类和回归属于监督学习，聚类属于无监督学习。 泛化： 机器学习不仅在已有的训练样本上表现出高准确率，在新的未尝试过的样本上也能体现较高的准确率。显然强泛化的模型，更适用于整个样本空间，虽然样只是空间中一个很小的采样。 假设空间：由对象所可能存在的不同属性值所张成的空间 归纳： 从特殊到一般的“泛化”过程，而从“样例”中学习显然是一个归纳的过程，所以也称为“归纳学习”。 狭义归纳：要求从训练数据集中获得概念，所以也称概念学习或者概念形成。 概念学习中最简单的就是布尔概念学习，即让机器判断对或错，黑或白，类似预测中的二分类学习。 演绎：从一般到特殊的“特化”过程，从基础原理推演到具体的情况。在数学公理系统中，基于公理和推理推导出与之相恰的定理。 模拟搜索西瓜问题的假设空间有多种做法，例如从顶向下，从一般到特殊，从底向上，从特殊到一般。 搜索过程遇到和训练集的“正确答案”不一致时，需要删除或者调整参数使之逼近真相。 在现实问题中，存在着很大的假设空间。但学习过程是基于有限的样本训练集来进行的，可能有多个假设和训练集一致。即存在一个与训练集一致的假设集合，称为“版本空间”。不同训练集对应不同的版本空间，版本空间属于假设空间的一部分。 归纳偏好 版本空间的问题：如果有三个与训练集一致的假设，但在不同模型的情况下，面临新的样本，却会产生不同的输出判断。也就是说不同的模型具有不同的偏好，对某种类型的假设的偏好。 在训练集之外的样本误差的计算方法 P8~9 总误差和实际学习算法无关，任意两个学习算法的总误差相同。 也就是说学习算法所具有的不同训练集外误差的期望性相同。这就是“没有免费午餐定理” NFL。定理的前提：我们希望学习的真实目标函数f均匀分布，实际并非如此。该定理揭示的是，脱离具体问题，空泛谈“什么学习算法”更好是毫无意义的。","tags":[{"name":"机器学习","slug":"机器学习","permalink":"https://joshuaqyh.github.io/tags/机器学习/"}]},{"title":"机器学习 | 前向和反向传播Python代码实现","date":"2018-07-30T05:58:03.051Z","path":"2018/07/30/神经网络-前向和方向传播/","text":"Just show the code. 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164\"\"\" 神经网络模型简介： 单层神经元（感知机）： 1. 输入向量Wi： 多个同维向量，其中包括多个输入节点和标注为+1的偏置节点 2. 输入权值j1： 每个输入向量（除去偏置节点）在输入神经元时都需要乘上一个相应的权值 3. 输入值 ΣWiji + b： 为每个输入节点乘上相应的权值然后求和再加上偏置节点 4. 激活函数： 通常使用sigmoid函数，作为激活函数，有单极性和双极性之分 5. 输出值： 激活函数的返回值，为神经元网络的输出或者为下一个神经元的输入 多层神经元模型： 为单层神经元的级联，每一层的结构包括多个神经元，接受上一层神经元的输入 产生下一神经元的输出，不同层的神经元之间有相应的权值。 * 层次结构：输入层+隐藏层+输出层 1. 输入层：包含多个输入节点和一个标注为+1的偏置节点，偏置节点不接受输入。 2. 隐藏层：为多个神经元级联而成，每一层数目与输入层数目一致 3. 输出层：只有一个神经元结构，最后一层的隐藏层的作为输出层的输入，输出整个神经网络的结果 前向传播与后向（反向）传播 --- 前向传播对应预测（分类），后向传播对应训练 * 前向传播：就是给定模型参数即输入层的输入和偏置节点，逐一计算各层的输出值，直到最后输出神经网络的结果 * 后向传播： \"\"\"import math# 单极性激活函数，优点连续可导def sigmoid1(x): \"\"\" :sigmoid单极性函数 1/(1+e^-x) :param: x， 函数自变量 :return: sigmoid函数值 \"\"\" return 1.0/(1.0 + math.exp(-x))# 单极性激活函数的导数def dsigmoid1(y): \"\"\" :sigmoid 单极性函数的导数 :param y 函数自变量: :return 函数 运算结果 \"\"\" return y*(1-y)#双极性激活函数 def sigmoid2(x): \"\"\" ：sigmoid双极性函数 tanh （z） : param x,函数自变量 : return 函数因变量 \"\"\" return math.tanh(x)#双性极性激活函数的导数def dsigmoid2(y): \"\"\" : sigmoid双极性函数的导数 ：param x,函数自变量 ：return 函数因变量 \"\"\" return 1.0 - y ** 2# 神经网络前向传播实现方法\"\"\" 前向传播算法，神经网络的输出值即预测值可作为后向传播误差的计算\"\"\"def runNN(self, inputs): \"\"\" ：前向传播进行分类 ：param: inputs-输入参数 ：return: 所属类别 \"\"\" # 输入的数目必须为每一层规定节点数-1，除去偏置节点，不接受输入 if len(inputs) != self.ni - 1: print (\"incorrect number of inputs\") # 将输入向量映射到神经元的输入节点值 # ai - 输入层 for i in range(self.ni - 1): self.ai[i] = inputs[i] #输入层到隐藏层，隐藏层的运算 # ah - 隐藏层的输出值 for j in range(self.nh): sum = 0.0 for i in range(self.ni): sum += (self.ai[i] * self.wi[i][j]) # wi为输入层到隐藏层的权值 权值求和 self.ah[j] = sigmoid(sum) #输入激活函数，产生下一神经元的输入 #隐藏层到输出层，输出层运算 # ao - 最终输出结果 for k in range(self.no): sum = 0.0 for j in range(self.nh): sum += (self.ah[j] * self.wo[j][k]) # wo为隐藏层到输出层的权值 self.ao[k] = sigmoid(sum) return self.ao \"\"\" 后向传播 指的是在训练的时候，根据最终输出的误差（预测值-目标值的平方和/2） 来调整倒数第二层、倒数第三层……第一层的参数的过程。 主要有三种调整 1. 输出层权值的调整 2. 隐藏层权值的调整 3. 偏置节点的调整 算法步骤 1. 随机初始化参数（指权值和偏置节点），对输入利用前向传播计算输出 2. 对输出和隐藏节点进行调整，计算delta。公式比较难写。。 3. 计算梯度可定义学习率影响训练速度，并更新权值参数偏置参数。 \"\"\" def backPropagate(self, targets, N, M): \"\"\" 后向传播算法 :param targets: 实例的类别 :param N: 本次学习率 :param M: 上次学习率 :return: 最终的误差平方和的一半 \"\"\" # http://www.youtube.com/watch?v=aVId8KMsdUU&amp;feature=BFa&amp;list=LLldMCkmXl4j9_v0HeKdNcRA # 计算输出层 deltas # dE/dw[j][k] = (t[k] - ao[k]) * s'( SUM( w[j][k]*ah[j] ) ) * ah[j] output_deltas = [0.0] * self.no for k in range(self.no): error = targets[k] - self.ao[k] output_deltas[k] = error * dsigmoid(self.ao[k]) # 更新输出层权值 for j in range(self.nh): for k in range(self.no): # output_deltas[k] * self.ah[j] 才是 dError/dweight[j][k] change = output_deltas[k] * self.ah[j] self.wo[j][k] += N * change + M * self.co[j][k] self.co[j][k] = change # 计算隐藏层 deltas hidden_deltas = [0.0] * self.nh for j in range(self.nh): error = 0.0 for k in range(self.no): error += output_deltas[k] * self.wo[j][k] hidden_deltas[j] = error * dsigmoid(self.ah[j]) # 更新输入层权值 for i in range(self.ni): for j in range(self.nh): change = hidden_deltas[j] * self.ai[i] # print 'activation',self.ai[i],'synapse',i,j,'change',change self.wi[i][j] += N * change + M * self.ci[i][j] self.ci[i][j] = change # 计算误差平方和 # 1/2 是为了好看，**2 是平方 error = 0.0 for k in range(len(targets)): error = 0.5 * (targets[k] - self.ao[k]) ** 2 return error 来源来自大牛 http://www.hankcs.com/ml/back-propagation-neural-network.html thx！","tags":[{"name":"人工智能","slug":"人工智能","permalink":"https://joshuaqyh.github.io/tags/人工智能/"},{"name":"python","slug":"python","permalink":"https://joshuaqyh.github.io/tags/python/"},{"name":"机器学习","slug":"机器学习","permalink":"https://joshuaqyh.github.io/tags/机器学习/"}]},{"title":"认识经济学原理","date":"2018-07-27T15:28:32.813Z","path":"2018/07/27/认识经济学原理/","text":"经济学学习##十大曼昆经济学原理 ###原理一：人们面临交替关系 典型的交替关系就是 “大炮和黄油”的交替，花更多钱在大炮研发上就注定了减少黄油生产的投入。 这其中 涉及到一个资源配置做出决策的问题。 认识到人们面临交替关系本身并没有告诉我们，人们将会或应该作出什么决策。一个学生不应该仅仅由于要增加用于学习经济学的时间而放弃心理学的学习。社会不应该仅仅由于环境控制降低了我们的物质生活水平而不再保护环境。也不应该仅仅由于帮助穷人扭曲了工作激励而忽视了他们。然而，认识到生活中的交替关系是重要的，因为人们只有了解他们可以得到的选择，才能作出良好的决策。 原理二：某种东西的成本是为了得到它而放弃的东西许多行为选择的成本有时不是那么明显，收益也分为长期和短期，时间成本 ，金钱成本，人力成本都是需要考量的。 原理三： 理性人考虑边际量做决策考虑行为所花的额外成本和额外收益，通过比较这种边际收益和边际成本来，评价比较合理。 原理四：人们会对激励做出反应激励在决定行为中的中心作用是重要的。激励在贸易中可能体现为商品的成本或者收益。 列出并简要解释个人作出决策的四个原理 原理五： 贸易能使每个人状况更好贸易竞争能使国家和个人在相互交易的过程中收益。国与国之间的贸易未必就是像体育比赛一样一方赢，一方输，事实恰好相反，两国之间贸易可以使每个国家状况更好。 原理六：市场通常是组织经济活动的一种好方法经济学家亚当·斯密（Adam Smith）在他 1776 年的著作《国富论》中提出了全部经济学中最有名的观察结果：家庭和企业在市场上相互交易，他们仿佛被一只“看不见的手”所指引，引起了合意的市场结果。本书的目的之一就是要解释这只看不见的手如何施展它的魔力。当你学习经济学时，你将会知道，价格就是看不见的手用来指引经济活动的工具。价格既反映了一种物品的社会价值，也反映了生产该物品的社会成本 关于看不见的手在指引经济活动中的技巧有一个重要推论：当政府阻止价格根据供求自发地调整时，它就限制了看不见的手协调组成经济的千百万家庭和企业的能力。这个推论解释了为什么税收对资源配置有不利的影响：税收扭曲了价格，从而扭曲了家庭和企业的决策。这个推论还解释了租金控制这类直接控制价格的政策所引起的更大伤害。而且，这个推论也解释了共产主义的失败。在共产主义国家中，价格不是在市场上决定的，而是由中央计划者指定。这些计划者缺乏那种在价格对市场力量自由地作出反应时反映在价格中的信息。中央计划者之所以失败，是因为它们在管理经济时把市场上那只看不见的手缚起来了。 ###原理七：政府有时可以改善市场结果 政府干预经济的原因：促进效率和促进平等。政策的目标不是做大经济蛋糕二十改变蛋糕的分割。 ​ 看不见的手通常会使市场有效地配置资源。但是，由于各种原因，有时看不见的手不起作用。经济学家用市场失灵这个词来指市场本身不能有效配置资源的情况。市场失灵的一个可能原因是外部性。外部性是一个人的行动对旁观者福利的影响。污染是一个典型的例子。如果一家化工厂并不承担它排放烟尘的全部成本，它就会大量排放。在这种情况下，政府就可以通过环境保护来增加经济福利。 市场失灵的另一个可能原因是市场势力。市场势力是指一个人（或一小群人）不适当地影响市场价格的能力。例如，假设镇里的每个人都需要水，但只有一口井。这口井的所有者对水的销售就有市场势力——在这种情况下，它是一个垄断者。这口井的所有者并不受残酷竞争的限制，而正常情况下看不见的手正是以这种竞争来制约个人的私利。你将会知道，在这种情况下，规定垄断者收取的价格有可能提高经济效率。 列出并简要解释关于经济相互交易的三个原理 原理八： 一国的生活水平取决于它生产物品与劳务的能力​ 用什么来解释各国和不同时期中生活水平的巨大差别呢？答案之简单出人意料之外。几乎所有生活水平的变动都可以归因于各国生产率的差别——这就是一个工人一小时所生产的物品与劳务量的差别。在那些每单位时间工人能生产大量物品与劳务的国家，大多数人享有高生活水平；在那些工人生产率低的国家，大多数人必须忍受贫困的生活。同样，一国的生产率增长率决定了平均收入增长率。 ​ 生产率和生活水平之间的基本关系是简单的，但它的意义是深远的。如果生产率是生活水平的首要决定因素，那么，其他解释的重要性就应该是次要的。例如，有人想把上个世纪美国工人生活水平的提高归功于工会或最低工资法。但美国工人的真正英雄行为是他们提高了生产率。另一个例子是，一些评论家声称，美国近年来收入增长放慢是由于日本和其他国家日益激烈的竞争。但真正的敌人不是来自国外的竞争，而是美国生产率增长的放慢。 ​ 生产率与生活水平之间的关系对公共政策也有深远的含义。在考虑任何一项政策如何影响生活水平时，关键问题是政策如何影响我们生产物品与劳务的能力。为了提高生活水平，决策者需要通过让工人受到良好的教育，拥有生产物品与劳务需要的工具，以及得到获取最好技术的机会。 原理九： 当政府发行了过多的货币之后，物价上涨货币发行量超量，会导致通货膨胀 原理十：社会面临通货膨胀与失业之间的短期交替关系交替关系称为菲利普斯曲线。 由于价格是粘性的，各种政府政策都具有不同于长期效应的短期效应。例如，当政府减少货币量时，它就减少了人们支出的数量。较低的支出与居高不下的价格结合在一起就减少了企业销售的物品与劳务量。销售量减少又引起企业解雇工人。因此，对价格的变动作出完全的调整之前，货币量减少就暂时增加了失业。 列出并简要解释描述整体经济如何运行的三个原理。 币值稳定–交换的媒介 币值不稳定–投机的工具","tags":[{"name":"经济学","slug":"经济学","permalink":"https://joshuaqyh.github.io/tags/经济学/"}]},{"title":"湫嘤记-壹","date":"2018-07-27T15:28:32.802Z","path":"2018/07/27/湫嘤记-壹/","text":"“我意识到在这个地球上，除了你，没有人能够远程控制我的感情。” ​ ——记生命中一段绵长的奇迹。 一开始并不是想要讲一个宏大而浪漫的故事。没得讲，也不敢想。那天的白衣和相机，那天的短暂相遇，成了我最意想不到的一场奇迹。 一、十二月份的广州已经有些寒意，凉风把天一点一点吹高，很高，高到目光都不知道多久才能到达流云之上。 匆匆忙忙出门的路人A，对这次任务并没有一丝的兴趣。高中母校的校庆将至，每个人都要拍一段对母校的祝福。跟摄影师师兄约好的时间，就是今天了。 要在陌生人面前，对着他手中的相机镜头，挤出商业性微笑，说出一串感性的祝福语吗？开什么玩笑啊……难为情。社交恐惧症，真的很难为情。 万一是个很猥琐的师兄怎么办？万一很不好说话怎么办？就算不差，也实在是太抗拒陌生人了。路人A无奈地想着。 啊，他来了。 “你是XX吗？我就是师兄XXX。” 什么？师兄……原来是这样子的吗？ 路人A不太记得接下来说了些什么。唯一记忆犹新的，是那个将所有的焦虑和压抑都扫到流云之上去的微笑。 是光，冬日里不被云朵遮蔽的阳光，照在瞌睡的猫咪身上，绒毛的轮廓是一圈柔光如万千新生命跃动。 是歌，舒缓得如细水轻盈环绕，又是一股上扬的力量把你托起，升到可以离开所有世俗冷漠的高度。 路人A一直在小小的世界里搜集的，那种不经意间撞击心灵的感动，不经意间绚烂开放的美，似乎又落脚了。 没有架子，没有距离感，一直都那么清爽地咧嘴笑着，弯着湖水般的明亮双眼看着A，给她看相机里的画面。 不值一提的个人片段拍摄结束，故事按理来说到这里也结束了。 某一天朋友B在吃饭时向路人A提起，“XXX师兄真的是个超级温柔的人啊，从来不发脾气，什么都乐意帮忙，又那么有能力，你不知道，我们这次的策划啊，师兄他……” 路人A不知道策划的事。她只知道，这大概就是那一类自己很向往但是从来不可能成为的人吧。一直站在中心，那么耀眼，给所有的人善意，到处奉献自己的温柔，向暖，造暖。 她是个人主义者，不喜集群，闭门造车，琴棋书画只为取悦自己，纷繁复杂能不理则一概不理，从来高傲，却又自卑，无心也无力维持巨大的社交网络，不够有趣便拒之门外，融入世界需要莫大努力，打开心门需要莫大缘分。 可能是孤独，也有人说是独特。一个人流浪久了，自己也不知道是什么了。但是路人A，也是向暖的，也是想要有变化的，也是想靠近光的。 二、路人A咬咬牙，主动在微信上找了师兄。字字斟酌，反反复复，写学术论文般修改底稿，删除，空格，删除，空格，终于回车。 “师兄真的很厉害呢。“ “我想我没办法成为集体喜欢的那种人，但是我真的很欣赏师兄。” 师兄并没有因为生分而怠于回复，而是真诚地聊了很久，像阔别的旧友。每字每句的温度，恰如哥哥轻拍肩的安心感，暖流注入了A的心房。 “被集体喜欢很难，而且也未必就是真的喜欢……个人或者集体主义都好，都是中性词。” 她并没有被冷漠对待，A的心里有小小的欢喜，受宠若惊。 转念一想，欢喜什么？也许，所谓地暖，就是这样的吧。他生性使然，我怎可自作多情。 12月份也就这么悠悠晃过去了。没有其他值得提的故事。 但师兄在A的心中不经意撒下了几叶茶叶，不知不觉已被如获至宝地泡了一壶普洱，愈发醇厚，愈发袭人，空水共氤氲，只是，不敢细细品。 但A想要把这份勇敢继续下去。从小到大，A的行动力一直不强，很多事情都在安排好了的轨道上，只要往前走，不出意外就能得到。但A知道，十八岁以后，这种安稳已经消失了，从今往后的路不再属于被动前进的人。情感，也是如此。 1月1日，心血来潮的A在跨年的零点送出了一张小小的明信片。 “师兄，隐约觉得在师兄身上看到了我缺失的东西——那种冬日阳光般的温柔和热情，愿意付出自己，从不吝啬自己的微笑。愿你继续用那份细腻和温柔治愈世界，时光也一定会眷顾可爱的你……” 他说，哇，好喜欢！谢谢你。你也要继续简单快乐下去呀。 他还说，XX，你短头发很温雅的呢。 被夸了！ 屏幕那边的A在捂嘴笑。温雅……是这样吗？就算是商业性夸奖，也是饮饱喝足的幸福了。 但是，这个时期的A清楚——或者说，在强迫自己用底线思维去说服自己搞清楚，她并不是真的喜欢上了师兄，她只是向暖，仅此而已，而也足够。应当知足，因为贪婪的悬崖一跃下即万劫不复。 也许跨年夜的小小感恩是某种契机吧，一月份的路人A和她阳光一样的师兄开始慢慢变熟，慢慢发现这样那样的共同点，慢慢酝酿这样那样的话题。 A依然很谨慎，她不会每天都去叨扰师兄，她小心翼翼地选择着合适的时间、合适的频率、合适的话题，像雏鸟的羽毛，时不时轻挠师兄某根神经。 三、有一天，A偶然听到了一首歌，如空谷幽兰，却又仿佛能最深入人心中的每个见不到阳光的缝隙和角落，如天鹅绒的触感紧紧包围，所有的不安都暂时消失在悠悠回荡的歌声中，天地和胸膛，融为一体。如果有翅膀，此时的蓝天，一定最适合飞翔…… A马上想到的，是分享给师兄。A突然想到那句话： “那天我在街上看到一棵形状奇怪的榕树，第一反应竟是拍下来给你看。那时候我就知道，我大事不好了……” 这一刻她似乎明白了这种感觉。 A写了一段小小的乐评，连同歌曲一起发给了师兄。 22点50分，没有反应。 23点，没有反应。 23点30分，没有反应。 0点， 没有反应。 1点， …… A控制不住自己每过几分钟就看一眼手机，但终究是失望。她把头埋在枕头里，一遍又一遍地提醒自己该冷静一点了。也许只是一阵风吧，吹过了便过，他的好，只是一种逢场的应变，一种高超的社交技巧，一种对任何人都适用的套路，他是一个善于交际的人，给每个人阳光，可是管不了你绚烂不绚烂。 其实A还是不愿意相信的。师兄不是这样的人。就在两种想法的打架中，她终于撑不住，睡着了。 第二天醒来第一件事仍是抓起手机打开微信。 她看到了师兄回复的消息！一条，两条，三条，四条……很多，很长，很用心。 “细听这首歌，仿似一个歌者在悬崖上低吟浅唱，下视平野，远眺海洋，天空和海洋汇聚成地平线，歌声悠悠的回荡在天地间，还有绕耳的回响……淡淡的孤独与忧伤，却给人从中站起来的力量……” 原来一直都熬夜的师兄，刚好在那天养生了一回，早早入睡。A的消息，师兄是凌晨醒来才看到的。事情就是这么巧合。 师兄的那段文字，跟A的感受完美契合，甚至，A想不到更好的语言去表达出来的部分，师兄表达出来了。能够去感知虚无缥缈的东西，并用文字去表达出来的人，是拥有一颗诗意的心的，是有情怀有温度的人，A始终这么相信着。她再次确信了，师兄的内心，有星辰大海，值得她去探索。 就这么一来二去，A朦胧地感觉到，她和师兄，站在某一座吊桥的两端，相望着对方，想跨出一步，却因为不清楚绳的承重而担忧，是否会因彼此走近而使桥断裂，跌入深渊。 可是A很快就明白，脚底下的并不是深谷。 四、某一天，朋友C说，你怎么好像变温柔了。 是的，她不再那么棱角分明，不再那么冷若冰山，偶尔微笑，偶尔体贴，会去想环路上的猫咪是否有个可以安稳睡觉的家，会去想雨夜执勤的保安身上会不会太单薄，家里是否牵挂……难道这种改变毫无理由？她才突然悟到，自己好像被感染了。 水愈发接近沸腾，躁动的气泡随心跳的频率不断上升，茶香再也无处可逃，飘进了彼此的心里。 然后，他说，你以后就不用再拿我当师兄了，就叫我的名字就好了。 然后，他说，能和你倾心交流真的很开心，我认识的人太多，但这样的人真的不多。 然后，他说，晚上走环路的时候如果一个人害怕，也可以叫上我的。 然后，他说，明天一起复习吗？ 那天晚上，A到凌晨三点半才入睡。翻来覆去的，都是一个月前师兄那模糊的身影。再次见面，他会不会对我印象减分？我长得足够好看吗？我的谈吐足够大方吗？我有很多话题跟他讲吗？不断地在心里一遍遍打草稿，想流程，仿佛迎接一场重要的面试。 令A怎么也没有想到的是，接下来的两天，她几乎都和师兄待在一起。 也许，如果第一次见面那天晚上，A没有跟师兄说：“今天真的很开心，谢谢你”，师兄也就不会说“明天还继续吗？”，故事可能也就没有接下来的进展了。 等到很后来才知道，必然，是心的互相吸引；偶然，是彼此一个小小的表示主动的动作，必然和偶然的叠加，便是难以置信的天时地利人和。 再然后，在人烟稀少的环路，在微风轻拂的中心湖，在碧绿的草地上，在有阳光的树林里，两个人天南地北地聊着，漫无目的，只顾相互接近。彼此的人设一次又一次地崩塌、修缮、重建，越来越真实，越来越完整。 他们见面越来越频繁。而路人A的心里已经发生了翻天覆地的变化。但A还是不敢多想，她怕自己的细腻和敏感会给自己招来祸事——自作多情，终归破灭。 你很耀眼 你很充实 像一阵风 似乎可以吹动所有的安分和不安分 但我不知道你会不会眷顾曾经经过的草地 你的世界像一副完整的拼图 那我应该从哪里进去 她强行关闭自己少女情窦初开的窗户，若无其事地继续相处。她仍坚守着她的底线思维，奢望太多是要吃亏的，即使感受到了某种电波，也不能得意忘形。 这样做朋友也非常幸福不是吗？ 果然，低潮来了。 考试周，整整四天彼此都没有联系。四天，四天里他也许一刻都没有想起过A的事吧。果然还是普通的朋友吧？想得起来了就联系，想不起来就淡如水。A很难过。 倒数第二天，考完试出来，疲累的A一个人听着歌在内环上慢悠悠地走着，看着轻云追着夕阳跑，看着粉色的云块被红色的云块吞噬，紫色的云块和黄色的云块缠绵。 好想跟他说话。好想好想。不怕丢脸了，不想矜持了，不怕造成困扰了。久旱何时逢甘霖。 A终于忍不住拿出手机。聊了那么一两句，A还在码着字，师兄突然说：“先这样吧，我同学催我去打游戏了……” A默默把字一个一个删掉，默默地继续走。那天，A不知道怎么的迷迷糊糊走上了外环，在太阳落山之后迷路了，长长的环路逐渐融化在漆黑夜色中，她无奈地打开导航，在狂风中骑车，骑了很久很久，慌乱之中总算赶回了学校。 晚上，A因为白天的事有点失落，而最后一天又是两门最艰难的专业课，万分疲劳的A扔掉厚重的课本，插上耳机，开始宣泄自己的情感。手指在键盘上飞舞，诗行像疾速前行的火车一样，呼啸着穿过自己的内心。她疯狂地把自己的感情全都宣泄在这密密麻麻的文字里，只怕手速赶不上思维的激流，只怕语言传达不了内心的狂热。 手机屏幕猝不及防地亮了。是那熟悉的头像。茫茫海雾中航行的船只看到了信号塔的灯光。 “在复习吗？要不要出来走走？”看一看时刻，十一点半。 A叫了一声，差点从床上掉下来。她飞快地冲出去，所有的烦乱在这短短的信息里烟消云散。 “深夜的环路，雾气朦胧的恍若仙境，好棒啊。” “呃，什么雾……这是丁达尔效应。” “哇，你能不能诗意一点？现在这个氛围，一定要这么理性嘛？诶，工科男的思维啊……”A已经可以放肆一点地打趣了。 然后文艺到骨子里的文科生A和理性至上的工科生在凌晨寒冷的环路上傻笑了起来。 回想这几天的事，A突然有点谴责自己。我是不是对师兄太不信任了？事到如今，似乎没有必要再因为一些小事而去怀疑师兄的真诚，没必要不断地去拷问这段朦胧的感情。 水深火热的考试周终于过去，A第一次主动约了师兄走环路。 A想杀一个措手不及。“我问你一个问题。你会不会烦我呀？” “为什么突然这么说啊？你突然这样，弄得我好不知所措。” “如果我频繁地找你会打扰到你，那你可以直接说的……我不想过分地影响你的生活。” “我，我不烦你啊……我这个人的性格，不会轻易觉得别人烦的。”这句话让A倒吸一口凉气，她觉得师兄的回答烂透了。A直接就说了，原来你不烦我，是因为你性格的原因，而不是因为我的某些特质或者吸引你的地方啊？ “不，不是这样的……哎呀，怎么说，我……我感觉我最近像个智障了。不知道怎么表达，可是，可是我真的没有烦你啊！” 看到师兄慌乱的样子，A窃喜。她相信的，她相信师兄没有觉得她困扰。但是，她就是想逗一逗师兄。 “你的回答让我伤心了。” “你的提问也让我伤心了。” “为什么？” “居然问我有没有烦你，我肯定伤心啊。” 哦？似乎师兄的情商，其实一点都不低。 五、次日，师兄约了A一起去看电影。 从学校到巨幕影院，有将近一个小时的遥远路程。可是A却觉得这简直是一种馈赠，与他一起走，即使是走在永无止境的潘洛斯阶梯，也没有问题。 晚风清凉，A突然说：“你唱歌给我听好不好？” 羞涩了一下之后，师兄唱了很多。唱了少女的祈祷，唱了童话镇，唱了怯。 “祈求天地放过一双恋人，怕发生的永远别发生。从来没顺利遇上好景降临，如何能重拾信心……” A若有所思。 每次过红绿灯的时候，其实A都在观察师兄的侧脸。这侧脸真的很好看，长长的睫毛，高挺的鼻梁，还有那如水的目光，融化了春天的雪，深藏了如烟的柳絮。 聊着聊着，他们聊到了有点沉重的话题。A在社团里一直有些自卑，不起眼又被孤立，如今走到退社的境地。A垂下了头，难为情地苦笑。 一直盯着地面的A，突然感受到一个温暖的手掌，轻轻地拍了拍自己的后脑勺，轻得像羽毛掉落，掉落在A的内心，然后，烟火盛放。 “不要自卑啦，你很好的，我只希望你好好的呀……” A假装镇定自若，心如止水，继续说着什么话，但大脑里早已不知道自己在说什么。 看电影的过程中，师兄一直把头侧向A的这一边。只要A扶一下眼镜或吸一下鼻子，师兄就警觉地看过来。A抽泣了，他都知道。他会温柔地拍一拍A的额头，用温柔得像哄婴儿的声音说“没事没事，没事哈……” 看的是印度电影《神秘巨星》。电影中尹希娅的小男友，可爱又浪漫、情商极高的钦腾，一举一动都触动情窦初开少女的心弦。对比了一下有些木讷、不解风情的师兄，A凑近他，悄声说了一句“你看人家，情商多高。学习一下？” “啊……怎么办……呜……”师兄一副慌忙又委屈的模样，让A忍俊不禁。 看完电影的A，感动得怎么也止不住眼泪。“现在不要看我，我妆都花了。”“花了也非常好看。” 她心里在想着，如果此刻如此脆弱的我，可以得到师兄一个拥抱，哪怕片刻永恒…… 回去的路上，A的腿很酸痛。她开玩笑般地说，师兄可以背我吗？ “可以啊！上来吧。” “不不不……不用了。”A还是没有勇气接受。 但是A也有自己的小心机。她有意无意地就提起自己走不动了，她多希望，师兄能够扶着她走路。她想要接触，想要接触师兄温暖的手，想要感受到那熟悉的温度，想要靠在他结实的肩膀上看着疏星点点。 结果并没有。也许师兄也在小心翼翼地着棋吧，生怕下错一步，便不复从前。 一路无言，只有脚步声和影子，在路灯下演着默剧，揉碎夜的寒冷。 “你，现在在想什么呀？”师兄打破沉默。 完了，被将一军了。向来善于表达、自诩情商高的A突然舌头打结，捉摸不透这句话的意味，也想不到很好的回答。 “那，那你在想什么？” “你猜。” “我不猜。” 就这样，两个人各怀心事地继续走着，走回了各自的宿舍。 A不想要再静默下去，她把考试周的时候写的诗送给了师兄，希望迟钝的他能够在字里行间领会到哪怕一丝期许。 “我习惯了沉默 习惯了自己的高傲 习惯了比孤独更深一层的独特 习惯了窝在自己的舒适地带 也习惯了冷漠和稀零 也许我很不起眼 但也希望有人能够注意到我 我其实也不甘只是这样 也想有改变 想跟着你一起成长 想要被你所带动 所感染 也想向你尽可能展示我的光怪陆离 想让你感到至少是不无聊的 在兵荒马乱的世界 唱一首有点奇怪的歌 至少是让人值得注意的 很难喜欢君子之交淡如水这句话 只是对淡去的感情无法挽回的一种无奈叹惜 改变不了的事情 万用的道理去解释 解脱自己或者自我麻痹 如果可以像浪花一样热烈 像喷泉一样灵动 为什么要选择淡如水 这样想的我很自私 我知道 每个人都有自己的生活 但是 如果可以用一点点的自私去换一点点的改变 用一点点的改变去一点点走进别人的生活 一点点地让自己变得美好 一点点地为别人变得美好而献出自己微弱的光 该如何感动得泪湿眼眶 我像橡皮糖很黏 因为无法自我消化 所以渴望别人帮忙咀嚼我的情怀 快乐和烦恼 我总是无法独立 千头万绪像蒲公英一样飞舞 去寻找值得落下的地方 去看看——别人的房前屋后 别人的花开花落 别人那些在凌晨降临的软肋和在清晨复苏的坚定 那些写在眼里的信念和藏在心里的叹息 别人那些孤独 冷了深夜铁青的窗沿 别人那些温柔 爬上老家瓦顶的月光 我喜欢仰望有趣的灵魂中深藏的星辰大海 拥抱春暖花开 而你碰巧就在这里 那就让相同的彼此懂得 不同的便互相成就 我希望的 能有心照不宣 像足迹融化在雪地里 也有口口声声 是光点斑驳了夏季 顺着一架很长很长的梯子 从今天爬到明天 后天 坐在未来的屋顶 一起看湛蓝的天空如何变成金色的夕阳 泼墨的流云如何变成厚涂的油画 编织一个很长很长的故事 也从今天写到明天 后天 写在未来的结尾 金色的夕阳又唤醒了金色的朝阳 一轮又一轮 但我们永远年轻” 但是师兄似乎并不解其中味，他说，诗意的灵魂不拘一格。 A想要的不是赞赏呀。 六、接下来就是寒假了。A独自坐车回家，师兄还要留在学校几天。 见不到面的第一天，A有点骚动。深夜，A还是不愿意道晚安。“去睡吧，醒来再聊呀。” 一个小小的约定，给了A对明天的十足期待。睡吧，一早醒来，说不定还会有思念已久的粿汁可以吃。 见不到面的第二天，一早醒来，没有早餐。也没有师兄的消息。中午，没有动静。下午，没有动静。晚上，没有动静。 23点，仍然没有动静。 A无精打采地趴在床上，发了一个“你不要我了”的表情。 他很快就回复了。“没有呀！”他说今天很忙。 那就原谅你吧。 “抗日神剧好雷啊。为什么有枪不用，用刀……还有好多病句，什么几十位烈士壮烈牺牲……” “哎，你看这个就该隐藏智商。它的市场瞄准的又不是我们。你呀，智商该上线的时候不上线，在这时候就上线……” A继续聊。突然间，一个巨大方块唐突地跳了出来，密密麻麻的文字霸占了屏幕。 “有好多话没有说呢，无法准确传达我自己，从何说起呢，试着说一下。 总觉得和你有了默契，你是明白我的，我的快乐与忧虑也很想翻译成言语与你分享，除去忧伤，带给你一束光。 我一开始答应和你走在一起不是因为我要和你在一起，而是你能明白我…… 我特别享受能与你走在夜道中，晚风拂过脸庞，你我倾谈。你伤心需要陪伴的时候，有时说不出来安慰的话，我心头总是一顿软绵绵的无力感，我描述不出那种具体的感觉，但我还是知道的——那叫做喜欢。” A的提醒，让师兄“智商终于上线了” 这就是传说中的……告白吗？ “有好多话没有说呢，无法准确传达我自己，从何说起呢，试着说一下。 总觉得和你有了默契，你是明白我的，我的快乐与忧虑也很想翻译成言语与你分享，除去忧伤，带给你一束光。 我一开始答应和你走在一起不是因为我要和你在一起，而是你能明白我…… 我特别享受能与你走在夜道中，晚风拂过脸庞，你我倾谈。你伤心需要陪伴的时候，有时说不出来安慰的话，我心头总是一顿软绵绵的无力感，我描述不出那种具体的感觉，但我还是知道的——那叫做喜欢。” A还没反应过来，还没意识到这意味着什么，眼泪就先下来了。 泪水一片一片模糊视线，一个一个的方块字却越来越清晰，仿佛复刻进心里，默念便能倒背如流。 她不知道，其实在她按捺不住去找师兄聊的这段时间里，师兄已经在开始准备，开始酝酿，开始勇敢地迈出一步。 “ 我想说，我在2017的尾巴突然变得很幸运……就像我给你的诗写的，你碰巧就在这里，我就那么幸运遇到了你。 我想要的，有人能跟我一起看夕阳和朝霞。我也愿意去仰望他的天空，他的孤独和快乐。 跟你一起的日子，我希望内环有八万里。” “怪我，在你走的前一天晚上没牵起你的手。让你一个人坐车回去，我很不自在。” “那这个锅，你可要好好背着。” “下次见面，我就要抱抱你……” 路人A终于可以卸掉她路人的外衣，就像尹希娅卸掉自己黑色的罩袍。她终于可以说，她不再是路人A，不再是他世界里微不足道的路人，不再是孤独地站在世界边缘的流浪诗人，她是嘤嘤，世界上独一无二的嘤嘤。 他也不再是触不可及的完美师兄，他也有脆弱的一面， 傻气的一面，浪漫的一面，可爱的一面，他是奕浩，世界上独一无二的奕浩。 七、某天晚上，嘤嘤和奕浩在打电话。 他说，“我就想这样子跟你浪费时光，什么也不做，跟你说话。” 她说，“浪费这个词不是很好，改一下。” 怎么改？ ……想了很久。 嘤嘤在奕浩的电脑上敲下了：孕育时光。 然后嘤嘤又想了想，继续敲下了：奕起变老。 然后奕浩移动光标，在最前面敲下了：颖你而在。 因你而在，孕育时光，一起变老。 颖你而在，孕育时光，奕起变老。 嘤嘤又想起了约会时的对话： 我们就这样到处走，没有目的地，哪里都是过程。终点就是你，终点就是我。 我们的故事才刚刚开始，并且永远不会结束。","tags":[{"name":"love","slug":"love","permalink":"https://joshuaqyh.github.io/tags/love/"}]},{"title":"操作系统 | 内存管理","date":"2018-07-27T15:28:32.788Z","path":"2018/07/27/内存管理--操作系统第七章/","text":"指令和数据绑定到内存地址的条件 编译时— 若知道进程在内存里的驻留地址，直接生成 绝对代码 加载时— 若不知道进程的驻留地址，那么生成可重定位代码 执行时— 如果进程需要进行内存段之间的移动，那么需要延迟到执行时才进行 52703573268 逻辑地址空间和物理地址空间CPU 所生成的地址通常称为逻辑地址( logical address) ，而内存单元所看到的地址(I!IJ加载到内存地址寄存器(memory-address register) 中的地址)通常称为物理地址(physicaladdress) 。 编译和加载时的地址绑定方法生成相同的逻辑地址和物理地址。但是， 执行时的地址绑定方案导致不同的逻辑地址和物理地址。对于这种情况， 通常称逻辑地址为虚拟地址(virtual address)。在本书中， 对逻辑地址和虚拟地址不作区分。由程序所生成的所有逻辑地址的集合称为逻辑地址空间(logical address space), 与这些逻辑地址相对应的所有物理地址的集合称为物理地址空间(physical address space)。因此， 对千执行时地址绑定方案，逻辑地址空间与物理地址空间是不同的。运行时从虚拟地址到物理地址的映射是由被称为内存管理单元(memory-managementunit, MMU)的硬件设备来完成的。 52703635150 动态链接动态链接的概念与动态加载相似。只是这里不是将加载延迟到运行时，而是将链接延迟到运行时 动态加载迄今为止所讨论的是一个进程的整个程序和数据必须处于物理内存中，以便执行。因此进程的大小受物理内存大小的限制。为了获得更好的内存空间使用率，可以使用动态加载(dynamic loading) 。采用动态加载时，一个子程序只有在调用时才被加载。所有子程序都以可重定位的形式保存在磁盘上。主程序装入内存并执行。当一个子程序需要调用另一个子程序时，调用子程序首先检查另一个子程序是否己加载。如果没有，可重定位的链接程序将用来加载所需要的子程序，并更新程序的地址表以反映这→变化。接着，控制传递给新加载的子程序。动态加载的优点是不用的子程序决不会被加载。如果大多数代码需要用来处理异常情况，如错误处理，那么这种方法特别有用。对于这种情况，虽然总体上程序比较大，但是所使用的部分(即加载的部分)可能小很多。动态加载不需要操作系统提供特别的支持。利用这种方法来设计程序主要是用户的责任。不过，操作系统可以帮助程序员，如提供子程序库以实现动态加载。 交换进程需要在内存中以便执行。不过，进程可以暂时从内存中交换(swap) 到备份存储(backing store) 上，当需要再次执行时再调回到内存中。（例子：轮转法CPU调度） 如何进程换出roll out进程换入 roll in，操作系统较少采用。 连续内存分配内存通常分为两个区域:一个用于驻留操作系统，另一个用于用户进程。操作系统可以位于低内存，也可位于高内存。影响这一决定的主要因素是中断向量的位置。由于中断向量通常位于低内存，因此程序员通常将操作系统也放在低内存。在本书中，只讨论操作系统位于低内存的情况。真他情况的讨论类似。通常需要将多个进程同时放在内存中，因此需要考虑如何为输入队列中需要调入内存的进程分配内存空间。采用连续内存分配( contiguous memo可allocation) 时，每个进程位于一个连续的内存区域。 内存映射与保护问题通过采用重定位寄存器(已在8.1.3 小节讨论)和界限地址寄存器(己在8. 1.1小节讨论)，可以实现这种保护。重定位寄存器含有最小的物理地址值;界限地址寄存器含有逻辑地址的范围值(例如，重定位=100040 ，界限=74600) 。有了重定位寄存器和界限地址寄存器，每个逻辑地址必须小于界限地址寄存器。MMU 动’;ti:ltfp将逻辑地址加上重定位寄存器的值后映射成物理地址。映射后的物理地址再送交内存单元 内存分配方法最为简单的内存分配方法之一就是将内存分为多个固定大小的分区(partition) 。每个分区只能容纳一个进程。因此，多道程序的程度会受分区数所限制。如果使用这种多分区方法(multiple-partition method) ，当一个分区空闲时，可以从输入队列中选择一个进程，以调入到空闲分区。当进程终止时，其分区可以被其他进程所使用。这种方法最初为IBM 08/360 操作系统(称为MFT) 所使用，现在已不再使用。下面所描述的方法是固定分区方案的推广(称为MV凹，它主要用于批处理环境。这里所描述的许多思想也可用于采用纯分段内存管理的分时操作系统。 在可变分区(variable-partition) 方案里，操作系统有一个表，用于记录哪些内存可用和哪些内存已被占用。-开始，所有内存都可用于用户进程，因此可以作为一大块可用内存，称为孔(hole) 。当有新进程需要内存时，为该进程查找足够大的孔。如果找到，可以从该孔为该进程分配所需的内存，孔内未分配的内存可以下次再用。随着进程进入系统，它们将被加入到输入队列。操作系统根据所有进程的内存需要和现有可用内存情况来决定哪些进程可分配内存。当进程分配到空间时，它就装入内存，并开始竞争CPU 。当进程终It时，它将释放内存，该内存可以被操作系统分配给输入队列中的其他进程。在任意时候，再→组可用孔(块)大小列表和输入队列。操作系统根据调度算法来对输入队列进行排序。内存不断地分配给进程，直到下-个进程的内存需求不能满足为止，这时没有足够大的可用孔来装入进程。操作系统可以等到有足够大的空间，或者往下扫描输入队列以确定是否有其他内存需求较小的进程可以被满足。通常，→组不同大小的孔分散在内存中。当新进程需要内存时，系统为该进程查找足够大的孔。如果孔太大，那么就分为两块:一块分配给新进程，另一块还回到孔集合。当进程终止时，它将释放其内存，该内存将还给孔集合。如果新孔与其他孔相邻，那么将这些孔合并成大孔。这时，系统可以检查是否杳进程在等待内存~间，新合井的内存空间是否满足等待进程。这种方法是通用动态存储分配问题的二种情况(根据一组空闲孔来分配大小为n 的请求)。这个问题有许多解决方法。从-组可用孔中选择-个空闲孔的最为常用方法有首次适应( first岳1)、最佳适应(best-fiO 、最差适应(worst-fit) 。·首次适应:分配第一小足够大的孔。查找可以从头开始，也可以从上次首次适应结束时开始(避开碎片）。一旦找到足够大的空闲孔，就可以停止。·最佳适应:分配最小的足够大的孔。必须查找整个列表，除非列表按大小排序。这种方法可以产生最小剩余孔。·最差适应:分配最大孔。同样，必须查找整个列表，除非列表按大小排序。这种方法可以产生最大剩余孔，该孔可能比最佳适应方法产生的较小剩余孔更为有用。模拟结果显示首次适应和最佳适应方法在执行时间和利用空间方面都好于最差适应方法。首次适应和最佳适应方法在利用空间方面难分伯仲，但是首次适应方法要更快些。 碎片首次适应方法和最佳适应方法算法都有外部碎片问题(external 企agmentation) 0 随着进程装入和移出内存，空闲内存空间被分为小片段。当所有总的可用内存之和可以满足请求，但并不连续时，这就出现了外部碎片问题，该问题可能很严重。在最坏情况下，每两个进程之间就有空闲块(或浪费〉。如果这些内存是一整块，那么就可以再运行多个进程。","tags":[{"name":"操作系统","slug":"操作系统","permalink":"https://joshuaqyh.github.io/tags/操作系统/"}]},{"title":"计组 | 流水线技术简介","date":"2018-07-27T15:28:32.768Z","path":"2018/07/27/流水线技术简介/","text":"[TOC] 流水线技术流水线基础概念​ • 指令的执行过程是，对每一条指令做取指令，分析指令，执行指令。 ​ • 取指–移码–执行–访存–写回 ​ • 流水执行是，取指令时间上一条指令的执行阶段，执行指令阶段可能是下一条指令的取指令阶段。 ​ • 抽象概念：把一个重复过程分为若干个子过程，每个子部件由专门的部件实现。多个处理过程在时间上错开错开，依次通过各个部件。 ​ • 流水的段：每个子过程。 ​ • 流水的深度：子过程的个数。例如： 入-取指令-指令译码-执行-存结果-出–》浮点加法：入-求阶差-对阶-尾数相加-规格化-出 ​ • 流水时间是每一个段时间的总和，需要注意的是通过一个段的时间最长的段为流水线设计的瓶颈。流水线中各段的时间应尽可能相等，否则将引起流水线堵塞、断流。时间长的段将成为流水线的瓶颈 ​ • 时空图：从时间和空间两个方面来描述指令流水执行 ​ • 流水线的性能指标–吞吐率。即单位时间内完成任务的数量或者输出结果的数 量。 ​ ​ 相关​ • 数据相关 ​ • 名相关 ​ ○ 输出相关–写写操作 ​ ○ 反相关–先读后写，读的名和写的名一致 ​ • 控制相关 ​ ​ 每条指令访问读写的寄存器称为名 ​ 输出相关–写写操作，两条指令的 ​ 反相关—先读后写，读的名和写的名一致 ​ 换名技术 ​ 流水线冒险（冲突）​ 1. 结构冒险–硬件不支持多条指令在同一时间周期执行–重复，细分部件 ​ 2. 数据冒险–一条指令需要等待另外一条指令完成而造成流水线暂停。（所以设计的段的时候时间应尽量保持一致–前推旁路–写后读冲突–在写入i之前，j先读取，会造成读取错误。 ​ 为避免数据等待的问题，在每个段之间设计了一个缓冲寄存器（也叫锁存器） ​ 3.控制冒险 （分支冒险）–决策依赖于另外一条指令的结果，但其他指令正在执行当中。","tags":[{"name":"计组理论","slug":"计组理论","permalink":"https://joshuaqyh.github.io/tags/计组理论/"}]},{"title":"数据库 | 关系数据库设计理论简介","date":"2018-07-27T15:28:32.735Z","path":"2018/07/27/关系数据库设计理论/","text":"[TOC] 函数依赖 X→Y，表示Y依赖于X； X→Y，且Y→X不成立，Y→Z，则X→Z，表示Z传递依赖于X。 函数依赖性质 自反性 传递性 增广性 A → C 可以推出 AB → BC 52686998926 函数依赖的种类（完全函数依赖：在关系模式R（u）中，X,Y是U的子集，Y函数依赖于X 并且 Y非函数依赖于X的子集，则称Y完全函数依赖于X。X f &gt;Y）—&gt; Y依赖于X,但未必都依赖X的子集。 （部分函数依赖：在关系模式R（u）中，X,Y是U的子集，Y函数依赖于X 并且 Y函数依赖于X的子集） （函数依赖：某个属性集决定另一个属性集时，例如学生学号属性集Sno决定学生姓名属性集Sname，称Sname函数依赖于Sname ） （平凡函数依赖：Y函数依赖于X,并且Y包含于X，例如（Sno）-&gt;(Sno)、（Sno、Sname）-&gt;（Sno）） （非平凡函数依赖：Y函数依赖于X,并且Y不包含于X,例如(Sno,Sname）-&gt;（Ssex）） 键候选键： 能够唯一表示一个元组，且不含多属性超键： 是指能够唯一表示一个元组的属性集主属性：表示候选键中的属性非主属性：不包含在主键中的属性 判断主键的方法 ：若属性集为{ A , B, C}，A+ = ABC。 则A为主键。（属性闭包判断法） 范式 Normal Forms（1）第一范式1NF：关系中的所以属性值都是不可分割的原子值；（2）第二范式2NF：如果关系是1NF，且每个非主属性都完全依赖于候选键；（3）第三范式3NF：如果关系是1NF，且每个非主属性都不传递依赖于候选键；（4）鲍依斯-科得(巴斯)范式BCNF范式：如果关系是1NF，且每个属性都不传递依赖于候选键。 BCNF意味着在关系模式中每一个决定因素都包含候选键，也就是说，只要属性或属性组A能够决定任何一个属性B，则A的子集中必须有候选键。 52687012974 属性闭包定义：闭包就是由一个属性直接或间接推导出的所有属性的集合。 表示：B的闭包用B+表示。 计算：关系R的属性集X的闭包的步骤如下： 设最终将成为闭包的属性集是Y，把Y初始化为X； . 检查F中的每一个函数依赖A→B，如果属性集A中所有属性均在Y中，而B中有的属性不在Y中，则将 其加入到Y中； 重复第二步，直到没有属性可以添加到属性集Y中为止。 最后得到的Y就是X＋ 举例： 例1： R = {A,B,C,D,E} ​ F = {B→CD， D→E, B→A, E→C， AD→B } ​ 则 B+ = B ; B+ = BCD; B+ = BCDA； B+ = BCDAE。（推导过程是属性依赖传递的过程。 ​ 所以最终B+ 包含了R中所有属性。 故B is a key for R。 例2： 有关系模式R(U，F)，其中U={A，B，C，D，E，I}，F={A→D，AB→E，BI→E，CD→I，E→C}，计算(AE)闭包。 (1) 令X={AE}，X(0)=AE (2)在F中寻找尚未使用过的左边是AE的子集的函数依赖，结果是: A→D， E→C；所以 X(1)=X(0)DC=ACDE， 显然 X(1)≠X(0). (3) 在F中寻找尚未使用过的左边是ACDE的子集的函数依赖， 结果是: CD→I；所以 X(2)=X(1)I=ACDEI。虽然X（2）≠X(1)，但F中寻找尚未使用过函数依赖的左边已经没有X（2）的子集，所以不必再计算下去，即(AE)+=ACDEI。 例3：f={a-&gt;b，b-&gt;c，a-&gt;d，e-&gt;f}；由a可直接得到b和d，间接得到c，则a的闭包就是{a，b，c，d} 关系模式分解关系模式分解必须遵守两个准则 (1)无损联接性：信息不失真（不增减信息）。 (2)函数依赖保持性：不破坏属性间存在的依赖关系 无损连接分解R的无损分解为X Y，那么 x∩y →x 或者 x∩y → y. ####Dependency Preserving Decomposition 依赖保持分解 关系模式R&lt;U,F&gt;的分解是指R为它的一组子集 ρ={R1&lt;U1,F1&gt;, R2&lt;U2,F2&gt;,…, Rk&lt;Uk,Fk&gt;}所代替的过程。 其中U=U1∪U2∪…∪k ,并且没有Ui≤Uj(表Ui包含于Uj，1≤i,j≤k), Fi是F在Ui上的投影，即Fi={X→Y∈F+∧XY≤Ui}(表XY包含于Ui）。 描述：R被分解为 i个关系子集 Ri。Fi为每个子集的函数依赖投影。 计算函数依赖fi保持的方法就是：Fi∪Fj 推出 fi成立，其中Fi Fj的计算从自身属性和原来函数依赖推导得来。 模式分解是独立保持的条件就是，所有函数依赖Fi的投影的并集的闭包 = F的闭包 思考： 可否是Fi的闭包的并集 = F的闭包？ 回答：不可以，因为每个子集的函数依赖Fi，可能产生跨子集的函数依赖，先求Fi的闭包会产生不完整的闭包关系。 BCNF分解BCNF的要求：函数依赖要么平凡，函数依赖的左侧是超键 如果X→Y违反BCNF, 分解R 为R-Y 和XY。 第三范式分解第三范式的条件： 平凡依赖 x 属于超键 A属于候选键 部分依赖 传递依赖 最小覆盖模型— 简化函数依赖集 补充知识点自然连接在连接运算当中，一种最常用的连接是自然连接。如果关系R与S具有相同的属性组B，且该属性组的值相等时的连接称为自然连接，结果关系的属性集合为R的属性并上S减去属性B的属性集合。 参考的文章 函数依赖集闭包、属性集闭包、超键、候选键和最小函数依赖集 四种范式的实例 函数依赖不懂看这里","tags":[{"name":"数据库理论","slug":"数据库理论","permalink":"https://joshuaqyh.github.io/tags/数据库理论/"}]},{"title":"操作系统 | 死锁问题","date":"2018-07-27T15:28:32.721Z","path":"2018/07/27/读者写者问题/","text":"读者写者问题–写者对数据库有排他的访问 第一读者-写者问题 若有写者正在访问对象，那么其他读者需要保持等待 第二读者-写者问题 如果有写者等待访问对象，那么不会有新读者开始读操作 以上问题经常出现在数据库的访问读写问题之中。 哲学家问题导致出现哲学家饥饿的情况。 死锁的特征！死锁的必要条件： 互斥 占有并等待 非抢占 循环等待 52643424888 资源分配图节点集可分为两类：一类是系统活动进程集合（节点连接的线代表申请边，表示申请创建进程），一类是系统所有资源类型的集合（节点连接的线代表分配边，表示请求分配资源）。 52643431340 死锁处理方法 使用协议预防或者避免死锁 允许系统进入死锁状态，然后检测恢复它 忽视死锁，认为死锁不可能存在。。。（unix windows多采用这种办法，，比较常用 ​ 死锁预防只要保证死锁的四个必要条件有一个不成立，就可以起到死锁预防的效果。 否定互斥条件：这仅仅适用于共享资源。非共享资源必须有互斥条件 占有并等待：两种协议 非抢占：协议：一个进程占有资源并申请另外一个无法分配的资源，那么原来的资源将会隐式释放 循环等待：对所有资源类型进行编号排序，按编号递增顺序来申请资源。 死锁预防的缺点：低设备利用率和 低吞吐率 死锁避免死锁避免的方法：获得申请资源时进程的附加信息：意思是获得资源的先验信息，根据信息来判断是否分配资源或让其等待。 死锁避免的两个方法： 安全状态：存在一个安全序列，给进程分配资源，使得永远不会出现死锁，系统状态就是安全的。 资源分配图： 银行家算法 ！！！ ！！！死锁避免-银行家算法（重点）数据结构 Allocation：当前进程各种资源分配的的实例数量—- 二维矩阵 — 行代表不同进程，列代表资源 Max: 当前进程各类型资源的最大需求 —————— 二维矩阵— 同1 Need: 当前资源仍需要的各种类型资源——————- 二维矩阵— 同1 Avoidable: 当前系统能再提供的资源———————- 一维数组– 列代表资源类型，只有一行 安全性算法：一个Finish[m]数组判断进程是否完成， 每满足一个进程资源请求设为Finish[i] = true, 最后检测所有Finish是否都为false, 如果不是则不安全。 资源请求算法：每个进程有一个请求向量，系统假设满足该请求，然后计算分配后的结果是否安全，不安全则不分配。 两者最大缺点：无法提前预知进程对资源的最大需求。 死锁检测系统需要提供： 检测出现了死锁的算法 如何从死锁中恢复过来 检测算法 对于资源只有单个实例 对于资源有两个实例与银行家的安全算法不同的是最大需求矩阵变化为请求矩阵。其他基本一致 。得到一个安全序列的时候则认为系统安全。 时间复杂度 O （m*n^2) 恢复算法取消死锁的方法 终止一个或者某些进程 终止所有死锁进程—- 不大好 一次终止一个进程直到死锁取消。部分终止需要进程终止进程的选择，但终止完需要恢复！调度原则有： 按优先级：优先级低的先终止 按执行时间长度：执行时间短的先终止 按进程需要的资源：需要资源多的先终止 需要注意饥饿的情况。。 资源抢占","tags":[{"name":"操作系统","slug":"操作系统","permalink":"https://joshuaqyh.github.io/tags/操作系统/"}]},{"title":"计组 | 课堂笔记","date":"2018-07-27T15:28:32.706Z","path":"2018/07/27/第四章CPU--计组课堂笔记-01/","text":"CPU基础概念CPU功能： 指令控制，操作控制，时间控制，数据加工 CPU控制方式：同步控制，异步控制，联合控制 CPU指令周期：取值时间+执行时间 CPU周期：机器周期，总线周期。 CPU中断逻辑中断基础概念 暂停当前程序的执行，转而去执行其他程序，执行完毕之后，重新恢复中断程序的执行 中断源： 人为设置的中断，程序性事故, 硬件故障，外部事件（比如断电） 中断分类：可屏蔽中断和不可屏蔽中断；内部中断和外部中断；软中断和硬中断。 根据CPU是否可以采取响应判断来分类：可屏蔽中断，不可屏蔽中断。 电源断电，CPU不可禁止响应，另外可以根据中断源是否被屏蔽来确定是否给予响应。 ​ ####中断系统需要解决的7个问题： 中断如何向CPU提出诉求 多个中断同时发生请求，CPU如何优先处理？ 硬件排队 软件轮询 CPU响应中断的条件，时间，方式。 中断服务程序入口地址的查找：硬件向量法和软件查询法 中断响应的条件：中断允许触发器必须为1 中断响应时间：当前指令周期结束。（而不是指令执行结束） （2， 3 为中断响应的充分必要条件） CPU响应中断后如何保护现场 中断响应结束之后如何阻止源程序的执行转入中断服务程序的入口地址 中断处理结束后，CPU如何恢复现场 中断处理结束过程中出现了新的中断请求,CPU该如何处理 处理办法 ：中断处理系统中配置响应的软件和硬件 中断屏蔽技术 实现多重中断的条件： 提前设置开中断指令 优先级高的中断源有权屏蔽优先级别低的中断源 中断屏蔽的结果 屏蔽触发器与屏蔽字 改变中断优先登记以及运行轨迹的变化 中断屏蔽字的设置 ​ 多重中断的断点保护 中断响应轨迹图 设置中断屏蔽字改变中断响应优先级 发生多重中断时中断响应逻辑类似于CPU调度中的优先级调度。 引起cpu中断的各种因素（称为中断源） 人为设置的中断（访管指令） 程序性事故 硬件故障 I/O设备 外部事件","tags":[{"name":"计组理论","slug":"计组理论","permalink":"https://joshuaqyh.github.io/tags/计组理论/"},{"name":"CPU","slug":"CPU","permalink":"https://joshuaqyh.github.io/tags/CPU/"}]},{"title":"计组 | 单周期CPU设计笔记和总结","date":"2018-07-27T15:28:32.694Z","path":"2018/07/27/单周期CPU设计笔记和总结/","text":"单周期CPU设计与实现（实验)每一个指令都在一个时钟周期内完成，称为单周期CPU。 单周期CPU数据通路图该图描述的是CPU中数据，如何在 PC时钟，指令存储器，寄存器组，控制单元，ALU，数据存储器和控制器中如何传送的过程。 MIPS指令的三种格式 R类型 I类型 J类型 算术运算指令 逻辑运算指令 移位指令 比较指令 存储器读写指令 分支指令 跳转指令 停机指令 CPU学习笔记 - 5/15 ###逻辑设计 组合单元— 操作单元 如门 ALU 状态单元— 存储单元，如存储器，寄存器 注： 状态单元需要两个输入（时钟信号值和输入数据值） 一个输出（输出数据值）。 建立数据通路部件认识： PC程序计数器：存储当前指令的地址，每执行完一条指令，PC+4。（一个指令4个字节） 指令存储器： 数据存储器： 寄存器堆： ALU: 加法器： MIPS指令特点","tags":[{"name":"计组实验","slug":"计组实验","permalink":"https://joshuaqyh.github.io/tags/计组实验/"}]},{"title":"计组 | Verilog 设计初步","date":"2018-07-27T15:28:32.680Z","path":"2018/07/27/Verilog设计初步/","text":"Verilog设计初步Verilog 代码模板1234567891011121314151617181920212223242526//语句关键字字母都为小写字母，大小写敏感//硬件思维来写代码//命名不能以数字开头module &lt;顶层模块名&gt; (输入输出端口列表) //定义输入输出端口列表 output 输出端口列表； //输出端口生声明 input 输入端口列表； //输入输出端口生命 /*定义数据类型，功能定义，函数实现*/ reg 信号名； //逻辑功能定义 assign&lt;结果信号名&gt; = &lt;表达式&gt;; //用always块描述逻辑功能 always @(&lt;敏感信号&gt;) begin //过程赋值运算 //语句，if else while task end //调用其他模块 &lt;调用模块名module_name&gt;&lt;例化模块名&gt;(&lt;端口列表&gt;)； //门元件例化 门元件关键字&lt;例化门元件名&gt;(&lt;端口列表port_list&gt;);endmodule 四位选择器 123456789module mux4_1(out,in0, in1, in2,in4,sel); output out; input in0,in1,in2,in3; input[1:0] reg out; always @（in0 or in1 or in2 or in3 or sel) begin case(sel) 数据类型及运算符 整数类型 构成是：字符宽度+进制+数值。 例如：2’0xd5; 宽度为2的十六进制d5。 逻辑类型 高低电平 1 0，电路里体现为电压的区间 x：未知 z: 高阻 net类型 常用的是wire。用法是 wire[7:0] databus。 //databus宽度8 寄存器类型 reg integer time real realtime parameter参数 用来定义符号常量。 parameter sel = 8’ha3。 向量类型 逻辑运算符 位运算符 三目运算 位拼接运算符 下例采用数据流方式描述1位全加器。 在本例中，有两个连续赋值语句。这些赋值语句是并发的，与其书写的顺序无关。只要连续赋值语句右端表达式中操作数的值变化(即有事件发生), 连续赋值语句即被执行。如果A变化，则两个连续赋值都被计算，即同时对右端表达式求值，并将结果赋给左端目标。 语句 initial always @（敏感信号） @ (posedge clk) 上升沿 @ (negedge clk) 下降沿触发 赋值语句 连续赋值语句assign 只要连续赋值语句右端表达式中操作数的值变化, 连续赋值语句即被执行。 阻塞赋值 a = b; ————-非时序赋值（组合） 非阻塞赋值 a&lt;=b ————时序赋值中使用 时序和组合在电路上的表现是时序赋值过程中需要等待时钟沿来触发。 函数设计特点层次化模块化顶层模块和底层模块的设计方法，将模块细分为若干个子模块，在底层实现子模块功能，在顶层组合各个子模块。","tags":[{"name":"verilog","slug":"verilog","permalink":"https://joshuaqyh.github.io/tags/verilog/"}]},{"title":"SQL用法总结","date":"2018-07-27T15:28:32.663Z","path":"2018/07/27/SQL 用法--postgresql/","text":"SQL 用法–postgresql[TOC] 运算符https://www.postgresql.org/docs/9.1/static/functions-geometry.html 官方链接最全。 表格操作建表12345678CREATE TABLE users ( user_id INT AUTO_INCREMENT PRIMARY KEY, //声明主键 username VARCHAR(255) NOT NULL UNIQUE, //声明非空，唯一 password VARCHAR(255) NOT NULL FOREIGN KEY (user_id) REFERENCES projects (user_id) //声明 user_id为外键引用自表格projects); 改表123456ALTER TABLE table_nameADD new_colum data_type column_constraint [AFTER existing_column]; // 加列DROP COLUMN max_limit, //删除列MODIFY fee NUMERIC (10, 2) NOT NULL; //修改列约束 删表TRUNCATE table_name; // 将行清空，但表头依旧保留 DROP table table_name; //删除整个表格 PRIMARY KEY constraint UNIQUE constraint The number of constraints One Many NULL values Do not allow Allow 表的连接内连接–INNER JOIN两个表使用内连接，通过指定一个属性来匹配，若两个表的同一属性具有相同值，则保留在连接表中，其余不相等的行则消去。 图解 使用示例（内连接也可以连接多张表格） 12345SELECT A.nFROM AINNER JOIN B ON B.n = A.n;INNER JOIN C ON C.n = A.n; 全连接–FUll OUTER JOIN指定连接条件，属性值相同的行保留，但不重复，属性值不同的值保留，但存在某些为Null的情况。 用法示例 123SELECT column_listFROM AFULL OUTER JOIN B ON B.n = A.n; 左连接–LEFT JOIN对几个将要连接的表指定条件进行连接，属性匹配的时候，会保留左表所有属性，即便右表属性为NULL,但不会存在左表属性为NULL的情况。 代码示例： 12345SELECT A.nFROM ALEFT JOIN B ON B.n = A.n; 右连接–RIGHT JOIN和左连接相反，用法如下： 12345SELECT A.nFROM ALEFT JOIN B ON B.n = A.n; 交叉连接–CROSS JOIN看图就知道。。。交叉连接结果的表格是 两表行数相乘。需要指出的一点就是两个表相连不需要指定cross join。 12345SELECT column_listFROM A, B; 创建索引 PostgreSQL provides several index types: B-tree, Hash, GiST and GIN. Each index type uses a different algorithm that is best suited to different types of queries. By default, the CREATE INDEX command creates B-tree indexes, which fit the most common situations. 创建b_tree索引语法： create index index_name ON table_name(column_name) postgresql默认b树索引。官方描述如下： B-trees can handle equality and range queries on data that can be sorted into some ordering. In particular, the PostgreSQL query planner will consider using a B-tree index whenever an indexed column is involved in a comparison using one of these operators: &lt; &lt;= = &gt;= &gt; Constructs equivalent to combinations of these operators, such as BETWEEN and IN , can also be implemented with a B-tree index search. Also, an IS NULL or IS NOT NULL condition on an index column can be used with a B-tree index. 上述说明b_tree在范围查询中比较有效，也可以用于顺序检索数据。 当查询条件为范围查询时(运算符是 &gt; &lt; &lt;= &gt;= = is null, is not null, between and ,in)，b_tree索引可以体现较为良好的性能。 创建hash索引语法： create index index_name on table_name using hash(column_name) 官方描述 Hash indexes can only handle simple equality comparisons. The query planner will consider using a hash index whenever an indexed column is involved in a comparison using the = operator. 上述说明，hash索引仅仅在处理简单的等值比较-(=) 中相对有效。 使用GiST索引(错误）语法： create index index_name on table_name using GiST（column_name) 官方描述 GiST indexes are not a single kind of index, but rather an infrastructure within which many different indexing strategies can be implemented. Accordingly, the particular operators with which a GiST index can be used vary depending on the indexing strategy (the operator class). As an example, the standard distribution of PostgreSQL includes GiST operator classes for several two-dimensional geometric data types, which support indexed queries using these operators: &lt;&lt; &amp;&lt; &amp;&gt; &gt;&gt; `&lt;&lt; ` `&amp;&lt; ` ` &amp;&gt;` ` &gt;&gt;` @&gt; &lt;@ ~= &amp;&amp; 上述描述可知，gist 不是单一类型的索引，实现了不同策略索引的基础结构。可以根据索引策略（运算符类）来采取不同的索引策略。 详见官方文档gist index 使用GIN索引gin索引能够用于优化级的最近邻查找。 GIN indexes are inverted indexes which can handle values that contain more than one key, arrays for example. Like GiST, GIN can support many different user-defined indexing strategies and the particular operators with which a GIN index can be used vary depending on the indexing strategy. As an example, the standard distribution of PostgreSQLincludes GIN operator classes for one-dimensional arrays, which support indexed queries using these operators: &lt;@ @&gt; = &amp;&amp; 用法查看官方描述gin index. 分析效率 explain将explain(analyze)置于语句的开始，结果将返回语句执行效率有关的数值。 123456789101112explain （analyze） Select s_name, s_address, s_nationkey From table_a Where s_suppkey = 717;explain （analyze） Select s_name, s_address, s_nationkey From b_tree_a Where s_suppkey = 717;explain （analyze） Select s_name, s_address, s_nationkey From hash_a Where s_suppkey = 717; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126Click To Expand CodePostgreSQLThe following script creates the HR sample database structure in PostgreSQL.CREATE TABLE regions ( region_id SERIAL PRIMARY KEY, region_name CHARACTER VARYING (25));CREATE TABLE countries ( country_id CHARACTER (2) PRIMARY KEY, country_name CHARACTER VARYING (40), region_id INTEGER NOT NULL, FOREIGN KEY (region_id) REFERENCES regions (region_id) ON UPDATE CASCADE ON DELETE CASCADE);CREATE TABLE locations ( location_id SERIAL PRIMARY KEY, street_address CHARACTER VARYING (40), postal_code CHARACTER VARYING (12), city CHARACTER VARYING (30) NOT NULL, state_province CHARACTER VARYING (25), country_id CHARACTER (2) NOT NULL, FOREIGN KEY (country_id) REFERENCES countries (country_id) ON UPDATE CASCADE ON DELETE CASCADE);CREATE TABLE departments ( department_id SERIAL PRIMARY KEY, department_name CHARACTER VARYING (30) NOT NULL, location_id INTEGER, FOREIGN KEY (location_id) REFERENCES locations (location_id) ON UPDATE CASCADE ON DELETE CASCADE);CREATE TABLE jobs ( job_id SERIAL PRIMARY KEY, job_title CHARACTER VARYING (35) NOT NULL, min_salary NUMERIC (8, 2), max_salary NUMERIC (8, 2));CREATE TABLE employees ( employee_id SERIAL PRIMARY KEY, first_name CHARACTER VARYING (20), last_name CHARACTER VARYING (25) NOT NULL, email CHARACTER VARYING (100) NOT NULL, phone_number CHARACTER VARYING (20), hire_date DATE NOT NULL, job_id INTEGER NOT NULL, salary NUMERIC (8, 2) NOT NULL, manager_id INTEGER, department_id INTEGER, FOREIGN KEY (job_id) REFERENCES jobs (job_id) ON UPDATE CASCADE ON DELETE CASCADE, FOREIGN KEY (department_id) REFERENCES departments (department_id) ON UPDATE CASCADE ON DELETE CASCADE, FOREIGN KEY (manager_id) REFERENCES employees (employee_id) ON UPDATE CASCADE ON DELETE CASCADE);CREATE TABLE dependents ( dependent_id SERIAL PRIMARY KEY, first_name CHARACTER VARYING (50) NOT NULL, last_name CHARACTER VARYING (50) NOT NULL, relationship CHARACTER VARYING (25) NOT NULL, employee_id INTEGER NOT NULL, FOREIGN KEY (employee_id) REFERENCES employees (employee_id) ON DELETE CASCADE ON UPDATE CASCADE);CREATE TABLE regions ( region_id SERIAL PRIMARY KEY, region_name CHARACTER VARYING (25)); CREATE TABLE countries ( country_id CHARACTER (2) PRIMARY KEY, country_name CHARACTER VARYING (40), region_id INTEGER NOT NULL, FOREIGN KEY (region_id) REFERENCES regions (region_id) ON UPDATE CASCADE ON DELETE CASCADE); CREATE TABLE locations ( location_id SERIAL PRIMARY KEY, street_address CHARACTER VARYING (40), postal_code CHARACTER VARYING (12), city CHARACTER VARYING (30) NOT NULL, state_province CHARACTER VARYING (25), country_id CHARACTER (2) NOT NULL, FOREIGN KEY (country_id) REFERENCES countries (country_id) ON UPDATE CASCADE ON DELETE CASCADE); CREATE TABLE departments ( department_id SERIAL PRIMARY KEY, department_name CHARACTER VARYING (30) NOT NULL, location_id INTEGER, FOREIGN KEY (location_id) REFERENCES locations (location_id) ON UPDATE CASCADE ON DELETE CASCADE); CREATE TABLE jobs ( job_id SERIAL PRIMARY KEY, job_title CHARACTER VARYING (35) NOT NULL, min_salary NUMERIC (8, 2), max_salary NUMERIC (8, 2)); CREATE TABLE employees ( employee_id SERIAL PRIMARY KEY, first_name CHARACTER VARYING (20), last_name CHARACTER VARYING (25) NOT NULL, email CHARACTER VARYING (100) NOT NULL, phone_number CHARACTER VARYING (20), hire_date DATE NOT NULL, job_id INTEGER NOT NULL, salary NUMERIC (8, 2) NOT NULL, manager_id INTEGER, department_id INTEGER, FOREIGN KEY (job_id) REFERENCES jobs (job_id) ON UPDATE CASCADE ON DELETE CASCADE, FOREIGN KEY (department_id) REFERENCES departments (department_id) ON UPDATE CASCADE ON DELETE CASCADE, FOREIGN KEY (manager_id) REFERENCES employees (employee_id) ON UPDATE CASCADE ON DELETE CASCADE); CREATE TABLE dependents ( dependent_id SERIAL PRIMARY KEY, first_name CHARACTER VARYING (50) NOT NULL, last_name CHARACTER VARYING (50) NOT NULL, relationship CHARACTER VARYING (25) NOT NULL, employee_id INTEGER NOT NULL, FOREIGN KEY (employee_id) REFERENCES employees (employee_id) ON DELETE CASCADE ON UPDATE CASCADE);","tags":[{"name":"SQL","slug":"SQL","permalink":"https://joshuaqyh.github.io/tags/SQL/"}]},{"title":"cocos2d学习丨坑和解决办法","date":"2018-07-27T15:28:32.642Z","path":"2018/07/27/Q&A_cocos2d/","text":"cocos2d 使用遇到的问题和解决办法[TOC] Q 1： 如何解决中文乱码？A1: 直接看正确的示例代码，杂七杂八的代码太多，跟上版本的是下面这个 xml文件 1234&lt;dict&gt; &lt;key&gt;HelloWorldStringkey&gt; &lt;string&gt;你好，世界string&gt; dict&gt; 解析xml文件的代码。需要注意按键值获取中文内容保存为char*指针后，用于创建的label类是CCLabelTTF，而不是Label. 1234567891011121314151617//利用CCDictionary来读取xml CCDictionary *strings = CCDictionary::createWithContentsOfFile(\"strings.xml\");//载入资源文件夹的strings.xml //读取HelloWorld键中的值objectForKey根据key，获取对应的string const char *HelloWorld = ((CCString*)strings-&gt;objectForKey(\"HelloWorldString\"))-&gt;m_sString.c_str(); //获取屏幕的尺寸、位置信息等 CCSize visibleSize = CCDirector::sharedDirector()-&gt;getVisibleSize(); //乱码文字 CCLabelTTF *label0 = CCLabelTTF::create(\"你好，世界\",\"arial\",72); label0-&gt;setPosition(ccp(visibleSize.width/2,2*visibleSize.height/3)); this-&gt;addChild(label0); //正常中文 CCLabelTTF *label1 = CCLabelTTF::create(HelloWorld,\"arial\",72); label1-&gt;setPosition(ccp(visibleSize.width/2,visibleSize.height/3)); this-&gt;addChild(label1); Q2：xml文件资源（字体,图片等等）的放置的正确位置？A2：xml文件需要放在整个顶级项目文件里头的resources文件夹，而不是放在win32项目的resource…..坑。。具体可以看初始代码引用字体文件的路径。 Q3： 一开始打开项目文件发现文件不可用或者项目文件被卸载？A3：文件路径被改变，重新解压cocos安装包，重新安装。并且存放路径不能出现中文。 Q4: 编译时出现 libbox.lib不是有效的win32程序？A4：需要将hellococos项目设置为启动项。 Q5：当出现许多.h 文件不可用的时候？A5：重定解决方案目标 Q6:本地坐标系和世界坐标系如何互换计算1234CCPoint p1 = sprite2-&gt;convertToNodeSpace(sprite1-&gt;getPosition());CCPoint p2 = sprite2-&gt;convertToWorldSpace(sprite1-&gt;getPosition());CCPoint p3 = sprite2-&gt;convertToNodeSpaceAR(sprite1-&gt;getPosition());CCPoint p4 = sprite2-&gt;convertToWorldSpaceAR(sprite1-&gt;getPosition()); 计算方法都是用sprite1的坐标去加减sprite2的坐标，针对本地坐标系就用减法，针对世界坐标系就用加法。","tags":[{"name":"cocos2d","slug":"cocos2d","permalink":"https://joshuaqyh.github.io/tags/cocos2d/"}]},{"title":"ant,junit,vim,java","date":"2018-07-27T15:28:32.625Z","path":"2018/07/27/Leanring_report-ant-junit-vim-java/","text":"Vim简介Vim是一款上古编辑器，被广大程序员成为编辑器之神，这与之强大的编辑功能和编辑效率是分不开的。和Emace一样都在代码行业享有盛誉。vim最为重要的一点就是一切操作几乎可以舍弃鼠标，熟悉了vim命令的话，光靠键盘指令可以使开发效率迅速提高。 Vim的安装Linux下在Ubuntu平台下控制台敲入下列指令即可自动安装。 sudo apt-get install vim Windows下去官网 直接下载使用。 Vim常用指令和教程首先值得注意的一点就是其实vim是自带教程的Vimtutor,s使用方法是linux下输入命令vimtutor,即可开启教程，这属于官方教程， 最为详细，没有之一。 在这里介绍一些常用的vim命令，有利于快速上手vim。 1. 创建或打开文件 vim filename vim helloworld.java 2.添加内容一开始进入处于正常模式在编辑窗口直接输入i,a,o等字符可以进入输入模式，可以在屏幕下方看到insert单词。按左上角Esc键可以回到正常模式，使用各种方便的指令。以下指令均在正常模式下进行。 3.删除内容dd可以删除光标所在的一整行。 ndd可以删除光标以下的n行 4. 复制内容yy可以复制光标所在行的字符nyy可以复制光标以下的n行字符 5.粘贴内容p/P作用时粘贴字符，小写p将已复制的字符粘贴到光标以下，大写P将字符粘贴到光标以上。 6. 撤销内容撤销指令使用u,类似于windows上的ctrl z`。 7. 保存文件先进入正常模式Esc，然后输入:。然后输入： q 离开vim w 保存内容 wq 保存内容并离开vim,回到命令行 其他还有许多可以提高效率的指令在这里就不多赘述啦。 ​ Java知识入门###初探java 从hello world入门, 初步体会java这一门面向对象编程语言。在HelloWorld.java文件中键入以下代码。（注意文件名称必须和类名一致） 12345public class HelloWorld &#123; public static void main(String[] args) &#123; System.out.println(\"Hello World\"); &#125;&#125; 其中用到的编译指令是 javac HelloWorld.java 命令行没有弹出其他消息，即为编译成功。 执行指令是 java HelloWorld 这里用到两个重要指令javac java ，分别是编译和执行指令。 ###基础知识 由于已经学习过C++，java语言在一定程度上和C++是类似的，所以在Java入门学习上可以直接跳过基础语法，对象和类，基本数据类型，运算符，循环结构，分支结构。 Java面向对象java继承java继承的概念和C++类似，同样是定义一个父类，然后定义一个子类，来继承父类的属性，和C++不同的是，java用关键字extends 来表示继承关系。继承格式是 1234567class 父类 &#123;&#125; class 子类 extends 父类 &#123;&#125; ####继承的特性 子类拥有父类非private的属性，方法。 子类可以拥有自己的属性和方法，即子类可以对父类进行扩展。 子类可以用自己的方式实现父类的方法。 Java的继承是单继承，但是可以多重继承，单继承就是一个子类只能继承一个父类，多重继承就是，例如A类继承B类，B类继承C类，所以按照关系就是C类是B类的父类，B类是A类的父类，这是java继承区别于C++继承的一个特性。 提高了类之间的耦合性（继承的缺点，耦合度高就会造成代码之间的联系）。 ​ ####继承的关键字 关键字 作用 extends 单一继承 implements 继承多个父类 super 实现对父类父类成员的访问，引用父类 this 指向自己的引用 final 将自身定义为不可继承的类 java重写和重载重写#####重写含义 重写是子类对父类的允许访问的方法的实现过程进行重新编写, 返回值和形参都不能改变。即外壳不变，核心重写！重写的好处在于子类可以根据需要，定义特定于自己的行为。 也就是说子类能够根据需要实现父类的方法。。 重写方法的原则 参数列表必须完全与被重写方法的相同； 返回类型必须完全与被重写方法的返回类型相同； 访问权限不能比父类中被重写的方法的访问权限更低。例如：如果父类的一个方法被声明为public，那么在子类中重写该方法就不能声明为protected。 父类的成员方法只能被它的子类重写。 声明为final的方法不能被重写。 声明为static的方法不能被重写，但是能够被再次声明。 子类和父类在同一个包中，那么子类可以重写父类所有方法，除了声明为private和final的方法。 子类和父类不在同一个包中，那么子类只能够重写父类的声明为public和protected的非final方法。 代码实例1234567891011121314151617181920class Animal&#123; public void move()&#123; System.out.println(\"动物可以移动\"); &#125;&#125; class Dog extends Animal&#123; public void move()&#123; super.move(); // 应用super类的方法 System.out.println(\"狗可以跑和走\"); &#125;&#125; public class TestDog&#123; public static void main(String args[])&#123; Animal b = new Dog(); // Dog 对象 b.move(); //执行 Dog类的方法 &#125;&#125; 运行的结果是 狗可以跑和走 可以看到在Dog类中重写了move()方法，传入的参数和返回类型和原来父类的方法一致，但内部代码可以修改。 ####重载 #####重载含义 重载(overloading) 是在一个类里面，方法名字相同，而参数不同。返回类型可以相同也可以不同。 每个重载的方法（或者构造函数）都必须有一个独一无二的参数类型列表。 重载的规则 被重载的方法必须改变参数列表(参数个数或类型或顺序不一样)； 被重载的方法可以改变返回类型； 被重载的方法可以改变访问修饰符； 被重载的方法可以声明新的或更广的检查异常； 方法能够在同一个类中或者在一个子类中被重载。 无法以返回值类型作为重载函数的区分标准。 代码实例1234567891011121314151617181920212223242526272829public class Overloading &#123; public int test()&#123; System.out.println(\"test1\"); return 1; &#125; public void test(int a)&#123; System.out.println(\"test2\"); &#125; //以下两个参数类型顺序不同 public String test(int a,String s)&#123; System.out.println(\"test3\"); return \"returntest3\"; &#125; public String test(String s,int a)&#123; System.out.println(\"test4\"); return \"returntest4\"; &#125; public static void main(String[] args)&#123; Overloading o = new Overloading(); System.out.println(o.test()); o.test(1); System.out.println(o.test(1,\"test3\")); System.out.println(o.test(\"test4\",1)); &#125;&#125; 运行结果是 test1 test2 test3 test4 从运行结果看，调用的传参不同的函数顺序执行。 多态多态就是对象多种表现形式的体现。 #####多态存在的三个必要条件 继承 重写 父类引用指向子类对象 这里提供一份代码以便理解。大意就是一个抽象父类声明但不定义一个方法，在其他子类中可以重写这个方法。 123456789101112131415161718192021abstract class Animal &#123; abstract void eat(); &#125; class Cat extends Animal &#123; public void eat() &#123; System.out.println(\"吃鱼\"); &#125; public void work() &#123; System.out.println(\"抓老鼠\"); &#125; &#125; class Dog extends Animal &#123; public void eat() &#123; System.out.println(\"吃骨头\"); &#125; public void work() &#123; System.out.println(\"看家\"); &#125; &#125; ###java组件部分设计 Swing在本次实训实验中利用了Swing这个java的GUI工具包，以实现一个简单的计算器。其中的主要用途是引用这些包的相关控件，控件的相关接口，同时给这些控件注册事件，建立事件处理逻辑。 介绍控件，首先应提到JComponet 。 JComponent Swing 的整个可视组件库的基础构造块是 JComponent。它是所有组件的父类。它是一个抽象类，所以不能创建 JComponent，但是作为类层次结构的结果，从字面意义来说它包含了数百个函数，Swing 中的每个组件都可以使用这些函数。 注意： 每一个控件都是一个类，具有许多接口函数，在eclipes这个IDE上可以轻松获取。使用方法：鼠标移动到某一个控件类名，按ctrl键点击类名，即可弹出这个控件类里头详细的函数定义。 常用的控件集合 控件 用途 JLabel 用作文本描述 JButton 按钮 JFrame 窗口 JPanel 控件容器 JTextField 文本输入框 JCheckBox 确认框 GridLayout 生成网格状的布局 Tips: 任何一个控件都有Add()的方法，意味着每一个控件都可以添加到另外一个控件里。 注册事件的方法以下以button为例，进行两种常用方式的注册。 方法1 匿名内部类实现123456button.addActionListener( new ActionListener()&#123; public void actionPerformed(ActionEvent e) &#123; System.out.println(\"你按了按钮一\"); &#125; &#125;); //调用监听函数并定义监听事件 方法2 利用一般内部类实现1234567button.addActionListener(new Button2ActionListener()); private class Button1ActionListener implements ActionListener&#123; public void actionPerformed(ActionEvent e) &#123; System.out.println(\"你按了按钮一\"); &#125; &#125; //将事件处理为一个类事件 用了以上的基础知识就可以解决一个简单计算器的实现啦。 Junit 学习和使用###Junit是什么 JUnit是用于编写和运行可重复的自动化测试的开源测试框架， 这样可以保证我们的代码按预期工作。JUnit可广泛用于工业和作为支架(从命令行)或IDE(如Eclipse)内单独的Java程序。 JUnit提供： 断言测试预期结果。 测试功能共享通用的测试数据。 测试套件轻松地组织和运行测试。 图形和文本测试运行。 JUnit用于测试： 整个对象 对象的一部分 - 交互的方法或一些方法 几个对象之间的互动(交互) ​ ###JUnit的特点 JUnit是用于编写和运行测试的开源框架。 提供了注释，以确定测试方法。 提供断言测试预期结果。 提供了测试运行的运行测试。 JUnit测试让您可以更快地编写代码，提高质量 JUnit是优雅简洁。它是不那么复杂以及不需要花费太多的时间。 JUnit测试可以自动运行，检查自己的结果，并提供即时反馈。没有必要通过测试结果报告来手动梳理。 JUnit测试可以组织成测试套件包含测试案例，甚至其他测试套件。 Junit显示测试进度的，如果测试是没有问题条形是绿色的，测试失败则会变成红色。 注解 描述 @Testpublic void method() 测试注释指示该公共无效方法它所附着可以作为一个测试用例。 @Beforepublic void method() Before注释表示，该方法必须在类中的每个测试之前执行，以便执行测试某些必要的先决条件。 @BeforeClasspublic static void method() BeforeClass注释指出这是附着在静态方法必须执行一次并在类的所有测试之前。发生这种情况时一般是测试计算共享配置方法(如连接到数据库)。 @Afterpublic void method() After 注释指示，该方法在执行每项测试后执行(如执行每一个测试后重置某些变量，删除临时变量等) @AfterClasspublic static void method() 当需要执行所有的测试在JUnit测试用例类后执行，AfterClass注解可以使用以清理建立方法，(从数据库如断开连接)。注意：附有此批注(类似于BeforeClass)的方法必须定义为静态。 @Ignorepublic static void method() 当想暂时禁用特定的测试执行可以使用忽略注释。每个被注解为@Ignore的方法将不被执行。","tags":[{"name":"Java","slug":"Java","permalink":"https://joshuaqyh.github.io/tags/Java/"},{"name":"vim","slug":"vim","permalink":"https://joshuaqyh.github.io/tags/vim/"}]},{"title":"git学习","date":"2018-07-27T15:28:32.596Z","path":"2018/07/27/git学习/","text":"从本地添加项目到github仓库在git bash 命令行下进行： 123456789$ mkdir project //本地新建一个仓库，项目文件夹$ cd project // 进入文件夹$ git init // 初始化$ git remote add origin git@github.com:username/RepoName.git // 添加远程地址,换用户名和仓库名$ cat .git/config //查看配置文件是否添加远程地址成功$ git add -A // 上传本地项目$ git commit -m \"first commit\" //项目注释$ git push origin master // 上传仓库初始代码$ git status //查看提交情况，这一行出现在commit之前 git基础命令 git staus ————————————————————————- 进入仓库，查看仓库文件状态 git diff + filename ———————————————————— 查看文件与上一次提交时的不同 git add + filename || git commit -m “注释” ———————提交到库 —此处相当于代码存档 git log ——————————————————————————查看存档历史 git reset –hard HEAD^ ———————————————— —-一个^ 表示回退几次; HEA~100 回退一百次 git reset –hard 版本id —————————————————–回溯版本id git reflog ——————————————————————– 查看历史指令，可以看到之前的版本id git checkout – filename —————————————————— 舍弃上一次更改 git pull —————————————————————————— 更新内容 暂存区概念前面讲了我们把文件往Git版本库里添加的时候，是分两步执行的： 第一步是用git add把文件添加进去，实际上就是把文件修改添加到暂存区； 第二步是用git commit提交更改，实际上就是把暂存区的所有内容提交到当前分支。 因为我们创建Git版本库时，Git自动为我们创建了唯一一个master分支，所以，现在，git commit就是往master分支上提交更改。 你可以简单理解为，需要提交的文件修改通通放到暂存区，然后，一次性提交暂存区的所有修改。 多次修改的版本 可以多次add 保留到暂存区之后，一次性commit提交到版本库。 分支命令查看分支：git branch 创建分支：git branch &lt;name&gt; 切换分支：git checkout &lt;name&gt; 创建+切换分支：git checkout -b &lt;name&gt; 合并某分支到当前分支：git merge &lt;name&gt; 删除分支：git branch -d &lt;name&gt; 提交分支： git push origin branchname // orgin 相当于仓库， 意思为提交到仓库的某一分支 git 协同多人协作的工作模式通常是这样： 首先，可以试图用git push origin &lt;branch-name&gt;推送自己的修改； 如果推送失败，则因为远程分支比你的本地更新，需要先用git pull试图合并； 如果合并有冲突，则解决冲突，并在本地提交； 没有冲突或者解决掉冲突后，再用git push origin &lt;branch-name&gt;推送就能成功！ 如果git pull提示no tracking information，则说明本地分支和远程分支的链接关系没有创建，用命令git branch --set-upstream-to &lt;branch-name&gt; origin/&lt;branch-name&gt;。 这就是多人协作的工作模式，一旦熟悉了，就非常简单。 查看远程库信息，使用git remote -v； 本地新建的分支如果不推送到远程，对其他人就是不可见的； 从本地推送分支，使用git push origin branch-name，如果推送失败，先用git pull抓取远程的新提交； 在本地创建和远程分支对应的分支，使用git checkout -b branch-name origin/branch-name，本地和远程分支的名称最好一致； 建立本地分支和远程分支的关联，使用git branch --set-upstream branch-name origin/branch-name； 从远程抓取分支，使用git pull，如果有冲突，要先处理冲突。 ​ ​ 标签敲命令git tag &lt;name&gt;就可以打一个新标签： 1$ git tag v1.0 可以用命令git tag查看所有标签： 12$ git tagv1.0 因为创建的标签都只存储在本地，不会自动推送到远程。所以，打错的标签可以在本地安全删除。 如果要推送某个标签到远程，使用命令git push origin &lt;tagname&gt;： 1234$ git push origin v1.0Total 0 (delta 0), reused 0 (delta 0)To github.com:michaelliao/learngit.git * [new tag] v1.0 -&gt; v1.0 或者，一次性推送全部尚未推送到远程的本地标签： 1234$ git push origin --tagsTotal 0 (delta 0), reused 0 (delta 0)To github.com:michaelliao/learngit.git * [new tag] v0.9 -&gt; v0.9 如果标签已经推送到远程，要删除远程标签就麻烦一点，先从本地删除： 12$ git tag -d v0.9Deleted tag &apos;v0.9&apos; (was f52c633) 然后，从远程删除。删除命令也是push，但是格式如下： 123$ git push origin :refs/tags/v0.9To github.com:michaelliao/learngit.git - [deleted] v0.9 一些git学习链接git 代码分享 廖雪峰git教程","tags":[{"name":"git","slug":"git","permalink":"https://joshuaqyh.github.io/tags/git/"}]},{"title":"操作系统 | CPU调度算法（重点）","date":"2018-07-27T15:28:32.558Z","path":"2018/07/27/CPU调度算法/","text":"CPU调度算法 先到先服务 fcfs – CPU请求次序 缺点：FCFS 算法对于分时系统(每个用户需要定时地得到一定的CPU 时间)是特别麻烦的。允许一个进程保持CPU 时间过长将是个严重错误。 最短作业优先sjf – 平均等待时间最短 | 最优 存在抢占和非抢占 抢占（最短剩余时间优先）：由于CPU到达时间和CPU区间大小的差异，长作业可以优先处理，但出现短作业请求的时候，优先处理短作业 ​ 优先级调度 – fcfs sjf都是特殊的优先级调度 每个进程都有一个优先级与其关联，具有最高优先级的进程会分配到CPU 。具有相同优先级的进程按FCFS 顺序调度。 同样存在抢占调度的情况 问题：存在阻塞或饥饿– 存在进程一直处于等待状态 解决方法：老化– 等待时间越长，优先级提高 优先级可通过内部或外部方式来定义。内部定义优先级使用一些测量数据以计算进程优先级。例如，时间极限、内存要求、打开文件的数量和平均I/O 区间与平均CPU 区间之比都可以用于计算优先级。外部优先级是通过操作系统之外的准则来定义的，如进程重要性、用于支付使用计算机的费用类型和数量、赞助工作的单位、其他(通常为政治)因素。 ​ 轮转法调度 – rr ( round robin 为分时系统而设置的 平均等待时间较长，响应时间较长 定义较小的时间处理单元，时间片。时间片和周转时间有关，要考虑和上下文切换的时间比例 进程存储在一个fifo循环队列中 ​ 多级队列调度 多级队列 调度算法(multilevel queue scheduling algorithm) 将就绪队列分成多个独立队列(见图5.6) 。根据进程的属性，如内存大小、进程优先级、进程类型，一个进程被永久地分配到一个队列。 根据进程的性质和属性对进程进行分组的方法，给不同的队列设立优先级。比如前台交互进程和后台批处理过程。前台交互进程较高。 每个队列可以采用不同的调度算法，前台交互需要等待时间较短的调度算法，通常选用rr调度，后台批处理可以选择fcfs,优先级调度算法。 缺点同样会产生阻塞的情况 队列之间必须有调度，通常采用固定优先级抢占调度。例如，前台队列可以比后台队列具有绝对的优先级。现在来研究一下具有5 个队列的多级队列调度算法的例子，按优先级来排列:①系统进程。②交互进程。③交互编辑进程。④批处理进程。⑤学生进程。 多级反馈队列调度 多级反馈队列调度算法(multilevel feedback queue scheduling algorithm) 允许进程在队列之间移动。主要思想是根据不同CPU 区间的特点以区分进程。如果进程使用过多CPU 时间，那么它会被转移到更低优先级队列。这种方案将νo 约束和交互进程留在更高优先级队列。此外，在较低优先级队列中等待时间过长的进程会被转移到更高优先级队列。这种形式的老化阻止饥饿的发生。 通常，多级反馈队列调度程序可由下列参数来定义:.队列数量。· 每个队列的调度算法。· 用以确定何时升级到更高优先级队列的方法。. 用以确定何时降级到更低优先级队列的方法。· 用以确定进程在需要服务时应进入哪个队列的方法。","tags":[{"name":"操作系统","slug":"操作系统","permalink":"https://joshuaqyh.github.io/tags/操作系统/"}]},{"title":"知乎问答——如何用互联网思维卖馒头","date":"2018-07-27T15:28:32.545Z","path":"2018/07/27/知乎问答_如何用互联网思维买馒头/","text":"回答一一、规划 slogan：做中国好馒头、做好中国馒头 使命：让全中国人重新吃上安心馒头 愿景：成为世界顶级的馒头品牌 广告语：这一口，谁不爱 目标人群：新中产阶级 新中产消费观的最大特征：相较于价格，他们在意质量，对于高质量的商品和服务，他们愿意为之付出更高的代价。较高的收入与体面的工作给中产带来片刻的欣慰，但不安与焦虑才是中产光鲜外表下最戳心的痛点，消费升级正是他们面对这种焦虑选择的解决方案。 二、设计 1.品牌 品牌要能让人产生联想，要好记，比如：”真馒头” 2.设计 包装要讲究，但重点是一定要去德国买一个红点奖。 每个包装上，还必须有扎心的文案，比如: 我们拼尽全力，不是为了活成别人想要的模样 你只来了一下子，却改变了我一辈子 我有馒头，你有故事吗? 3.产品 要秉承匠心精神，只做单一产品–真•葱花馒头，将一款产品做到极致。 但是可以根据用户人群推出专属款，比如 有助记忆力的儿童款 提高睡眠质量的老人款 4.门店 不同类型的门店来满足用户多元化的场景需求，包括满足用户线下社交需求的旗舰店，满足亲子活动的DIY体验店，以及快速自提、服务商务人群的快取店，满足客户外送需求的外卖厨房店。通过差异化的门店布局，实现对消费者日常生活全方位覆盖。 5.定价 统一价19.9元！！没有足够的利润空间，618、双11、双12你拿什么打折？ 三、营销 1.讲故事 馒头的面全部来自北纬36°黄金优麦区种植的8848号小麦，纯手工脱粒。 蒸馒头的水，选自长白山矿物质水，再经过36道工艺人工萃取。 创新思维碰撞传统手工技艺，再造中国馒头新未来。 2.讲情怀 创始人211名校毕业后，放弃BTA百万年薪自主创业；尝遍了全国各地大街小巷所有的馒头，拜访数十位隐居的大师，经历了同事朋友的嘲讽、女朋友的离等非常人所能经历的磨难后，终于发明了拥有独特、唯一口味的”真馒头”。 3.软文推广 《震惊！男人吃了沉默，女人吃了流泪》 《感动！一个馒头如果没有情怀，那它和面粉有什么区别》 《刚刚！人人都在疯抢这款馒头》 … 4.造气氛 找很多人来回排队，不用多讲，这是网红店的标配。但是排队的人员组成还是要有讲究的，需要有学生、青年、白领、中年人，而且不能一起到，要分批到。 5.制造热点事件 哭诉鹅厂抄袭商业模式 喊话某互联网大佬，打赌3年后比营业额 6.社会化传播 赞助绝地求生，新增能量馒头，吃一个血条全满！ 雇人拿着馒头去starbuck、costa，让咖啡、苹果笔记本、馒头成为新一代的装B三件套。 抢在韩国人前为馒头申遗！ 7.微微一抖 微博：每天去抢杜蕾斯、回忆专用小马甲的沙发，设置转发有奖活动； 微信公众号：每天深夜10点，推送一条荷尔蒙满满的语音鸡汤，一定要煽情！ 抖音：做一个卡通吉祥物，天天耍贱，卖萌，用户爱看什么拍什么。 8.饥饿营销 每家门店每天限量8888个，卖完即止。第二天的馒头需要提前预约。 9.裂变营销 给好友免费送馒头，他吃你也吃。 10.社群运营 建立真馒头的粉丝群，收集种子用户的建议反馈，经常与粉丝互动。邀请5个人进群可免费领取一个馒头，群成员可享受新品内测试吃福利。 11.APP运营 开启步数兑换优惠券功能，倡导绿色出行； 消费有积分，积分可以浇水种小麦，小麦长成后可以直接磨成面，寄给用户。 增加交友功能，注册必须上传吃馒头的自拍照，可以查看5公里内异性用户的照片，但是必须相互点赞，才能加好友聊天。 12.会员体系 充值5000黄金会员，享8折优惠；充值10000白金会员，全部5折，生日赠送定制版馒头。 13.配送模式 可以在APP或公众号上自助完成下单，下单时可以选择温度、辣度等，制作好了系统会发提示，凭二维码领取，节约排队时间；如果选择外送，在已经开通的外送区域15分钟左右送到，超过30分钟免费。 四、实现盈利 炒作互联网新零售+馒头的成功之道，然后花钱发一堆新闻通稿，进行大量商业路演，约见各类ＶＰ，重点来了： 想要快速套现的可以选择阿里的投资，2年内一定会被全资收购； 想要上市的优选搜狐的投资，直接搭建境外架构，3年后妥妥纳斯达克敲钟。 最后你们一定会问，你谁啊，靠不靠谱啊？ “我，秦始皇，打钱！” 回答二一、规划 slogan：做中国好馒头、做好中国馒头 使命：让全中国人重新吃上安心馒头 愿景：成为世界顶级的馒头品牌 广告语：这一口，谁不爱 目标人群：新中产阶级 新中产消费观的最大特征：相较于价格，他们在意质量，对于高质量的商品和服务，他们愿意为之付出更高的代价。较高的收入与体面的工作给中产带来片刻的欣慰，但不安与焦虑才是中产光鲜外表下最戳心的痛点，消费升级正是他们面对这种焦虑选择的解决方案。 二、设计 1.品牌 品牌要能让人产生联想，要好记，比如：”真馒头” 2.设计 包装要讲究，但重点是一定要去德国买一个红点奖。 每个包装上，还必须有扎心的文案，比如: 我们拼尽全力，不是为了活成别人想要的模样 你只来了一下子，却改变了我一辈子 我有馒头，你有故事吗? 3.产品 要秉承匠心精神，只做单一产品–真•葱花馒头，将一款产品做到极致。 但是可以根据用户人群推出专属款，比如 有助记忆力的儿童款 提高睡眠质量的老人款 4.门店 不同类型的门店来满足用户多元化的场景需求，包括满足用户线下社交需求的旗舰店，满足亲子活动的DIY体验店，以及快速自提、服务商务人群的快取店，满足客户外送需求的外卖厨房店。通过差异化的门店布局，实现对消费者日常生活全方位覆盖。 5.定价 统一价19.9元！！没有足够的利润空间，618、双11、双12你拿什么打折？ 三、营销 1.讲故事 馒头的面全部来自北纬36°黄金优麦区种植的8848号小麦，纯手工脱粒。 蒸馒头的水，选自长白山矿物质水，再经过36道工艺人工萃取。 创新思维碰撞传统手工技艺，再造中国馒头新未来。 2.讲情怀 创始人211名校毕业后，放弃BTA百万年薪自主创业；尝遍了全国各地大街小巷所有的馒头，拜访数十位隐居的大师，经历了同事朋友的嘲讽、女朋友的离等非常人所能经历的磨难后，终于发明了拥有独特、唯一口味的”真馒头”。 3.软文推广 《震惊！男人吃了沉默，女人吃了流泪》 《感动！一个馒头如果没有情怀，那它和面粉有什么区别》 《刚刚！人人都在疯抢这款馒头》 … 4.造气氛 找很多人来回排队，不用多讲，这是网红店的标配。但是排队的人员组成还是要有讲究的，需要有学生、青年、白领、中年人，而且不能一起到，要分批到。 5.制造热点事件 哭诉鹅厂抄袭商业模式 喊话某互联网大佬，打赌3年后比营业额 6.社会化传播 赞助绝地求生，新增能量馒头，吃一个血条全满！ 雇人拿着馒头去starbuck、costa，让咖啡、苹果笔记本、馒头成为新一代的装B三件套。 抢在韩国人前为馒头申遗！ 7.微微一抖 微博：每天去抢杜蕾斯、回忆专用小马甲的沙发，设置转发有奖活动； 微信公众号：每天深夜10点，推送一条荷尔蒙满满的语音鸡汤，一定要煽情！ 抖音：做一个卡通吉祥物，天天耍贱，卖萌，用户爱看什么拍什么。 8.饥饿营销 每家门店每天限量8888个，卖完即止。第二天的馒头需要提前预约。 9.裂变营销 给好友免费送馒头，他吃你也吃。 10.社群运营 建立真馒头的粉丝群，收集种子用户的建议反馈，经常与粉丝互动。邀请5个人进群可免费领取一个馒头，群成员可享受新品内测试吃福利。 11.APP运营 开启步数兑换优惠券功能，倡导绿色出行； 消费有积分，积分可以浇水种小麦，小麦长成后可以直接磨成面，寄给用户。 增加交友功能，注册必须上传吃馒头的自拍照，可以查看5公里内异性用户的照片，但是必须相互点赞，才能加好友聊天。 12.会员体系 充值5000黄金会员，享8折优惠；充值10000白金会员，全部5折，生日赠送定制版馒头。 13.配送模式 可以在APP或公众号上自助完成下单，下单时可以选择温度、辣度等，制作好了系统会发提示，凭二维码领取，节约排队时间；如果选择外送，在已经开通的外送区域15分钟左右送到，超过30分钟免费。 四、实现盈利 炒作互联网新零售+馒头的成功之道，然后花钱发一堆新闻通稿，进行大量商业路演，约见各类ＶＰ，重点来了： 想要快速套现的可以选择阿里的投资，2年内一定会被全资收购； 想要上市的优选搜狐的投资，直接搭建境外架构，3年后妥妥纳斯达克敲钟。 最后你们一定会问，你谁啊，靠不靠谱啊？ “我，秦始皇，打钱！”","tags":[{"name":"互联网思维","slug":"互联网思维","permalink":"https://joshuaqyh.github.io/tags/互联网思维/"}]}]