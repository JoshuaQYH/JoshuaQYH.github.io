<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
    

    

    



    <meta charset="utf-8">
    
    
    
    
    <title>adaboost集成学习 | KnowMyself | Code and life</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
    <meta name="theme-color" content="#3F51B5">
    
    
    <meta name="keywords" content="人工智能,机器学习,计算机视觉">
    <meta name="description" content="Adaboost 原理Adaboost 全称为 adaptive boost,  意为自适应的提升方法，作用是能够通过分布不同权重的方式将多个弱分类器提升为一个强分类器，不同的弱分类器解决不同的分类问题，多个弱分类器通过加权组合得到一个强分类器。详细公式过程如下:  给定 N 个样本的特征向量 $(x_1, …..) \, (x_2…..)  \, …(x_N, ….)$, 每一个样本都有对应的标">
<meta name="keywords" content="人工智能,机器学习,计算机视觉">
<meta property="og:type" content="article">
<meta property="og:title" content="adaboost集成学习">
<meta property="og:url" content="https://joshuaqyh.github.io/2018/12/20/adaboost集成学习/index.html">
<meta property="og:site_name" content="KnowMyself">
<meta property="og:description" content="Adaboost 原理Adaboost 全称为 adaptive boost,  意为自适应的提升方法，作用是能够通过分布不同权重的方式将多个弱分类器提升为一个强分类器，不同的弱分类器解决不同的分类问题，多个弱分类器通过加权组合得到一个强分类器。详细公式过程如下:  给定 N 个样本的特征向量 $(x_1, …..) \, (x_2…..)  \, …(x_N, ….)$, 每一个样本都有对应的标">
<meta property="og:locale" content="default">
<meta property="og:updated_time" content="2018-12-20T13:35:39.338Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="adaboost集成学习">
<meta name="twitter:description" content="Adaboost 原理Adaboost 全称为 adaptive boost,  意为自适应的提升方法，作用是能够通过分布不同权重的方式将多个弱分类器提升为一个强分类器，不同的弱分类器解决不同的分类问题，多个弱分类器通过加权组合得到一个强分类器。详细公式过程如下:  给定 N 个样本的特征向量 $(x_1, …..) \, (x_2…..)  \, …(x_N, ….)$, 每一个样本都有对应的标">
    
        <link rel="alternate" type="application/atom+xml" title="KnowMyself" href="/atom.xml">
    
    <link rel="shortcut icon" href="/favicon.ico">
    <link rel="stylesheet" href="//unpkg.com/hexo-theme-material-indigo@latest/css/style.css">
    <script>window.lazyScripts=[]</script>

    <!-- custom head -->
    

</head>

<body>
    <div id="loading" class="active"></div>

    <aside id="menu" class="hide">
  <div class="inner flex-row-vertical">
    <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menu-off">
        <i class="icon icon-lg icon-close"></i>
    </a>
    <div class="brand-wrap" style="background-image:url(/img/brand.jpg)">
      <div class="brand">
        <a href="/" class="avatar waves-effect waves-circle waves-light">
          <img src="/img/avatar.jpg">
        </a>
        <hgroup class="introduce">
          <h5 class="nickname">Qiuyihao</h5>
          <a href="mailto:576261090@qq.com" title="576261090@qq.com" class="mail">576261090@qq.com</a>
        </hgroup>
      </div>
    </div>
    <div class="scroll-wrap flex-col">
      <ul class="nav">
        
            <li class="waves-block waves-effect">
              <a href="/">
                <i class="icon icon-lg icon-home"></i>
                主页
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/archives">
                <i class="icon icon-lg icon-archives"></i>
                Archives
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/tags">
                <i class="icon icon-lg icon-tags"></i>
                Tags
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/categories">
                <i class="icon icon-lg icon-th-list"></i>
                Categories
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="https://github.com/JoshuaQYH" target="_blank">
                <i class="icon icon-lg icon-github"></i>
                Github
              </a>
            </li>
        
      </ul>
    </div>
  </div>
</aside>

    <main id="main">
        <header class="top-header" id="header">
    <div class="flex-row">
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light on" id="menu-toggle">
          <i class="icon icon-lg icon-navicon"></i>
        </a>
        <div class="flex-col header-title ellipsis">adaboost集成学习</div>
        
        <div class="search-wrap" id="search-wrap">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="back">
                <i class="icon icon-lg icon-chevron-left"></i>
            </a>
            <input type="text" id="key" class="search-input" autocomplete="off" placeholder="検索">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="search">
                <i class="icon icon-lg icon-search"></i>
            </a>
        </div>
        
        
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menuShare">
            <i class="icon icon-lg icon-share-alt"></i>
        </a>
        
    </div>
</header>
<header class="content-header post-header">

    <div class="container fade-scale">
        <h1 class="title">adaboost集成学习</h1>
        <h5 class="subtitle">
            
                <time datetime="2018-12-20T01:18:27.000Z" itemprop="datePublished" class="page-time">
  2018-12-20
</time>


            
        </h5>
    </div>

    


</header>


<div class="container body-wrap">
    
    <aside class="post-widget">
        <nav class="post-toc-wrap post-toc-shrink" id="post-toc">
            <h4>TOC</h4>
            <ol class="post-toc"><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#Adaboost-原理"><span class="post-toc-number">1.</span> <span class="post-toc-text">Adaboost 原理</span></a></li><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#代码实现"><span class="post-toc-number">2.</span> <span class="post-toc-text">代码实现</span></a></li></ol>
        </nav>
    </aside>


<article id="post-adaboost集成学习" class="post-article article-type-post fade" itemprop="blogPost">

    <div class="post-card">
        <h1 class="post-card-title">adaboost集成学习</h1>
        <div class="post-meta">
            <time class="post-time" title="2018-12-20 09:18:27" datetime="2018-12-20T01:18:27.000Z" itemprop="datePublished">2018-12-20</time>

            


            
<span id="busuanzi_container_page_pv" title="文章总阅读量" style="display:none">
    <i class="icon icon-eye icon-pr"></i><span id="busuanzi_value_page_pv"></span>
</span>


        </div>
        <div class="post-content" id="post-content" itemprop="postContent">
            <h1 id="Adaboost-原理"><a href="#Adaboost-原理" class="headerlink" title="Adaboost 原理"></a>Adaboost 原理</h1><p>Adaboost 全称为 adaptive boost,  意为自适应的提升方法，作用是能够通过分布不同权重的方式将多个弱分类器提升为一个强分类器，不同的弱分类器解决不同的分类问题，多个弱分类器通过加权组合得到一个强分类器。详细公式过程如下:</p>
<ol>
<li>给定 N 个样本的<strong>特征向量</strong> $(x_1, …..) \, (x_2…..)  \, …(x_N, ….)$, 每一个样本都有对应的<strong>标签</strong> ${y_1, \, y_2, … y_N}$ 与之相对。</li>
<li>初始化每个<strong>样本</strong>权重 $D_1(i) = (w_1,…..w_N)$ ，初始权重值都为$1/N$。</li>
<li>循环迭代 $T $ 次，每一次迭代执行如下步骤:<ol>
<li>找出分类误差最小的弱分类器 $h_j$ , 计算公式为：$h_j = arg\, min \, \theta  $，其中 $\theta = \sum_1^N D_i * (h_j(x_i…) \neq \,y_i)$ </li>
<li>计算该弱分类器 $h_j$ 的<strong>分类器权重</strong> $\alpha =0.5 * ln(\frac{1 - \theta}{\theta})$ 。这意味着误分率小于0.5的弱分类器得到更高的分类器权重。</li>
<li>重新更新所有样本的权重  $D_{t+1}(i) = \frac{D_t(i)exp(-a_ty_ih_t(x_i))}{Z}$，其中$Z$为规范化因子， 公式为所有样本权重的分子部分$D_t(i)exp(-a_ty_ih_t(x_i))$ <strong>之和</strong>。该式子使得误分类的样本权重提升，正确分类的样本权重降低。</li>
</ol>
</li>
<li>迭代结束，输出强分类器 $H(x) = \sum_{t=1}^{T}  a_t h_t(x)$， 形式为$T$ 个分类器的加权组合。</li>
</ol>
<h1 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h1><p>以下是我个人写的一个Adaboost方法的实现，弱分类器采用sklearn库中的决策树分类器。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">    Description: 以决策树分类器为弱分类器，使用adaboost进行分类器增强</span></span><br><span class="line"><span class="string">    Author: qiuyihao</span></span><br><span class="line"><span class="string">    Date: 18/11/19</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn.tree <span class="keyword">import</span> DecisionTreeClassifier</span><br><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">AdaboostWithDT</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    @ self.param:</span></span><br><span class="line"><span class="string">        train_num: 训练的迭代的次数</span></span><br><span class="line"><span class="string">        classifier_num: 分类器的个数，等于迭代的次数</span></span><br><span class="line"><span class="string">        learn_rate:  学习率，在确定最优（误分率最小的）分类器的时候使用</span></span><br><span class="line"><span class="string">        train_data: 保存的训练数据</span></span><br><span class="line"><span class="string">        train_labels: 保存训练标签</span></span><br><span class="line"><span class="string">        train_samples_num: 训练样本的数目</span></span><br><span class="line"><span class="string">        vector_columns: 样本特征向量的维度</span></span><br><span class="line"><span class="string">        classifer_sets: 学习得到的弱分类器集合</span></span><br><span class="line"><span class="string">        sample_weights: 学习得到的样本的权重集合</span></span><br><span class="line"><span class="string">        alpha: 弱分类器的权重集合</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, n_estunatirs = <span class="number">50</span>, learn_rate = <span class="number">1.0</span>)</span>:</span></span><br><span class="line">        self.train_num = n_estunatirs        <span class="comment"># 迭代次数</span></span><br><span class="line">        self.classifier_num = n_estunatirs   <span class="comment"># 学习到的弱分类器的个数</span></span><br><span class="line">        self.learn_rate = learn_rate         <span class="comment"># 学习率</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">init_args</span><span class="params">(self, train_data, train_labels)</span>:</span></span><br><span class="line">        self.train_data = train_data</span><br><span class="line">        self.train_labels = train_labels </span><br><span class="line">        self.train_samples_num, self.vector_columns = train_data.shape <span class="comment"># 驯良样本数目, 样本特征向量的维度 </span></span><br><span class="line"></span><br><span class="line">        self.classifier_sets = []  <span class="comment"># 学得的弱分类器的集合</span></span><br><span class="line"></span><br><span class="line">        self.sample_weights = [<span class="number">1.0</span> / self.train_samples_num] * self.train_samples_num <span class="comment"># 训练样本的权重集合</span></span><br><span class="line"></span><br><span class="line">        self.alpha = []  <span class="comment"># 弱分类器的权重集合</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 输入误分率，计算在这一轮迭代中的alpha值，即当前习得的分类器的权重值</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">cal_alpha</span><span class="params">(self, error)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">0.5</span> * np.log((<span class="number">1</span> - error) / error)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#计算规范化因子，在更新权重的时候会使用到</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">cal_normalize_factor</span><span class="params">(self,weights,alpha,classifiers)</span>:</span>  <span class="comment"># 第i个样本的classifers[i] 表示分类结果</span></span><br><span class="line">        <span class="keyword">return</span> sum([weights[i] * np.exp(<span class="number">-1</span> * alpha * self.train_labels[i] * classifiers[i]) <span class="keyword">for</span> i <span class="keyword">in</span> range(self.train_samples_num)])    </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 更新样本的权重值</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">cal_weight</span><span class="params">(self, alpha, classifier, normalize_factor)</span>:</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(self.train_samples_num):</span><br><span class="line">           self.sample_weights[i] = self.sample_weights[i] * np.exp(<span class="number">-1</span> * alpha * self.train_labels[i] * classifier[i]) / normalize_factor</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 训练弱分类器</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">        输入：训练样本，标签，样本权重</span></span><br><span class="line"><span class="string">        输出：分类器，误分因子， 分类结果</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">find_classifier</span><span class="params">(self, features, labels, weights)</span>:</span></span><br><span class="line">        samples_num = len(features)  <span class="comment"># 训练样本数目</span></span><br><span class="line">        error = <span class="number">1000000</span>             <span class="comment"># 错误率</span></span><br><span class="line">        resultClassifier = <span class="keyword">None</span>    <span class="comment"># 该轮得到的最佳分类器</span></span><br><span class="line">       </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">5</span>):</span><br><span class="line">            learn_size = self.learn_rate + i </span><br><span class="line">            max_depth = <span class="number">6</span> + learn_size  </span><br><span class="line">            min_samples_leaf = <span class="number">6</span> + learn_size</span><br><span class="line">            min_samples_split = <span class="number">6</span> + learn_size</span><br><span class="line"></span><br><span class="line">            DTClassifier = DecisionTreeClassifier(max_depth=max_depth, </span><br><span class="line">            min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf) <span class="comment"># 决策树分类器</span></span><br><span class="line">            DTClassifier.fit(features, labels) <span class="comment"># 传入样本数据和标签，训练决策树分类器</span></span><br><span class="line"></span><br><span class="line">            <span class="comment"># 计算误分类因子 </span></span><br><span class="line">            predicted_value = DTClassifier.predict(features) <span class="comment"># 二维预测结果</span></span><br><span class="line">            error_factor = <span class="number">0</span>  </span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(samples_num):</span><br><span class="line">                <span class="keyword">if</span> predicted_value[j] != labels[j]:</span><br><span class="line">                    error_factor += weights[j]</span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> error_factor &lt; error:</span><br><span class="line">                error  = error_factor</span><br><span class="line">                resultClassifier = DTClassifier</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">if</span> error == <span class="number">0</span>:</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">        result = resultClassifier.predict(features)  <span class="comment"># 存储分类结果</span></span><br><span class="line">        <span class="keyword">return</span> resultClassifier, error, result </span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">        训练接口:</span></span><br><span class="line"><span class="string">        输入： 训练样本集， 标签集</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span><span class="params">(self, train_data, train_labels)</span>:</span></span><br><span class="line">        self.init_args(train_data, train_labels)</span><br><span class="line">        <span class="keyword">for</span> epoch <span class="keyword">in</span> range(self.train_num):  <span class="comment"># 训练次数</span></span><br><span class="line">            <span class="comment"># 训练得到弱分类器（决策树分类器）</span></span><br><span class="line">            resultClassifier, minError, classifiedResult = self.find_classifier(train_data, train_labels, self.sample_weights)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 计算分类器的权重系数alpha</span></span><br><span class="line">            a = self.cal_alpha(minError)</span><br><span class="line">            self.alpha.append(a)</span><br><span class="line">            </span><br><span class="line">            <span class="comment">#记录分类器</span></span><br><span class="line">            self.classifier_sets.append(resultClassifier)</span><br><span class="line"></span><br><span class="line">            <span class="comment">#更新权重</span></span><br><span class="line">            Z = self.cal_normalize_factor(self.sample_weights, a, classifiedResult)</span><br><span class="line">            self.cal_weight(a, classifiedResult, Z)</span><br><span class="line"></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">        预测接口：</span></span><br><span class="line"><span class="string">        输入：一个样本数据</span></span><br><span class="line"><span class="string">        输出：预测结果</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(self, test_data)</span>:</span></span><br><span class="line">        result = <span class="number">0</span></span><br><span class="line">        voteList = [<span class="number">0</span> <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10</span>)]  </span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(self.classifier_sets)):</span><br><span class="line">            classifer = self.classifier_sets[i]</span><br><span class="line">            test_value = np.array(test_data).reshape(<span class="number">1</span>, len(test_data)).tolist() <span class="comment"># 二维形式</span></span><br><span class="line">            predicted_value =int(classifer.predict(test_value))</span><br><span class="line">            voteList[predicted_value] += self.alpha[i]  <span class="comment"># 投票的思想 按分类器权值投票</span></span><br><span class="line">        result = voteList.index(max(voteList))</span><br><span class="line">        <span class="keyword">return</span> result</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">        使用测试数据和标签评估</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">score</span><span class="params">(self, test_data, test_labels)</span>:</span></span><br><span class="line">        right_num = <span class="number">0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(len(test_data)):</span><br><span class="line">            <span class="keyword">if</span> self.predict(test_data[i]) == test_labels[i]:</span><br><span class="line">                right_num += <span class="number">1</span></span><br><span class="line">        <span class="keyword">return</span> right_num / len(test_data)</span><br></pre></td></tr></table></figure>
<ol>
<li>对 mnist 数据集做初步处理，将数据标签合并到一个训练数据文件 (.csv) 和一个测试数据文件 (.csv) 中。</li>
<li>读取数据文件，得到N 个样本的<strong>特征向量</strong> $(x_1, …..) \, (x_2…..)  \, …(x_N, ….)$, 以及每个样本对应的<strong>标签</strong> ${y_1, \, y_2, … y_N}$ 。</li>
<li>初始化每个<strong>样本</strong>权重 $D_1(i) = (w_1,…..w_N)$ ，初始权重值都为$1/N$。</li>
<li>循环迭代 $T $ 次，每一次迭代执行如下步骤 :<ol>
<li>找出分类误差最小的弱分类器 $h_j$ , 计算公式为：$h_j = arg\, min \, \theta  $，其中 $\theta = \sum_1^N D_i * (h_j(x_i…) \neq \,y_i)$ </li>
<li>计算该弱分类器 $h_j$ 的<strong>分类器权重</strong> $\alpha =0.5 * ln(\frac{1 - \theta}{\theta})$ 。这意味着误分率小于0.5的弱分类器得到更高的分类器权重。</li>
<li>重新更新所有样本的权重  $D_{t+1}(i) = \frac{D_t(i)exp(-a_ty_ih_t(x_i))}{Z}$，其中$Z$为规范化因子， 公式为所有样本权重的分子部分$D_t(i)exp(-a_ty_ih_t(x_i))$ <strong>之和</strong>。该式子使得误分类的样本权重提升，正确分类的样本权重降低。</li>
</ol>
</li>
<li>迭代结束，输出强分类器 $H(x) = \sum_{t=1}^{T}  a_t h_t(x)$， 形式为$T$ 个分类器的加权组合。</li>
<li>输入测试数据做预测，得到准确率。</li>
</ol>

        </div>

        <blockquote class="post-copyright">
    
    <div class="content">
        
<span class="post-time">
    最終更新：<time datetime="2018-12-20T13:35:39.338Z" itemprop="dateUpdated">2018-12-20 21:35:39</time>
</span><br>


        
        Thanks for your reading  :) | URL <a href="/2018/12/20/adaboost集成学习/" target="_blank" rel="external">https://joshuaqyh.github.io/2018/12/20/adaboost集成学习/</a>
        
    </div>
    
    <footer>
        <a href="https://joshuaqyh.github.io">
            <img src="/img/avatar.jpg" alt="Qiuyihao">
            Qiuyihao
        </a>
    </footer>
</blockquote>

        


        <div class="post-footer">
            
	<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/人工智能/">人工智能</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/机器学习/">机器学习</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/计算机视觉/">计算机视觉</a></li></ul>


            
<div class="page-share-wrap">
    

<div class="page-share" id="pageShare">
    <ul class="reset share-icons">
      <li>
        <a class="weibo share-sns" target="_blank" href="http://service.weibo.com/share/share.php?url=https://joshuaqyh.github.io/2018/12/20/adaboost集成学习/&title=《adaboost集成学习》 — KnowMyself&pic=https://joshuaqyh.github.io/img/avatar.jpg" data-title="微博">
          <i class="icon icon-weibo"></i>
        </a>
      </li>
      <li>
        <a class="weixin share-sns wxFab" href="javascript:;" data-title="微信">
          <i class="icon icon-weixin"></i>
        </a>
      </li>
      <li>
        <a class="qq share-sns" target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=https://joshuaqyh.github.io/2018/12/20/adaboost集成学习/&title=《adaboost集成学习》 — KnowMyself&source=Here are some records for life and study." data-title=" QQ">
          <i class="icon icon-qq"></i>
        </a>
      </li>
      <li>
        <a class="facebook share-sns" target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=https://joshuaqyh.github.io/2018/12/20/adaboost集成学习/" data-title=" Facebook">
          <i class="icon icon-facebook"></i>
        </a>
      </li>
      <li>
        <a class="twitter share-sns" target="_blank" href="https://twitter.com/intent/tweet?text=《adaboost集成学习》 — KnowMyself&url=https://joshuaqyh.github.io/2018/12/20/adaboost集成学习/&via=https://joshuaqyh.github.io" data-title=" Twitter">
          <i class="icon icon-twitter"></i>
        </a>
      </li>
      <li>
        <a class="google share-sns" target="_blank" href="https://plus.google.com/share?url=https://joshuaqyh.github.io/2018/12/20/adaboost集成学习/" data-title=" Google+">
          <i class="icon icon-google-plus"></i>
        </a>
      </li>
    </ul>
 </div>



    <a href="javascript:;" id="shareFab" class="page-share-fab waves-effect waves-circle">
        <i class="icon icon-share-alt icon-lg"></i>
    </a>
</div>



        </div>
    </div>

    
<nav class="post-nav flex-row flex-justify-between flex-row-reverse">
  

  
    <div class="waves-block waves-effect next">
      <a href="/2018/12/17/人工神经网络学习/" id="post-next" class="post-nav-link">
        <div class="tips">Next <i class="icon icon-angle-right icon-lg icon-pl"></i></div>
        <h4 class="title">人工神经网络学习</h4>
      </a>
    </div>
  
</nav>



    

















</article>



</div>

        <footer class="footer">
    <div class="top">
        
<p>
    <span id="busuanzi_container_site_uv" style="display:none">
        站点总访客数：<span id="busuanzi_value_site_uv"></span>
    </span>
    <span id="busuanzi_container_site_pv" style="display:none">
        站点总访问量：<span id="busuanzi_value_site_pv"></span>
    </span>
</p>


        <p>
            
                <span><a href="/atom.xml" target="_blank" class="rss" title="rss"><i class="icon icon-lg icon-rss"></i></a></span>
            
            <span>このブログの内容物は<a rel="license" href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.ja">クリエイティブ・コモンズ 表示 - 非営利 - 継承 4.0 国際ライセンスの下に提供されています</a></span>
        </p>
    </div>
    <div class="bottom">
        <p><span>Qiuyihao &copy; 2017 - 2018</span>
            <span>
                
                Power by <a href="http://hexo.io/" target="_blank">Hexo</a> Theme <a href="https://github.com/yscoder/hexo-theme-indigo" target="_blank">indigo</a>
            </span>
        </p>
    </div>
</footer>

    </main>
    <div class="mask" id="mask"></div>
<a href="javascript:;" id="gotop" class="waves-effect waves-circle waves-light"><span class="icon icon-lg icon-chevron-up"></span></a>



<div class="global-share" id="globalShare">
    <ul class="reset share-icons">
      <li>
        <a class="weibo share-sns" target="_blank" href="http://service.weibo.com/share/share.php?url=https://joshuaqyh.github.io/2018/12/20/adaboost集成学习/&title=《adaboost集成学习》 — KnowMyself&pic=https://joshuaqyh.github.io/img/avatar.jpg" data-title="微博">
          <i class="icon icon-weibo"></i>
        </a>
      </li>
      <li>
        <a class="weixin share-sns wxFab" href="javascript:;" data-title="微信">
          <i class="icon icon-weixin"></i>
        </a>
      </li>
      <li>
        <a class="qq share-sns" target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=https://joshuaqyh.github.io/2018/12/20/adaboost集成学习/&title=《adaboost集成学习》 — KnowMyself&source=Here are some records for life and study." data-title=" QQ">
          <i class="icon icon-qq"></i>
        </a>
      </li>
      <li>
        <a class="facebook share-sns" target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=https://joshuaqyh.github.io/2018/12/20/adaboost集成学习/" data-title=" Facebook">
          <i class="icon icon-facebook"></i>
        </a>
      </li>
      <li>
        <a class="twitter share-sns" target="_blank" href="https://twitter.com/intent/tweet?text=《adaboost集成学习》 — KnowMyself&url=https://joshuaqyh.github.io/2018/12/20/adaboost集成学习/&via=https://joshuaqyh.github.io" data-title=" Twitter">
          <i class="icon icon-twitter"></i>
        </a>
      </li>
      <li>
        <a class="google share-sns" target="_blank" href="https://plus.google.com/share?url=https://joshuaqyh.github.io/2018/12/20/adaboost集成学习/" data-title=" Google+">
          <i class="icon icon-google-plus"></i>
        </a>
      </li>
    </ul>
 </div>


<div class="page-modal wx-share" id="wxShare">
    <a class="close" href="javascript:;"><i class="icon icon-close"></i></a>
    <p>扫一扫，分享到微信</p>
    <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAMYAAADGCAAAAACs8KCBAAACLUlEQVR42u3aS27DMAwFwNz/0inQbWP7kXSLWhqvgkZVNF4Q/Oj1ip/393P095/fvn88yf+er7/hwcDAeCzjffocMc5XTo54vtvhPhgYGBswetslwbf3IvKzYWBgYJyvSQ56ngjmnzEwMDDygNtLEDEwMDDmjOQnzzHJbj3SzbU4BgbGAxnVwcBffv7F+QYGBsZDGJPgWG363xVkP5wKAwNjaUbSJptcrUh2njTpXtWtMTAwHsiYXKroBc08x0teKwYGxg6MaiM+v2aRh+zeSOBivoGBgbEQY3KgybeF0jQZpmJgYCzNyNO4ZJyZp4N5e67w4jAwMBZl5O2z3lWMvHGWv44PnzEwMLZhzMNuFVN9EYcrMTAwNmBU2/R56lYdDFQHGBgYGPswLhbFRWY1+FavfWBgYGBUx4rzixSTlxXNVzEwMJZg9IJpfgljsqY5yMTAwFiOcYO4Ve7mgTtaiYGBsQEjT7+ScrT6v/PSFwMDY21GrxKsXshIdsgT0CYMAwPjsYx5CywPwfcWxjd38jAwMP49IydVBwbJ+GHSKfzQbsPAwFiOUQ2y89HmpEy9OCcGBsaijLsK0eQo8wB9uA8GBsbSjF7TLW/lV8vaHhgDA2MHRm+ImJep85FDtAMGBsYGjF6QrSZz1eK5kBRiYGBgBIebJHzVGyIYGBgY1R+bpIn5tbCL4I6BgbEBo5r8zRPEamo4GmRiYGA8nDEpIHvhdRJ8RxgMDIznMb4APBfRP362O6wAAAAASUVORK5CYII=" alt="微信分享二维码">
</div>




    <script src="//cdn.bootcss.com/node-waves/0.7.4/waves.min.js"></script>
<script>
var BLOG = { ROOT: '/', SHARE: true, REWARD: false };


</script>

<script src="//unpkg.com/hexo-theme-material-indigo@latest/js/main.min.js"></script>


<div class="search-panel" id="search-panel">
    <ul class="search-result" id="search-result"></ul>
</div>
<template id="search-tpl">
<li class="item">
    <a href="{path}" class="waves-block waves-effect">
        <div class="title ellipsis" title="{title}">{title}</div>
        <div class="flex-row flex-middle">
            <div class="tags ellipsis">
                {tags}
            </div>
            <time class="flex-col time">{date}</time>
        </div>
    </a>
</li>
</template>

<script src="//unpkg.com/hexo-theme-material-indigo@latest/js/search.min.js" async></script>



<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
</script>

<script async src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script>




<script async src="//dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>



<script>
(function() {
    var OriginTitile = document.title, titleTime;
    document.addEventListener('visibilitychange', function() {
        if (document.hidden) {
            document.title = '唉要去哪里了！';
            clearTimeout(titleTime);
        } else {
            document.title = '(つェ⊂)咦!又好了!';
            titleTime = setTimeout(function() {
                document.title = OriginTitile;
            },2000);
        }
    });
})();
</script>



</body>
</html>
