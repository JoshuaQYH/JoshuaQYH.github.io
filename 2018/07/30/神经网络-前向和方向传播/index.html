
<!DOCTYPE html>
<html lang="" class="loading">
<head><meta name="generator" content="Hexo 3.8.0">
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <meta name="viewport" content="width=device-width, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <title>KnowMyself - Code and life</title>

    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="google" content="notranslate">
    <meta name="keywords" content="Fechin,"> 
    <meta name="description" content="Here are some records for life and study.,"> 
    <meta name="author" content="Qiuyihao"> 
    <link rel="alternative" href="atom.xml" title="KnowMyself" type="application/atom+xml"> 
    <link rel="icon" href="/img/favicon.png"> 
    <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">
    <link rel="stylesheet" href="/css/diaspora.css">
</head>
</html>
<body class="loading">
    <div id="loader"></div>
    <div id="single">
    <div id="top" style="display: block;">
    <div class="bar" style="width: 0;"></div>
    <a class="icon-home image-icon" href="javascript:;"></a>
    <div title="播放/暂停" class="icon-play"></div>
    <h3 class="subtitle">神经网络模型入门--前向和反向传播Python代码实现</h3>
    <div class="social">
        <!--<div class="like-icon">-->
            <!--<a href="javascript:;" class="likeThis active"><span class="icon-like"></span><span class="count">76</span></a>-->
        <!--</div>-->
        <div>
            <div class="share">
                <a title="获取二维码" class="icon-scan" href="javascript:;"></a>
            </div>
            <div id="qr"></div>
        </div>
    </div>
    <div class="scrollbar"></div>
</div>
    <div class="section">
        <div class="article">
    <div class="main">
        <h1 class="title">神经网络模型入门--前向和反向传播Python代码实现</h1>
        <div class="stuff">
            <span>七月 30, 2018</span>
            
  <ul class="post-tags-list"><li class="post-tags-list-item"><a class="post-tags-list-link" href="/tags/python/">python</a></li><li class="post-tags-list-item"><a class="post-tags-list-link" href="/tags/人工智能/">人工智能</a></li><li class="post-tags-list-item"><a class="post-tags-list-link" href="/tags/神经网络/">神经网络</a></li></ul>


        </div>
        <div class="content markdown">
            <p>Just show the code.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">	神经网络模型简介：</span></span><br><span class="line"><span class="string">	单层神经元（感知机）：</span></span><br><span class="line"><span class="string">	1. 输入向量Wi： 多个同维向量，其中包括多个输入节点和标注为+1的偏置节点</span></span><br><span class="line"><span class="string">	2. 输入权值j1： 每个输入向量（除去偏置节点）在输入神经元时都需要乘上一个相应的权值</span></span><br><span class="line"><span class="string">	3. 输入值 ΣWiji + b：   为每个输入节点乘上相应的权值然后求和再加上偏置节点</span></span><br><span class="line"><span class="string">	4. 激活函数： 通常使用sigmoid函数，作为激活函数，有单极性和双极性之分</span></span><br><span class="line"><span class="string">	5. 输出值：   激活函数的返回值，为神经元网络的输出或者为下一个神经元的输入</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">	多层神经元模型：</span></span><br><span class="line"><span class="string">	为单层神经元的级联，每一层的结构包括多个神经元，接受上一层神经元的输入</span></span><br><span class="line"><span class="string">	产生下一神经元的输出，不同层的神经元之间有相应的权值。</span></span><br><span class="line"><span class="string">	* 层次结构：输入层+隐藏层+输出层</span></span><br><span class="line"><span class="string">	1. 输入层：包含多个输入节点和一个标注为+1的偏置节点，偏置节点不接受输入。</span></span><br><span class="line"><span class="string">	2. 隐藏层：为多个神经元级联而成，每一层数目与输入层数目一致</span></span><br><span class="line"><span class="string">	3. 输出层：只有一个神经元结构，最后一层的隐藏层的作为输出层的输入，输出整个神经网络的结果</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">	前向传播与后向（反向）传播</span></span><br><span class="line"><span class="string">	--- 前向传播对应预测（分类），后向传播对应训练</span></span><br><span class="line"><span class="string">	* 前向传播：就是给定模型参数即输入层的输入和偏置节点，逐一计算各层的输出值，直到最后输出神经网络的结果</span></span><br><span class="line"><span class="string">	* 后向传播：</span></span><br><span class="line"><span class="string"> """</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"><span class="comment"># 单极性激活函数，优点连续可导</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid1</span><span class="params">(x)</span>:</span></span><br><span class="line">	<span class="string">"""</span></span><br><span class="line"><span class="string">	:sigmoid单极性函数 1/(1+e^-x)</span></span><br><span class="line"><span class="string">	:param: x， 函数自变量</span></span><br><span class="line"><span class="string">	:return: sigmoid函数值</span></span><br><span class="line"><span class="string">	"""</span></span><br><span class="line">	<span class="keyword">return</span> <span class="number">1.0</span>/(<span class="number">1.0</span> + math.exp(-x))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 单极性激活函数的导数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dsigmoid1</span><span class="params">(y)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">	:sigmoid 单极性函数的导数</span></span><br><span class="line"><span class="string">	:param  y 函数自变量:</span></span><br><span class="line"><span class="string">	:return 函数 运算结果</span></span><br><span class="line"><span class="string">	"""</span></span><br><span class="line">	<span class="keyword">return</span> y*(<span class="number">1</span>-y)</span><br><span class="line"></span><br><span class="line"><span class="comment">#双极性激活函数 </span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid2</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">	：sigmoid双极性函数 tanh （z）</span></span><br><span class="line"><span class="string">	: param x,函数自变量 </span></span><br><span class="line"><span class="string">	: return 函数因变量</span></span><br><span class="line"><span class="string">	"""</span></span><br><span class="line">	<span class="keyword">return</span> math.tanh(x)</span><br><span class="line"></span><br><span class="line"><span class="comment">#双性极性激活函数的导数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dsigmoid2</span><span class="params">(y)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">	: sigmoid双极性函数的导数</span></span><br><span class="line"><span class="string">	：param x,函数自变量</span></span><br><span class="line"><span class="string">	：return 函数因变量</span></span><br><span class="line"><span class="string">	"""</span></span><br><span class="line">	<span class="keyword">return</span> <span class="number">1.0</span> - y ** <span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 神经网络前向传播实现方法</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">	前向传播算法，神经网络的输出值即预测值可作为后向传播误差的计算</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">runNN</span><span class="params">(self, inputs)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">	：前向传播进行分类</span></span><br><span class="line"><span class="string">	：param: inputs-输入参数</span></span><br><span class="line"><span class="string">	：return: 所属类别</span></span><br><span class="line"><span class="string">	"""</span></span><br><span class="line">	<span class="comment"># 输入的数目必须为每一层规定节点数-1，除去偏置节点，不接受输入</span></span><br><span class="line">	<span class="keyword">if</span> len(inputs) != self.ni - <span class="number">1</span>:</span><br><span class="line">    	<span class="keyword">print</span> (<span class="string">"incorrect number of inputs"</span>)</span><br><span class="line">	</span><br><span class="line">	<span class="comment"># 将输入向量映射到神经元的输入节点值</span></span><br><span class="line">	<span class="comment"># ai - 输入层</span></span><br><span class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> range(self.ni - <span class="number">1</span>):</span><br><span class="line">		self.ai[i] = inputs[i]</span><br><span class="line">	</span><br><span class="line">	<span class="comment">#输入层到隐藏层，隐藏层的运算</span></span><br><span class="line">	<span class="comment"># ah - 隐藏层的输出值</span></span><br><span class="line">	<span class="keyword">for</span> j <span class="keyword">in</span> range(self.nh):</span><br><span class="line">		sum = <span class="number">0.0</span></span><br><span class="line">		<span class="keyword">for</span> i <span class="keyword">in</span> range(self.ni):</span><br><span class="line">    		sum += (self.ai[i] * self.wi[i][j]) <span class="comment"># wi为输入层到隐藏层的权值 权值求和 </span></span><br><span class="line">		self.ah[j] = sigmoid(sum)  <span class="comment">#输入激活函数，产生下一神经元的输入</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">#隐藏层到输出层，输出层运算</span></span><br><span class="line">	<span class="comment"># ao - 最终输出结果</span></span><br><span class="line">	<span class="keyword">for</span> k <span class="keyword">in</span> range(self.no):</span><br><span class="line">		sum = <span class="number">0.0</span></span><br><span class="line">		<span class="keyword">for</span> j <span class="keyword">in</span> range(self.nh):</span><br><span class="line">    		sum += (self.ah[j] * self.wo[j][k]) <span class="comment"># wo为隐藏层到输出层的权值</span></span><br><span class="line">		self.ao[k] = sigmoid(sum) </span><br><span class="line">	</span><br><span class="line">	<span class="keyword">return</span> self.ao</span><br><span class="line"></span><br><span class="line"> <span class="string">"""</span></span><br><span class="line"><span class="string">	后向传播</span></span><br><span class="line"><span class="string">	指的是在训练的时候，根据最终输出的误差（预测值-目标值的平方和/2）</span></span><br><span class="line"><span class="string"> 	来调整倒数第二层、倒数第三层……第一层的参数的过程。</span></span><br><span class="line"><span class="string"> 	</span></span><br><span class="line"><span class="string">	主要有三种调整</span></span><br><span class="line"><span class="string">	1. 输出层权值的调整</span></span><br><span class="line"><span class="string">	2. 隐藏层权值的调整</span></span><br><span class="line"><span class="string">	3. 偏置节点的调整</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">	算法步骤</span></span><br><span class="line"><span class="string">	1. 随机初始化参数（指权值和偏置节点），对输入利用前向传播计算输出</span></span><br><span class="line"><span class="string">	2. 对输出和隐藏节点进行调整，计算delta。公式比较难写。。</span></span><br><span class="line"><span class="string">	3. 计算梯度可定义学习率影响训练速度，并更新权值参数偏置参数。</span></span><br><span class="line"><span class="string"> """</span></span><br><span class="line"></span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">backPropagate</span><span class="params">(self, targets, N, M)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        后向传播算法</span></span><br><span class="line"><span class="string">        :param targets: 实例的类别 </span></span><br><span class="line"><span class="string">        :param N: 本次学习率</span></span><br><span class="line"><span class="string">        :param M: 上次学习率</span></span><br><span class="line"><span class="string">        :return: 最终的误差平方和的一半</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="comment"># http://www.youtube.com/watch?v=aVId8KMsdUU&amp;feature=BFa&amp;list=LLldMCkmXl4j9_v0HeKdNcRA</span></span><br><span class="line"> </span><br><span class="line">        <span class="comment"># 计算输出层 deltas</span></span><br><span class="line">        <span class="comment"># dE/dw[j][k] = (t[k] - ao[k]) * s'( SUM( w[j][k]*ah[j] ) ) * ah[j]</span></span><br><span class="line">        output_deltas = [<span class="number">0.0</span>] * self.no</span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> range(self.no):</span><br><span class="line">            error = targets[k] - self.ao[k]</span><br><span class="line">            output_deltas[k] = error * dsigmoid(self.ao[k])</span><br><span class="line"> </span><br><span class="line">        <span class="comment"># 更新输出层权值</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(self.nh):</span><br><span class="line">            <span class="keyword">for</span> k <span class="keyword">in</span> range(self.no):</span><br><span class="line">                <span class="comment"># output_deltas[k] * self.ah[j] 才是 dError/dweight[j][k]</span></span><br><span class="line">                change = output_deltas[k] * self.ah[j]</span><br><span class="line">                self.wo[j][k] += N * change + M * self.co[j][k]</span><br><span class="line">                self.co[j][k] = change</span><br><span class="line"> </span><br><span class="line">        <span class="comment"># 计算隐藏层 deltas</span></span><br><span class="line">        hidden_deltas = [<span class="number">0.0</span>] * self.nh</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(self.nh):</span><br><span class="line">            error = <span class="number">0.0</span></span><br><span class="line">            <span class="keyword">for</span> k <span class="keyword">in</span> range(self.no):</span><br><span class="line">                error += output_deltas[k] * self.wo[j][k]</span><br><span class="line">            hidden_deltas[j] = error * dsigmoid(self.ah[j])</span><br><span class="line"> </span><br><span class="line">        <span class="comment"># 更新输入层权值</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(self.ni):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(self.nh):</span><br><span class="line">                change = hidden_deltas[j] * self.ai[i]</span><br><span class="line">                <span class="comment"># print 'activation',self.ai[i],'synapse',i,j,'change',change</span></span><br><span class="line">                self.wi[i][j] += N * change + M * self.ci[i][j]</span><br><span class="line">                self.ci[i][j] = change</span><br><span class="line"> </span><br><span class="line">        <span class="comment"># 计算误差平方和</span></span><br><span class="line">        <span class="comment"># 1/2 是为了好看，**2 是平方</span></span><br><span class="line">        error = <span class="number">0.0</span></span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> range(len(targets)):</span><br><span class="line">            error = <span class="number">0.5</span> * (targets[k] - self.ao[k]) ** <span class="number">2</span></span><br><span class="line">        <span class="keyword">return</span> error</span><br></pre></td></tr></table></figure>
<p> 来源来自大牛 <a href="http://www.hankcs.com/ml/back-propagation-neural-network.html" target="_blank" rel="noopener">http://www.hankcs.com/ml/back-propagation-neural-network.html</a>  thx！</p>

            <!--[if lt IE 9]><script>document.createElement('audio');</script><![endif]-->
            <audio id="audio" loop="1" preload="auto" controls="controls" data-autoplay="false">
                <source type="audio/mpeg" src="">
            </audio>
            
                <ul id="audio-list" style="display:none">
                    
                        <li title="0" data-url="http://link.hhtjim.com/163/5146554.mp3"></li>
                    
                        <li title="1" data-url="http://link.hhtjim.com/qq/001faIUs4M2zna.mp3"></li>
                    
                </ul>
            
        </div>
        
    <div id="gitalk-container" class="comment link" data-ae="false" data-ci="" data-cs="" data-r="" data-o="" data-a="" data-d="false">查看评论</div>


    </div>
    
</div>


    </div>
</div>
</body>
<script src="//cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.min.js"></script>
<script src="//lib.baomitu.com/jquery/1.8.3/jquery.min.js"></script>
<script src="/js/plugin.js"></script>
<script src="/js/diaspora.js"></script>
<link rel="stylesheet" href="/photoswipe/photoswipe.css">
<link rel="stylesheet" href="/photoswipe/default-skin/default-skin.css">
<script src="/photoswipe/photoswipe.min.js"></script>
<script src="/photoswipe/photoswipe-ui-default.min.js"></script>

<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">
    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>
    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">
        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>
        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">
            <div class="pswp__top-bar">
                <!--  Controls are self-explanatory. Order can be changed. -->
                <div class="pswp__counter"></div>
                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
                <button class="pswp__button pswp__button--share" title="Share"></button>
                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>
                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>
            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div> 
            </div>
            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>
            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>
            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>
        </div>
    </div>
</div>




</html>