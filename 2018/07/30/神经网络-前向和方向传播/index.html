
 <!DOCTYPE HTML>
<html >
<head>
  <meta charset="UTF-8">
  
    <title>神经网络模型入门--前向和反向传播Python代码实现 | KnowMyself</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=3, minimum-scale=1">
    
    <meta name="author" content="Qiuyihao">
    
    <meta name="description" content="Just show the code.
1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697">
    
    
    
    
    
    <link rel="icon" href="/img/favicon.ico">
    
    
    <link rel="apple-touch-icon" href="/img/pacman.jpg">
    <link rel="apple-touch-icon-precomposed" href="/img/pacman.jpg">
    
    <link rel="stylesheet" href="/css/style.css">
</head>

  <body>
    <header>
      <div>
		
			<div id="imglogo">
				<a href="/"><img src="/img/logo.svg" alt="KnowMyself" title="KnowMyself"/></a>
			</div>
			
			<div id="textlogo">
				<h1 class="site-name"><a href="/" title="KnowMyself">KnowMyself</a></h1>
				<h2 class="blog-motto">Code and life</h2>
			</div>
			<div class="navbar"><a class="navbutton navmobile" href="#" title="Menu">
			</a></div>
			<nav class="animated">
				<ul>
					
						<li><a href="/">Home</a></li>
					
						<li><a href="/archives">Archives</a></li>
					
					<li>
					
					<form class="search" action="//google.com/search" method="get" accept-charset="utf-8">
						<label>Search</label>
						<input type="text" id="search" name="q" autocomplete="off" maxlength="20" placeholder="Search" />
						<input type="hidden" name="q" value="site:joshuaqyh.github.io">
					</form>
					
					</li>
				</ul>
			</nav>			
</div>

    </header>
    <div id="container">
      <div id="main" class="post" itemscope itemprop="blogPost">
	<article itemprop="articleBody"> 
		<header class="article-info clearfix">
  <h1 itemprop="name">
    
      <a href="/2018/07/30/神经网络-前向和方向传播/" title="神经网络模型入门--前向和反向传播Python代码实现" itemprop="url">神经网络模型入门--前向和反向传播Python代码实现</a>
  </h1>
  <p class="article-author">By
    
      <a href="https://joshuaqyh.github.io" title="Qiuyihao">Qiuyihao</a>
    </p>
  <p class="article-time">
    <time datetime="2018-07-30T05:58:03.051Z" itemprop="datePublished">2018-07-30</time>
    Updated:<time datetime="2018-07-30T06:00:50.732Z" itemprop="dateModified">2018-07-30</time>
    
  </p>
</header>
	<div class="article-content">
		
		
		<div id="toc" class="toc-article">
			<strong class="toc-title">Contents</strong>
		
		</div>
		
		<p>Just show the code.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">	神经网络模型简介：</span></span><br><span class="line"><span class="string">	单层神经元（感知机）：</span></span><br><span class="line"><span class="string">	1. 输入向量Wi： 多个同维向量，其中包括多个输入节点和标注为+1的偏置节点</span></span><br><span class="line"><span class="string">	2. 输入权值j1： 每个输入向量（除去偏置节点）在输入神经元时都需要乘上一个相应的权值</span></span><br><span class="line"><span class="string">	3. 输入值 ΣWiji + b：   为每个输入节点乘上相应的权值然后求和再加上偏置节点</span></span><br><span class="line"><span class="string">	4. 激活函数： 通常使用sigmoid函数，作为激活函数，有单极性和双极性之分</span></span><br><span class="line"><span class="string">	5. 输出值：   激活函数的返回值，为神经元网络的输出或者为下一个神经元的输入</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">	多层神经元模型：</span></span><br><span class="line"><span class="string">	为单层神经元的级联，每一层的结构包括多个神经元，接受上一层神经元的输入</span></span><br><span class="line"><span class="string">	产生下一神经元的输出，不同层的神经元之间有相应的权值。</span></span><br><span class="line"><span class="string">	* 层次结构：输入层+隐藏层+输出层</span></span><br><span class="line"><span class="string">	1. 输入层：包含多个输入节点和一个标注为+1的偏置节点，偏置节点不接受输入。</span></span><br><span class="line"><span class="string">	2. 隐藏层：为多个神经元级联而成，每一层数目与输入层数目一致</span></span><br><span class="line"><span class="string">	3. 输出层：只有一个神经元结构，最后一层的隐藏层的作为输出层的输入，输出整个神经网络的结果</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">	前向传播与后向（反向）传播</span></span><br><span class="line"><span class="string">	--- 前向传播对应预测（分类），后向传播对应训练</span></span><br><span class="line"><span class="string">	* 前向传播：就是给定模型参数即输入层的输入和偏置节点，逐一计算各层的输出值，直到最后输出神经网络的结果</span></span><br><span class="line"><span class="string">	* 后向传播：</span></span><br><span class="line"><span class="string"> """</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"><span class="comment"># 单极性激活函数，优点连续可导</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid1</span><span class="params">(x)</span>:</span></span><br><span class="line">	<span class="string">"""</span></span><br><span class="line"><span class="string">	:sigmoid单极性函数 1/(1+e^-x)</span></span><br><span class="line"><span class="string">	:param: x， 函数自变量</span></span><br><span class="line"><span class="string">	:return: sigmoid函数值</span></span><br><span class="line"><span class="string">	"""</span></span><br><span class="line">	<span class="keyword">return</span> <span class="number">1.0</span>/(<span class="number">1.0</span> + math.exp(-x))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 单极性激活函数的导数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dsigmoid1</span><span class="params">(y)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">	:sigmoid 单极性函数的导数</span></span><br><span class="line"><span class="string">	:param  y 函数自变量:</span></span><br><span class="line"><span class="string">	:return 函数 运算结果</span></span><br><span class="line"><span class="string">	"""</span></span><br><span class="line">	<span class="keyword">return</span> y*(<span class="number">1</span>-y)</span><br><span class="line"></span><br><span class="line"><span class="comment">#双极性激活函数 </span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid2</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">	：sigmoid双极性函数 tanh （z）</span></span><br><span class="line"><span class="string">	: param x,函数自变量 </span></span><br><span class="line"><span class="string">	: return 函数因变量</span></span><br><span class="line"><span class="string">	"""</span></span><br><span class="line">	<span class="keyword">return</span> math.tanh(x)</span><br><span class="line"></span><br><span class="line"><span class="comment">#双性极性激活函数的导数</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">dsigmoid2</span><span class="params">(y)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">	: sigmoid双极性函数的导数</span></span><br><span class="line"><span class="string">	：param x,函数自变量</span></span><br><span class="line"><span class="string">	：return 函数因变量</span></span><br><span class="line"><span class="string">	"""</span></span><br><span class="line">	<span class="keyword">return</span> <span class="number">1.0</span> - y ** <span class="number">2</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 神经网络前向传播实现方法</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">	前向传播算法，神经网络的输出值即预测值可作为后向传播误差的计算</span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">runNN</span><span class="params">(self, inputs)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">	：前向传播进行分类</span></span><br><span class="line"><span class="string">	：param: inputs-输入参数</span></span><br><span class="line"><span class="string">	：return: 所属类别</span></span><br><span class="line"><span class="string">	"""</span></span><br><span class="line">	<span class="comment"># 输入的数目必须为每一层规定节点数-1，除去偏置节点，不接受输入</span></span><br><span class="line">	<span class="keyword">if</span> len(inputs) != self.ni - <span class="number">1</span>:</span><br><span class="line">    	<span class="keyword">print</span> (<span class="string">"incorrect number of inputs"</span>)</span><br><span class="line">	</span><br><span class="line">	<span class="comment"># 将输入向量映射到神经元的输入节点值</span></span><br><span class="line">	<span class="comment"># ai - 输入层</span></span><br><span class="line">	<span class="keyword">for</span> i <span class="keyword">in</span> range(self.ni - <span class="number">1</span>):</span><br><span class="line">		self.ai[i] = inputs[i]</span><br><span class="line">	</span><br><span class="line">	<span class="comment">#输入层到隐藏层，隐藏层的运算</span></span><br><span class="line">	<span class="comment"># ah - 隐藏层的输出值</span></span><br><span class="line">	<span class="keyword">for</span> j <span class="keyword">in</span> range(self.nh):</span><br><span class="line">		sum = <span class="number">0.0</span></span><br><span class="line">		<span class="keyword">for</span> i <span class="keyword">in</span> range(self.ni):</span><br><span class="line">    		sum += (self.ai[i] * self.wi[i][j]) <span class="comment"># wi为输入层到隐藏层的权值 权值求和 </span></span><br><span class="line">		self.ah[j] = sigmoid(sum)  <span class="comment">#输入激活函数，产生下一神经元的输入</span></span><br><span class="line"></span><br><span class="line">	<span class="comment">#隐藏层到输出层，输出层运算</span></span><br><span class="line">	<span class="comment"># ao - 最终输出结果</span></span><br><span class="line">	<span class="keyword">for</span> k <span class="keyword">in</span> range(self.no):</span><br><span class="line">		sum = <span class="number">0.0</span></span><br><span class="line">		<span class="keyword">for</span> j <span class="keyword">in</span> range(self.nh):</span><br><span class="line">    		sum += (self.ah[j] * self.wo[j][k]) <span class="comment"># wo为隐藏层到输出层的权值</span></span><br><span class="line">		self.ao[k] = sigmoid(sum) </span><br><span class="line">	</span><br><span class="line">	<span class="keyword">return</span> self.ao</span><br><span class="line"></span><br><span class="line"> <span class="string">"""</span></span><br><span class="line"><span class="string">	后向传播</span></span><br><span class="line"><span class="string">	指的是在训练的时候，根据最终输出的误差（预测值-目标值的平方和/2）</span></span><br><span class="line"><span class="string"> 	来调整倒数第二层、倒数第三层……第一层的参数的过程。</span></span><br><span class="line"><span class="string"> 	</span></span><br><span class="line"><span class="string">	主要有三种调整</span></span><br><span class="line"><span class="string">	1. 输出层权值的调整</span></span><br><span class="line"><span class="string">	2. 隐藏层权值的调整</span></span><br><span class="line"><span class="string">	3. 偏置节点的调整</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">	算法步骤</span></span><br><span class="line"><span class="string">	1. 随机初始化参数（指权值和偏置节点），对输入利用前向传播计算输出</span></span><br><span class="line"><span class="string">	2. 对输出和隐藏节点进行调整，计算delta。公式比较难写。。</span></span><br><span class="line"><span class="string">	3. 计算梯度可定义学习率影响训练速度，并更新权值参数偏置参数。</span></span><br><span class="line"><span class="string"> """</span></span><br><span class="line"></span><br><span class="line"> <span class="function"><span class="keyword">def</span> <span class="title">backPropagate</span><span class="params">(self, targets, N, M)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">        后向传播算法</span></span><br><span class="line"><span class="string">        :param targets: 实例的类别 </span></span><br><span class="line"><span class="string">        :param N: 本次学习率</span></span><br><span class="line"><span class="string">        :param M: 上次学习率</span></span><br><span class="line"><span class="string">        :return: 最终的误差平方和的一半</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line">        <span class="comment"># http://www.youtube.com/watch?v=aVId8KMsdUU&amp;feature=BFa&amp;list=LLldMCkmXl4j9_v0HeKdNcRA</span></span><br><span class="line"> </span><br><span class="line">        <span class="comment"># 计算输出层 deltas</span></span><br><span class="line">        <span class="comment"># dE/dw[j][k] = (t[k] - ao[k]) * s'( SUM( w[j][k]*ah[j] ) ) * ah[j]</span></span><br><span class="line">        output_deltas = [<span class="number">0.0</span>] * self.no</span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> range(self.no):</span><br><span class="line">            error = targets[k] - self.ao[k]</span><br><span class="line">            output_deltas[k] = error * dsigmoid(self.ao[k])</span><br><span class="line"> </span><br><span class="line">        <span class="comment"># 更新输出层权值</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(self.nh):</span><br><span class="line">            <span class="keyword">for</span> k <span class="keyword">in</span> range(self.no):</span><br><span class="line">                <span class="comment"># output_deltas[k] * self.ah[j] 才是 dError/dweight[j][k]</span></span><br><span class="line">                change = output_deltas[k] * self.ah[j]</span><br><span class="line">                self.wo[j][k] += N * change + M * self.co[j][k]</span><br><span class="line">                self.co[j][k] = change</span><br><span class="line"> </span><br><span class="line">        <span class="comment"># 计算隐藏层 deltas</span></span><br><span class="line">        hidden_deltas = [<span class="number">0.0</span>] * self.nh</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> range(self.nh):</span><br><span class="line">            error = <span class="number">0.0</span></span><br><span class="line">            <span class="keyword">for</span> k <span class="keyword">in</span> range(self.no):</span><br><span class="line">                error += output_deltas[k] * self.wo[j][k]</span><br><span class="line">            hidden_deltas[j] = error * dsigmoid(self.ah[j])</span><br><span class="line"> </span><br><span class="line">        <span class="comment"># 更新输入层权值</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(self.ni):</span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> range(self.nh):</span><br><span class="line">                change = hidden_deltas[j] * self.ai[i]</span><br><span class="line">                <span class="comment"># print 'activation',self.ai[i],'synapse',i,j,'change',change</span></span><br><span class="line">                self.wi[i][j] += N * change + M * self.ci[i][j]</span><br><span class="line">                self.ci[i][j] = change</span><br><span class="line"> </span><br><span class="line">        <span class="comment"># 计算误差平方和</span></span><br><span class="line">        <span class="comment"># 1/2 是为了好看，**2 是平方</span></span><br><span class="line">        error = <span class="number">0.0</span></span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> range(len(targets)):</span><br><span class="line">            error = <span class="number">0.5</span> * (targets[k] - self.ao[k]) ** <span class="number">2</span></span><br><span class="line">        <span class="keyword">return</span> error</span><br></pre></td></tr></table></figure>
<p> 来源来自大牛 <a href="http://www.hankcs.com/ml/back-propagation-neural-network.html" target="_blank" rel="noopener">http://www.hankcs.com/ml/back-propagation-neural-network.html</a>  thx！</p>
  
	</div>
		<footer class="article-footer clearfix">

  <div class="article-tags">
  
  <span></span> <a href="/tags/神经网络/">神经网络</a>
  </div>




<div class="article-share" id="share">

  <div data-url="https://joshuaqyh.github.io/2018/07/30/神经网络-前向和方向传播/" data-title="神经网络模型入门--前向和反向传播Python代码实现 | KnowMyself" data-tsina="" class="share clearfix">
  </div>

</div>
</footer>   	       
	</article>
	
<nav class="article-nav clearfix">
 
 <div class="prev" >
 <a href="/2018/08/15/机器学习（一）--概念理解/" title="机器学习（一）--概念理解">
  <strong>PREVIOUS:</strong><br/>
  <span>
  机器学习（一）--概念理解</span>
</a>
</div>


<div class="next">
<a href="/2018/07/27/认识经济学原理/"  title="认识经济学原理">
 <strong>NEXT:</strong><br/> 
 <span>认识经济学原理
</span>
</a>
</div>

</nav>

	
</div>  
      <div class="openaside"><a class="navbutton" href="#" title="Show Sidebar"></a></div>

  <div id="toc" class="toc-aside">
  <strong class="toc-title">Contents</strong>
  
  </div>

<div id="asidepart">
<div class="closeaside"><a class="closebutton" href="#" title="Hide Sidebar"></a></div>
<aside class="clearfix">

  

  
<div class="tagslist">
	<p class="asidetitle">Tags</p>
		<ul class="clearfix">
		
			<li><a href="/tags/cocos2d/" title="cocos2d">cocos2d<sup>1</sup></a></li>
		
			<li><a href="/tags/git/" title="git">git<sup>1</sup></a></li>
		
			<li><a href="/tags/js-cocos2d-x/" title="js, cocos2d.x">js, cocos2d.x<sup>1</sup></a></li>
		
			<li><a href="/tags/love/" title="love">love<sup>1</sup></a></li>
		
			<li><a href="/tags/markdown/" title="markdown">markdown<sup>1</sup></a></li>
		
			<li><a href="/tags/postgresql/" title="postgresql">postgresql<sup>1</sup></a></li>
		
			<li><a href="/tags/verilog-计组实验/" title="verilog 计组实验">verilog 计组实验<sup>1</sup></a></li>
		
			<li><a href="/tags/互联网思维/" title="互联网思维">互联网思维<sup>1</sup></a></li>
		
			<li><a href="/tags/区块链/" title="区块链">区块链<sup>1</sup></a></li>
		
			<li><a href="/tags/操作系统/" title="操作系统">操作系统<sup>2</sup></a></li>
		
			<li><a href="/tags/数据库理论/" title="数据库理论">数据库理论<sup>1</sup></a></li>
		
			<li><a href="/tags/机器学习/" title="机器学习">机器学习<sup>1</sup></a></li>
		
			<li><a href="/tags/神经网络/" title="神经网络">神经网络<sup>1</sup></a></li>
		
			<li><a href="/tags/经济学，毛概/" title="经济学，毛概">经济学，毛概<sup>1</sup></a></li>
		
			<li><a href="/tags/编程软件-vim-java/" title="编程软件 vim java">编程软件 vim java<sup>1</sup></a></li>
		
			<li><a href="/tags/计组实验-CPU/" title="计组实验 CPU">计组实验 CPU<sup>1</sup></a></li>
		
			<li><a href="/tags/计组理论-CPU/" title="计组理论 CPU">计组理论 CPU<sup>1</sup></a></li>
		
		</ul>
</div>


  <div class="rsspart">
	<a href="" target="_blank" title="rss">RSS</a>
</div>

</aside>
</div>
    </div>
    <footer><div id="footer" >
	
	<div class="line">
		<span></span>
		<div class="author"></div>
	</div>
	
	
	<div class="social-font clearfix">
		
		
		
		
		
	</div>
		<p class="copyright">Powered by <a href="http://hexo.io" target="_blank" title="hexo">hexo</a> and Theme by <a href="https://github.com/A-limon/pacman" target="_blank" title="Pacman">Pacman</a> © 2018 
		
		<a href="https://joshuaqyh.github.io" target="_blank" title="Qiuyihao">Qiuyihao</a>
		
		</p>
</div>
</footer>
    <script src="/js/jquery-2.1.0.min.js"></script>
<script type="text/javascript">
$(document).ready(function(){ 
  $('.navbar').click(function(){
    $('header nav').toggleClass('shownav');
  });
  var myWidth = 0;
  function getSize(){
    if( typeof( window.innerWidth ) == 'number' ) {
      myWidth = window.innerWidth;
    } else if( document.documentElement && document.documentElement.clientWidth) {
      myWidth = document.documentElement.clientWidth;
    };
  };
  var m = $('#main'),
      a = $('#asidepart'),
      c = $('.closeaside'),
      o = $('.openaside');
  $(window).resize(function(){
    getSize(); 
    if (myWidth >= 1024) {
      $('header nav').removeClass('shownav');
    }else
    {
      m.removeClass('moveMain');
      a.css('display', 'block').removeClass('fadeOut');
      o.css('display', 'none');
      
      $('#toc.toc-aside').css('display', 'none');
        
    }
  });
  c.click(function(){
    a.addClass('fadeOut').css('display', 'none');
    o.css('display', 'block').addClass('fadeIn');
    m.addClass('moveMain');
  });
  o.click(function(){
    o.css('display', 'none').removeClass('beforeFadeIn');
    a.css('display', 'block').removeClass('fadeOut').addClass('fadeIn');      
    m.removeClass('moveMain');
  });
  $(window).scroll(function(){
    o.css("top",Math.max(80,260-$(this).scrollTop()));
  });
});
</script>

<script type="text/javascript">
$(document).ready(function(){ 
  var ai = $('.article-content>iframe'),
      ae = $('.article-content>embed'),
      t  = $('#toc'),
      h  = $('article h2')
      ah = $('article h2'),
      ta = $('#toc.toc-aside'),
      o  = $('.openaside'),
      c  = $('.closeaside');
  if(ai.length>0){
    ai.wrap('<div class="video-container" />');
  };
  if(ae.length>0){
   ae.wrap('<div class="video-container" />');
  };
  if(ah.length==0){
    t.css('display','none');
  }else{
    c.click(function(){
      ta.css('display', 'block').addClass('fadeIn');
    });
    o.click(function(){
      ta.css('display', 'none');
    });
    $(window).scroll(function(){
      ta.css("top",Math.max(140,320-$(this).scrollTop()));
    });
  };
});
</script>


<script type="text/javascript">
$(document).ready(function(){ 
  var $this = $('.share'),
      url = $this.attr('data-url'),
      encodedUrl = encodeURIComponent(url),
      title = $this.attr('data-title'),
      tsina = $this.attr('data-tsina');
  var html = [
  '<a href="#" class="overlay" id="qrcode"></a>',
  '<div class="qrcode clearfix"><span>扫描二维码分享到微信朋友圈</span><a class="qrclose" href="#share"></a><strong>Loading...Please wait</strong><img id="qrcode-pic" data-src="http://s.jiathis.com/qrcode.php?url=' + encodedUrl + '"/></div>',
  '<a href="#textlogo" class="article-back-to-top" title="Top"></a>',
  '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="article-share-facebook" target="_blank" title="Facebook"></a>',
  '<a href="#qrcode" class="article-share-qrcode" title="QRcode"></a>',
  '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="article-share-twitter" target="_blank" title="Twitter"></a>',
  '<a href="http://service.weibo.com/share/share.php?title='+title+'&url='+encodedUrl +'&ralateUid='+ tsina +'&searchPic=true&style=number' +'" class="article-share-weibo" target="_blank" title="Weibo"></a>',
  '<span title="Share to"></span>'
  ].join('');
  $this.append(html);
  $('.article-share-qrcode').click(function(){
    var imgSrc = $('#qrcode-pic').attr('data-src');
    $('#qrcode-pic').attr('src', imgSrc);
    $('#qrcode-pic').load(function(){
        $('.qrcode strong').text(' ');
    });
  });
});     
</script>






  </body>
</html>
